#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ•°æ®ç›®å½•ç®¡ç†å·¥å…·
ç”¨äºç®¡ç†å’Œç»´æŠ¤dataç›®å½•ä¸‹çš„å„ç§æ•°æ®æ–‡ä»¶
"""

import os
import json
import shutil
import glob
from datetime import datetime, timedelta
import argparse

class DataManager:
    """æ•°æ®ç›®å½•ç®¡ç†å™¨"""
    
    def __init__(self):
        self.data_root = "data"
        self.backtest_dir = os.path.join(self.data_root, "backtest")
        self.portfolio_dir = os.path.join(self.data_root, "portfolio")
        self.result_dir = os.path.join(self.data_root, "result")
        self.cache_dir = os.path.join(self.data_root, "cache")
        
    def ensure_directories(self):
        """ç¡®ä¿æ‰€æœ‰å¿…è¦çš„ç›®å½•å­˜åœ¨"""
        directories = [
            os.path.join(self.backtest_dir, "cache"),
            os.path.join(self.backtest_dir, "reports"),
            self.portfolio_dir,
            self.cache_dir,
            os.path.join(self.data_root, "smart_cache")
        ]
        
        for directory in directories:
            os.makedirs(directory, exist_ok=True)
            print(f"âœ… ç¡®ä¿ç›®å½•å­˜åœ¨: {directory}")
    
    def clean_old_cache(self, days=30):
        """æ¸…ç†è¿‡æœŸçš„ç¼“å­˜æ–‡ä»¶"""
        cutoff_date = datetime.now() - timedelta(days=days)
        cleaned_count = 0
        
        # æ¸…ç†å›æµ‹ç¼“å­˜
        cache_pattern = os.path.join(self.backtest_dir, "cache", "*.json")
        for cache_file in glob.glob(cache_pattern):
            if os.path.getmtime(cache_file) < cutoff_date.timestamp():
                os.remove(cache_file)
                cleaned_count += 1
                print(f"ğŸ—‘ï¸  åˆ é™¤è¿‡æœŸç¼“å­˜: {os.path.basename(cache_file)}")
        
        # æ¸…ç†é€šç”¨ç¼“å­˜
        cache_pattern = os.path.join(self.cache_dir, "*.json")
        for cache_file in glob.glob(cache_pattern):
            if os.path.getmtime(cache_file) < cutoff_date.timestamp():
                os.remove(cache_file)
                cleaned_count += 1
                print(f"ğŸ—‘ï¸  åˆ é™¤è¿‡æœŸç¼“å­˜: {os.path.basename(cache_file)}")
        
        print(f"âœ… æ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤ {cleaned_count} ä¸ªè¿‡æœŸç¼“å­˜æ–‡ä»¶")
    
    def clean_old_logs(self, days=7):
        """æ¸…ç†è¿‡æœŸçš„æ—¥å¿—æ–‡ä»¶"""
        cutoff_date = datetime.now() - timedelta(days=days)
        cleaned_count = 0
        
        # æ¸…ç†ç­›é€‰æ—¥å¿—
        log_pattern = os.path.join(self.result_dir, "*.log")
        for log_file in glob.glob(log_pattern):
            if os.path.getmtime(log_file) < cutoff_date.timestamp():
                os.remove(log_file)
                cleaned_count += 1
                print(f"ğŸ—‘ï¸  åˆ é™¤è¿‡æœŸæ—¥å¿—: {os.path.basename(log_file)}")
        
        # æ¸…ç†å­ç›®å½•ä¸­çš„æ—¥å¿—
        for root, dirs, files in os.walk(self.result_dir):
            for file in files:
                if file.endswith('.log'):
                    file_path = os.path.join(root, file)
                    if os.path.getmtime(file_path) < cutoff_date.timestamp():
                        os.remove(file_path)
                        cleaned_count += 1
                        print(f"ğŸ—‘ï¸  åˆ é™¤è¿‡æœŸæ—¥å¿—: {file}")
        
        print(f"âœ… æ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤ {cleaned_count} ä¸ªè¿‡æœŸæ—¥å¿—æ–‡ä»¶")
    
    def backup_portfolio(self):
        """å¤‡ä»½æŒä»“æ•°æ®"""
        portfolio_file = os.path.join(self.portfolio_dir, "portfolio.json")
        if not os.path.exists(portfolio_file):
            print("âš ï¸  æŒä»“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡å¤‡ä»½")
            return
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_file = os.path.join(self.portfolio_dir, f"portfolio.json.backup_{timestamp}")
        
        shutil.copy2(portfolio_file, backup_file)
        print(f"âœ… æŒä»“æ•°æ®å·²å¤‡ä»½: {os.path.basename(backup_file)}")
    
    def get_directory_stats(self):
        """è·å–ç›®å½•ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        
        # å›æµ‹ç¼“å­˜ç»Ÿè®¡
        cache_files = glob.glob(os.path.join(self.backtest_dir, "cache", "*.json"))
        cache_size = sum(os.path.getsize(f) for f in cache_files)
        stats['backtest_cache'] = {
            'count': len(cache_files),
            'size_mb': round(cache_size / 1024 / 1024, 2)
        }
        
        # æŒä»“æ•°æ®ç»Ÿè®¡
        portfolio_files = glob.glob(os.path.join(self.portfolio_dir, "*.json"))
        portfolio_size = sum(os.path.getsize(f) for f in portfolio_files)
        stats['portfolio'] = {
            'count': len(portfolio_files),
            'size_mb': round(portfolio_size / 1024 / 1024, 2)
        }
        
        # ç­›é€‰ç»“æœç»Ÿè®¡
        result_dirs = [d for d in os.listdir(self.result_dir) 
                      if os.path.isdir(os.path.join(self.result_dir, d))]
        stats['result_strategies'] = len(result_dirs)
        
        return stats
    
    def print_stats(self):
        """æ‰“å°ç›®å½•ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.get_directory_stats()
        
        print("\nğŸ“Š æ•°æ®ç›®å½•ç»Ÿè®¡ä¿¡æ¯")
        print("=" * 50)
        print(f"å›æµ‹ç¼“å­˜æ–‡ä»¶: {stats['backtest_cache']['count']} ä¸ª")
        print(f"å›æµ‹ç¼“å­˜å¤§å°: {stats['backtest_cache']['size_mb']} MB")
        print(f"æŒä»“ç›¸å…³æ–‡ä»¶: {stats['portfolio']['count']} ä¸ª")
        print(f"æŒä»“æ•°æ®å¤§å°: {stats['portfolio']['size_mb']} MB")
        print(f"ç­–ç•¥ç»“æœç›®å½•: {stats['result_strategies']} ä¸ª")
        print("=" * 50)
    
    def migrate_old_files(self):
        """è¿ç§»æ—§çš„æ–‡ä»¶åˆ°æ–°çš„ç›®å½•ç»“æ„"""
        print("ğŸ”„ å¼€å§‹è¿ç§»æ—§æ–‡ä»¶...")
        
        # è¿ç§»æ ¹ç›®å½•ä¸‹çš„å›æµ‹ç¼“å­˜æ–‡ä»¶
        old_cache_pattern = os.path.join(self.data_root, "backtest_cache_*.json")
        migrated_count = 0
        
        for old_file in glob.glob(old_cache_pattern):
            new_file = os.path.join(self.backtest_dir, "cache", os.path.basename(old_file))
            if not os.path.exists(new_file):
                shutil.move(old_file, new_file)
                migrated_count += 1
                print(f"ğŸ“¦ è¿ç§»ç¼“å­˜æ–‡ä»¶: {os.path.basename(old_file)}")
        
        # è¿ç§»æ ¹ç›®å½•ä¸‹çš„æŒä»“æ–‡ä»¶
        old_portfolio_files = [
            os.path.join(self.data_root, "portfolio.json"),
            os.path.join(self.data_root, "portfolio_scan_cache.json")
        ]
        
        for old_file in old_portfolio_files:
            if os.path.exists(old_file):
                new_file = os.path.join(self.portfolio_dir, os.path.basename(old_file))
                if not os.path.exists(new_file):
                    shutil.move(old_file, new_file)
                    migrated_count += 1
                    print(f"ğŸ“¦ è¿ç§»æŒä»“æ–‡ä»¶: {os.path.basename(old_file)}")
        
        print(f"âœ… è¿ç§»å®Œæˆï¼Œå…±è¿ç§» {migrated_count} ä¸ªæ–‡ä»¶")

def main():
    parser = argparse.ArgumentParser(description="æ•°æ®ç›®å½•ç®¡ç†å·¥å…·")
    parser.add_argument("--init", action="store_true", help="åˆå§‹åŒ–ç›®å½•ç»“æ„")
    parser.add_argument("--clean-cache", type=int, default=30, help="æ¸…ç†Nå¤©å‰çš„ç¼“å­˜æ–‡ä»¶")
    parser.add_argument("--clean-logs", type=int, default=7, help="æ¸…ç†Nå¤©å‰çš„æ—¥å¿—æ–‡ä»¶")
    parser.add_argument("--backup", action="store_true", help="å¤‡ä»½æŒä»“æ•°æ®")
    parser.add_argument("--stats", action="store_true", help="æ˜¾ç¤ºç›®å½•ç»Ÿè®¡ä¿¡æ¯")
    parser.add_argument("--migrate", action="store_true", help="è¿ç§»æ—§æ–‡ä»¶åˆ°æ–°ç›®å½•ç»“æ„")
    
    args = parser.parse_args()
    
    manager = DataManager()
    
    if args.init:
        manager.ensure_directories()
    
    if args.migrate:
        manager.migrate_old_files()
    
    if args.backup:
        manager.backup_portfolio()
    
    if args.clean_cache:
        manager.clean_old_cache(args.clean_cache)
    
    if args.clean_logs:
        manager.clean_old_logs(args.clean_logs)
    
    if args.stats:
        manager.print_stats()
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šä»»ä½•å‚æ•°ï¼Œæ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
    if not any(vars(args).values()):
        parser.print_help()
        print("\nğŸ“‹ å¸¸ç”¨å‘½ä»¤ç¤ºä¾‹:")
        print("python data_manager.py --init                    # åˆå§‹åŒ–ç›®å½•ç»“æ„")
        print("python data_manager.py --migrate                 # è¿ç§»æ—§æ–‡ä»¶")
        print("python data_manager.py --stats                   # æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯")
        print("python data_manager.py --backup                  # å¤‡ä»½æŒä»“æ•°æ®")
        print("python data_manager.py --clean-cache 30          # æ¸…ç†30å¤©å‰çš„ç¼“å­˜")
        print("python data_manager.py --clean-logs 7            # æ¸…ç†7å¤©å‰çš„æ—¥å¿—")

if __name__ == "__main__":
    main()
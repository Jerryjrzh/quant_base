# å¸¸è§é—®é¢˜è§£å†³æŒ‡å—

## ğŸš¨ é—®é¢˜åˆ†ç±»

### 1. æ•°æ®ç›¸å…³é—®é¢˜
### 2. ç­–ç•¥åˆ†æé—®é¢˜  
### 3. å›æµ‹ç³»ç»Ÿé—®é¢˜
### 4. å·¥ä½œæµæ‰§è¡Œé—®é¢˜
### 5. æ€§èƒ½é—®é¢˜
### 6. é…ç½®é—®é¢˜

---

## ğŸ“Š æ•°æ®ç›¸å…³é—®é¢˜

### é—®é¢˜1: æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ— æ³•è¯»å–

**ç—‡çŠ¶**:
```
FileNotFoundError: [Errno 2] No such file or directory: 'data/vipdoc/sh/000001.day'
```

**å¯èƒ½åŸå› **:
- æ•°æ®ç›®å½•è·¯å¾„é…ç½®é”™è¯¯
- æ•°æ®æ–‡ä»¶ç¼ºå¤±æˆ–æŸå
- æ–‡ä»¶æƒé™é—®é¢˜
- è‚¡ç¥¨ä»£ç æ ¼å¼é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:

1. **æ£€æŸ¥æ•°æ®ç›®å½•ç»“æ„**:
```bash
# æ£€æŸ¥æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨
ls -la data/vipdoc/

# åº”è¯¥çœ‹åˆ°å¦‚ä¸‹ç»“æ„:
# data/vipdoc/
# â”œâ”€â”€ sh/     # ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€
# â”œâ”€â”€ sz/     # æ·±åœ³è¯åˆ¸äº¤æ˜“æ‰€  
# â””â”€â”€ bj/     # åŒ—äº¬è¯åˆ¸äº¤æ˜“æ‰€
```

2. **éªŒè¯æ–‡ä»¶æƒé™**:
```bash
# æ£€æŸ¥æ–‡ä»¶æƒé™
ls -la data/vipdoc/sh/000001.day

# å¦‚æœæƒé™ä¸è¶³ï¼Œä¿®æ”¹æƒé™
chmod 644 data/vipdoc/sh/*.day
```

3. **ä½¿ç”¨è°ƒè¯•è„šæœ¬æ£€æŸ¥**:
```python
from backend.data_loader import DataLoader

loader = DataLoader()

# æ£€æŸ¥æ•°æ®ç›®å½•
print(f"æ•°æ®ç›®å½•: {loader.data_path}")
print(f"ç›®å½•å­˜åœ¨: {os.path.exists(loader.data_path)}")

# æ£€æŸ¥è‚¡ç¥¨åˆ—è¡¨
try:
    stock_list = loader.get_stock_list()
    print(f"æ‰¾åˆ° {len(stock_list)} åªè‚¡ç¥¨")
    print(f"å‰10åª: {stock_list[:10]}")
except Exception as e:
    print(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
```

4. **é…ç½®æ–‡ä»¶ä¿®æ­£**:
```python
# åœ¨ workflow_config.json ä¸­è®¾ç½®æ­£ç¡®çš„æ•°æ®è·¯å¾„
{
    "data": {
        "vipdoc_path": "/path/to/your/vipdoc/data",
        "cache_enabled": true,
        "cache_size_limit": 100
    }
}
```

### é—®é¢˜2: æ•°æ®æ ¼å¼é”™è¯¯æˆ–è§£æå¤±è´¥

**ç—‡çŠ¶**:
```
ValueError: could not convert string to float: 'invalid_data'
pandas.errors.ParserError: Error tokenizing data
```

**å¯èƒ½åŸå› **:
- æ•°æ®æ–‡ä»¶æ ¼å¼ä¸ç¬¦åˆé¢„æœŸ
- æ–‡ä»¶ç¼–ç é—®é¢˜
- æ•°æ®ä¸­åŒ…å«å¼‚å¸¸å­—ç¬¦
- æ–‡ä»¶æŸå

**è§£å†³æ–¹æ¡ˆ**:

1. **æ‰‹åŠ¨æ£€æŸ¥æ•°æ®æ ¼å¼**:
```python
# æ£€æŸ¥æ–‡ä»¶å‰å‡ è¡Œ
with open('data/vipdoc/sh/000001.day', 'r', encoding='utf-8') as f:
    for i, line in enumerate(f):
        if i < 5:  # åªçœ‹å‰5è¡Œ
            print(f"ç¬¬{i+1}è¡Œ: {repr(line)}")
```

2. **ä½¿ç”¨æ•°æ®éªŒè¯å·¥å…·**:
```python
from backend.data_loader import DataQualityMonitor

monitor = DataQualityMonitor()

# åŠ è½½å¹¶æ£€æŸ¥æ•°æ®è´¨é‡
try:
    df = loader.load_stock_data('000001')
    quality_report = monitor.check_data_quality(df, '000001')
    
    print(f"æ•°æ®è´¨é‡åˆ†æ•°: {quality_report['quality_score']}")
    for issue in quality_report['issues']:
        print(f"é—®é¢˜: {issue['type']} - {issue['count']}ä¸ª")
        
except Exception as e:
    print(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
```

3. **æ•°æ®ä¿®å¤è„šæœ¬**:
```python
def repair_data_file(file_path):
    """ä¿®å¤æŸåçš„æ•°æ®æ–‡ä»¶"""
    
    backup_path = file_path + '.backup'
    
    # å¤‡ä»½åŸæ–‡ä»¶
    shutil.copy2(file_path, backup_path)
    
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            lines = f.readlines()
        
        # æ¸…ç†æ•°æ®
        cleaned_lines = []
        for line in lines:
            # ç§»é™¤å¼‚å¸¸å­—ç¬¦
            cleaned_line = re.sub(r'[^\d\t\n.-]', '', line)
            if cleaned_line.strip():  # è·³è¿‡ç©ºè¡Œ
                cleaned_lines.append(cleaned_line)
        
        # å†™å›æ–‡ä»¶
        with open(file_path, 'w', encoding='utf-8') as f:
            f.writelines(cleaned_lines)
        
        print(f"æ–‡ä»¶ä¿®å¤å®Œæˆ: {file_path}")
        
    except Exception as e:
        # æ¢å¤å¤‡ä»½
        shutil.copy2(backup_path, file_path)
        print(f"ä¿®å¤å¤±è´¥ï¼Œå·²æ¢å¤å¤‡ä»½: {e}")
```

### é—®é¢˜3: æ•°æ®ç¼ºå¤±æˆ–ä¸å®Œæ•´

**ç—‡çŠ¶**:
```
Warning: 000001 æ•°æ®ä¸è¶³ï¼Œè·³è¿‡
Empty DataFrame: æ•°æ®ä¸ºç©º
```

**è§£å†³æ–¹æ¡ˆ**:

1. **æ£€æŸ¥æ•°æ®å®Œæ•´æ€§**:
```python
def check_data_completeness():
    """æ£€æŸ¥æ•°æ®å®Œæ•´æ€§"""
    
    loader = DataLoader()
    stock_list = loader.get_stock_list()
    
    incomplete_stocks = []
    
    for symbol in stock_list[:20]:  # æ£€æŸ¥å‰20åª
        try:
            df = loader.load_stock_data(symbol)
            
            if df.empty:
                incomplete_stocks.append((symbol, "æ•°æ®ä¸ºç©º"))
            elif len(df) < 30:
                incomplete_stocks.append((symbol, f"æ•°æ®ä¸è¶³: {len(df)}æ¡"))
            else:
                # æ£€æŸ¥æ—¥æœŸè¿ç»­æ€§
                date_gaps = check_date_gaps(df)
                if date_gaps > 10:
                    incomplete_stocks.append((symbol, f"æ—¥æœŸç¼ºå¤±: {date_gaps}å¤©"))
                    
        except Exception as e:
            incomplete_stocks.append((symbol, f"åŠ è½½å¤±è´¥: {str(e)}"))
    
    return incomplete_stocks
```

2. **æ•°æ®è¡¥å…¨ç­–ç•¥**:
```python
def fill_missing_data(df):
    """å¡«å……ç¼ºå¤±æ•°æ®"""
    
    # ä»·æ ¼æ•°æ®å‰å‘å¡«å……
    price_columns = ['open', 'high', 'low', 'close']
    df[price_columns] = df[price_columns].fillna(method='ffill')
    
    # æˆäº¤é‡ç”¨0å¡«å……
    df['volume'] = df['volume'].fillna(0)
    
    # æˆäº¤é¢æ ¹æ®ä»·æ ¼å’Œæˆäº¤é‡ä¼°ç®—
    df['amount'] = df['amount'].fillna(df['close'] * df['volume'])
    
    return df
```

---

## ğŸ¯ ç­–ç•¥åˆ†æé—®é¢˜

### é—®é¢˜4: æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å¼‚å¸¸

**ç—‡çŠ¶**:
```
RuntimeWarning: invalid value encountered in divide
ValueError: Input contains NaN, infinity or a value too large
```

**å¯èƒ½åŸå› **:
- æ•°æ®ä¸­åŒ…å«NaNå€¼
- é™¤é›¶é”™è¯¯
- æ•°æ®ç±»å‹ä¸åŒ¹é…
- è®¡ç®—å‚æ•°è®¾ç½®ä¸å½“

**è§£å†³æ–¹æ¡ˆ**:

1. **æ•°æ®é¢„å¤„ç†**:
```python
def safe_calculate_indicators(df):
    """å®‰å…¨çš„æŒ‡æ ‡è®¡ç®—"""
    
    # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
    if df.empty or len(df) < 30:
        raise ValueError("æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—æŒ‡æ ‡")
    
    # æ¸…ç†å¼‚å¸¸å€¼
    df = df.replace([np.inf, -np.inf], np.nan)
    df = df.fillna(method='ffill').fillna(method='bfill')
    
    # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
    numeric_columns = ['open', 'high', 'low', 'close', 'volume']
    for col in numeric_columns:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # è®¡ç®—æŒ‡æ ‡
    try:
        macd_data = calculate_macd(df)
        kdj_data = calculate_kdj(df)
        rsi_data = calculate_rsi(df)
        
        # æ£€æŸ¥ç»“æœ
        if macd_data.isnull().all().any():
            raise ValueError("MACDè®¡ç®—ç»“æœåŒ…å«å…¨éƒ¨NaN")
        
        return {
            'macd': macd_data,
            'kdj': kdj_data,
            'rsi': rsi_data
        }
        
    except Exception as e:
        logger.error(f"æŒ‡æ ‡è®¡ç®—å¤±è´¥: {str(e)}")
        raise
```

2. **å‚æ•°éªŒè¯**:
```python
def validate_indicator_params(params):
    """éªŒè¯æŒ‡æ ‡å‚æ•°"""
    
    errors = []
    
    # MACDå‚æ•°æ£€æŸ¥
    if 'macd' in params:
        macd_params = params['macd']
        if macd_params.get('fast_period', 12) >= macd_params.get('slow_period', 26):
            errors.append("MACDå¿«çº¿å‘¨æœŸå¿…é¡»å°äºæ…¢çº¿å‘¨æœŸ")
        
        if macd_params.get('signal_period', 9) <= 0:
            errors.append("MACDä¿¡å·çº¿å‘¨æœŸå¿…é¡»å¤§äº0")
    
    # KDJå‚æ•°æ£€æŸ¥
    if 'kdj' in params:
        kdj_params = params['kdj']
        if kdj_params.get('period', 27) <= 0:
            errors.append("KDJå‘¨æœŸå¿…é¡»å¤§äº0")
    
    # RSIå‚æ•°æ£€æŸ¥
    if 'rsi' in params:
        rsi_params = params['rsi']
        if rsi_params.get('period', 14) <= 1:
            errors.append("RSIå‘¨æœŸå¿…é¡»å¤§äº1")
    
    return errors
```

### é—®é¢˜5: ç­–ç•¥ä¿¡å·å¼‚å¸¸

**ç—‡çŠ¶**:
```
æ‰€æœ‰è‚¡ç¥¨éƒ½æ²¡æœ‰ä¿¡å·
ä¿¡å·å¼ºåº¦å¼‚å¸¸é«˜/ä½
ç­–ç•¥æ¡ä»¶åˆ¤æ–­é”™è¯¯
```

**è§£å†³æ–¹æ¡ˆ**:

1. **ç­–ç•¥è°ƒè¯•å·¥å…·**:
```python
def debug_strategy_logic(symbol, strategy_func, config):
    """è°ƒè¯•ç­–ç•¥é€»è¾‘"""
    
    loader = DataLoader()
    df = loader.load_stock_data(symbol)
    
    print(f"=== è°ƒè¯•ç­–ç•¥: {symbol} ===")
    print(f"æ•°æ®é•¿åº¦: {len(df)}")
    print(f"æ—¥æœŸèŒƒå›´: {df.index[0]} ~ {df.index[-1]}")
    
    # è®¡ç®—æŒ‡æ ‡
    indicators = safe_calculate_indicators(df)
    
    # æ˜¾ç¤ºæœ€æ–°æŒ‡æ ‡å€¼
    print("\næœ€æ–°æŒ‡æ ‡å€¼:")
    for name, data in indicators.items():
        if isinstance(data, pd.DataFrame):
            latest = data.iloc[-1]
            print(f"{name}: {latest.to_dict()}")
        else:
            print(f"{name}: {data.iloc[-1]}")
    
    # æ‰§è¡Œç­–ç•¥
    try:
        result = strategy_func(df, config)
        
        print(f"\nç­–ç•¥ç»“æœ:")
        print(f"ä¿¡å·: {result.get('signal', False)}")
        print(f"å¼ºåº¦: {result.get('strength', 0)}")
        print(f"æ¡ä»¶: {result.get('conditions', {})}")
        
        # åˆ†ææ¯ä¸ªæ¡ä»¶
        conditions = result.get('conditions', {})
        for condition, value in conditions.items():
            status = "âœ…" if value else "âŒ"
            print(f"  {status} {condition}: {value}")
        
    except Exception as e:
        print(f"ç­–ç•¥æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
```

2. **ä¿¡å·è´¨é‡æ£€æŸ¥**:
```python
def check_signal_quality(signals):
    """æ£€æŸ¥ä¿¡å·è´¨é‡"""
    
    if not signals:
        print("âš ï¸  æ²¡æœ‰ç”Ÿæˆä»»ä½•ä¿¡å·")
        return
    
    print(f"ğŸ“Š ä¿¡å·ç»Ÿè®¡:")
    print(f"æ€»ä¿¡å·æ•°: {len(signals)}")
    
    # å¼ºåº¦åˆ†å¸ƒ
    strengths = [s.get('strength', 0) for s in signals]
    print(f"å¼ºåº¦åˆ†å¸ƒ:")
    print(f"  å¹³å‡: {np.mean(strengths):.1f}")
    print(f"  æœ€å¤§: {np.max(strengths):.1f}")
    print(f"  æœ€å°: {np.min(strengths):.1f}")
    
    # ç­–ç•¥åˆ†å¸ƒ
    strategies = {}
    for signal in signals:
        strategy = signal.get('strategy', 'UNKNOWN')
        strategies[strategy] = strategies.get(strategy, 0) + 1
    
    print(f"ç­–ç•¥åˆ†å¸ƒ:")
    for strategy, count in strategies.items():
        print(f"  {strategy}: {count}")
    
    # è´¨é‡åˆ†æ•°åˆ†å¸ƒ
    quality_scores = [s.get('quality_score', 0) for s in signals if 'quality_score' in s]
    if quality_scores:
        print(f"è´¨é‡åˆ†æ•°:")
        print(f"  å¹³å‡: {np.mean(quality_scores):.1f}")
        print(f"  >70åˆ†: {sum(1 for s in quality_scores if s > 70)}")
```

---

## ğŸ”„ å›æµ‹ç³»ç»Ÿé—®é¢˜

### é—®é¢˜6: å›æµ‹ç»“æœå¼‚å¸¸

**ç—‡çŠ¶**:
```
æ”¶ç›Šç‡å¼‚å¸¸é«˜ (>1000%)
å¤æ™®æ¯”ç‡ä¸ºè´Ÿæ•°æˆ–å¼‚å¸¸å€¼
äº¤æ˜“æ¬¡æ•°ä¸º0
æœ€å¤§å›æ’¤è¶…è¿‡100%
```

**è§£å†³æ–¹æ¡ˆ**:

1. **å›æµ‹å‚æ•°éªŒè¯**:
```python
def validate_backtest_params(params):
    """éªŒè¯å›æµ‹å‚æ•°"""
    
    issues = []
    
    # æ£€æŸ¥åˆå§‹èµ„é‡‘
    initial_capital = params.get('initial_capital', 100000)
    if initial_capital <= 0:
        issues.append("åˆå§‹èµ„é‡‘å¿…é¡»å¤§äº0")
    
    # æ£€æŸ¥æ‰‹ç»­è´¹ç‡
    commission_rate = params.get('commission_rate', 0.0003)
    if commission_rate < 0 or commission_rate > 0.01:
        issues.append("æ‰‹ç»­è´¹ç‡å¼‚å¸¸")
    
    # æ£€æŸ¥æœ€å¤§ä»“ä½
    max_position = params.get('max_position_size', 0.2)
    if max_position <= 0 or max_position > 1:
        issues.append("æœ€å¤§ä»“ä½è®¾ç½®å¼‚å¸¸")
    
    return issues
```

2. **å›æµ‹ç»“æœéªŒè¯**:
```python
def validate_backtest_results(result):
    """éªŒè¯å›æµ‹ç»“æœ"""
    
    performance = result.get('performance', {})
    
    warnings = []
    
    # æ£€æŸ¥æ”¶ç›Šç‡
    total_return = performance.get('total_return', 0)
    if abs(total_return) > 5:  # æ”¶ç›Šç‡è¶…è¿‡500%
        warnings.append(f"æ”¶ç›Šç‡å¼‚å¸¸: {total_return:.2%}")
    
    # æ£€æŸ¥å¤æ™®æ¯”ç‡
    sharpe_ratio = performance.get('sharpe_ratio', 0)
    if sharpe_ratio < -2 or sharpe_ratio > 5:
        warnings.append(f"å¤æ™®æ¯”ç‡å¼‚å¸¸: {sharpe_ratio:.2f}")
    
    # æ£€æŸ¥æœ€å¤§å›æ’¤
    max_drawdown = performance.get('max_drawdown', 0)
    if max_drawdown > 1:
        warnings.append(f"æœ€å¤§å›æ’¤å¼‚å¸¸: {max_drawdown:.2%}")
    
    # æ£€æŸ¥äº¤æ˜“æ¬¡æ•°
    total_trades = performance.get('total_trades', 0)
    if total_trades == 0:
        warnings.append("æ²¡æœ‰æ‰§è¡Œä»»ä½•äº¤æ˜“")
    
    return warnings
```

3. **å›æµ‹ä¿®å¤å·¥å…·**:
```python
def fix_backtest_issues(backtest_system):
    """ä¿®å¤å›æµ‹é—®é¢˜"""
    
    # é‡ç½®å¼‚å¸¸çŠ¶æ€
    if backtest_system.current_cash < 0:
        logger.warning("ç°é‡‘ä¸ºè´Ÿï¼Œé‡ç½®ä¸ºåˆå§‹èµ„é‡‘çš„10%")
        backtest_system.current_cash = backtest_system.initial_capital * 0.1
    
    # æ¸…ç†å¼‚å¸¸æŒä»“
    invalid_positions = []
    for symbol, position in backtest_system.positions.items():
        if position.get('shares', 0) <= 0:
            invalid_positions.append(symbol)
    
    for symbol in invalid_positions:
        del backtest_system.positions[symbol]
        logger.warning(f"æ¸…ç†å¼‚å¸¸æŒä»“: {symbol}")
    
    # éªŒè¯äº¤æ˜“å†å²
    valid_trades = []
    for trade in backtest_system.trade_history:
        if (trade.get('price', 0) > 0 and 
            trade.get('shares', 0) > 0):
            valid_trades.append(trade)
    
    backtest_system.trade_history = valid_trades
```

---

## ğŸ”„ å·¥ä½œæµæ‰§è¡Œé—®é¢˜

### é—®é¢˜7: å·¥ä½œæµé˜¶æ®µæ‰§è¡Œå¤±è´¥

**ç—‡çŠ¶**:
```
Phase1æ‰§è¡Œå¤±è´¥: å‚æ•°ä¼˜åŒ–è¶…æ—¶
Phase2æ‰§è¡Œå¤±è´¥: æ ¸å¿ƒè§‚å¯Ÿæ± ä¸ºç©º
Phase3æ‰§è¡Œå¤±è´¥: å†å²æ•°æ®ä¸è¶³
```

**è§£å†³æ–¹æ¡ˆ**:

1. **é˜¶æ®µä¾èµ–æ£€æŸ¥**:
```python
def check_phase_dependencies():
    """æ£€æŸ¥é˜¶æ®µä¾èµ–"""
    
    issues = []
    
    # Phase1ä¾èµ–æ£€æŸ¥
    if not os.path.exists('data/vipdoc'):
        issues.append("Phase1: æ•°æ®ç›®å½•ä¸å­˜åœ¨")
    
    # Phase2ä¾èµ–æ£€æŸ¥
    if not os.path.exists('core_stock_pool.json'):
        issues.append("Phase2: æ ¸å¿ƒè§‚å¯Ÿæ± æ–‡ä»¶ä¸å­˜åœ¨")
    else:
        try:
            with open('core_stock_pool.json', 'r') as f:
                pool = json.load(f)
                if not pool.get('stocks'):
                    issues.append("Phase2: æ ¸å¿ƒè§‚å¯Ÿæ± ä¸ºç©º")
        except:
            issues.append("Phase2: æ ¸å¿ƒè§‚å¯Ÿæ± æ–‡ä»¶æŸå")
    
    # Phase3ä¾èµ–æ£€æŸ¥
    reports_dir = 'reports'
    if not os.path.exists(reports_dir):
        issues.append("Phase3: æŠ¥å‘Šç›®å½•ä¸å­˜åœ¨")
    else:
        signal_files = [f for f in os.listdir(reports_dir) if f.startswith('daily_signals_')]
        if not signal_files:
            issues.append("Phase3: æ²¡æœ‰å†å²äº¤æ˜“ä¿¡å·")
    
    return issues
```

2. **å·¥ä½œæµæ¢å¤æœºåˆ¶**:
```python
def recover_workflow_state():
    """æ¢å¤å·¥ä½œæµçŠ¶æ€"""
    
    recovery_actions = []
    
    # æ£€æŸ¥å¹¶åˆ›å»ºå¿…è¦ç›®å½•
    required_dirs = ['reports', 'logs', 'cache']
    for dir_name in required_dirs:
        if not os.path.exists(dir_name):
            os.makedirs(dir_name)
            recovery_actions.append(f"åˆ›å»ºç›®å½•: {dir_name}")
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if not os.path.exists('workflow_config.json'):
        # åˆ›å»ºé»˜è®¤é…ç½®
        default_config = get_default_workflow_config()
        with open('workflow_config.json', 'w') as f:
            json.dump(default_config, f, indent=2)
        recovery_actions.append("åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶")
    
    # æ£€æŸ¥æ ¸å¿ƒè§‚å¯Ÿæ± 
    if not os.path.exists('core_stock_pool.json'):
        # è§¦å‘Phase1æ‰§è¡Œ
        recovery_actions.append("éœ€è¦æ‰§è¡ŒPhase1ç”Ÿæˆæ ¸å¿ƒè§‚å¯Ÿæ± ")
    
    return recovery_actions
```

### é—®é¢˜8: é…ç½®æ–‡ä»¶é—®é¢˜

**ç—‡çŠ¶**:
```
ConfigError: é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯
KeyError: 'phases' key not found
ValueError: æ— æ•ˆçš„é…ç½®å€¼
```

**è§£å†³æ–¹æ¡ˆ**:

1. **é…ç½®éªŒè¯å·¥å…·**:
```python
def validate_config_file(config_path):
    """éªŒè¯é…ç½®æ–‡ä»¶"""
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
    except json.JSONDecodeError as e:
        return {'valid': False, 'error': f'JSONæ ¼å¼é”™è¯¯: {str(e)}'}
    except FileNotFoundError:
        return {'valid': False, 'error': 'é…ç½®æ–‡ä»¶ä¸å­˜åœ¨'}
    
    # æ£€æŸ¥å¿…è¦çš„é…ç½®é¡¹
    required_keys = ['phases', 'logging']
    missing_keys = [key for key in required_keys if key not in config]
    
    if missing_keys:
        return {'valid': False, 'error': f'ç¼ºå°‘å¿…è¦é…ç½®é¡¹: {missing_keys}'}
    
    # æ£€æŸ¥é˜¶æ®µé…ç½®
    phases = config.get('phases', {})
    required_phases = ['phase1', 'phase2', 'phase3']
    missing_phases = [phase for phase in required_phases if phase not in phases]
    
    if missing_phases:
        return {'valid': False, 'error': f'ç¼ºå°‘é˜¶æ®µé…ç½®: {missing_phases}'}
    
    # æ£€æŸ¥é¢‘ç‡è®¾ç½®
    for phase_name, phase_config in phases.items():
        frequency = phase_config.get('frequency_hours')
        if frequency is None or frequency <= 0:
            return {'valid': False, 'error': f'{phase_name}é¢‘ç‡è®¾ç½®æ— æ•ˆ'}
    
    return {'valid': True}
```

2. **é…ç½®ä¿®å¤å·¥å…·**:
```python
def repair_config_file(config_path):
    """ä¿®å¤é…ç½®æ–‡ä»¶"""
    
    # å¤‡ä»½åŸæ–‡ä»¶
    backup_path = config_path + '.backup'
    if os.path.exists(config_path):
        shutil.copy2(config_path, backup_path)
    
    # åŠ è½½é»˜è®¤é…ç½®
    default_config = get_default_workflow_config()
    
    # å°è¯•åˆå¹¶ç°æœ‰é…ç½®
    if os.path.exists(config_path):
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                existing_config = json.load(f)
            
            # é€’å½’åˆå¹¶é…ç½®
            merged_config = merge_configs(default_config, existing_config)
            
        except:
            merged_config = default_config
    else:
        merged_config = default_config
    
    # ä¿å­˜ä¿®å¤åçš„é…ç½®
    with open(config_path, 'w', encoding='utf-8') as f:
        json.dump(merged_config, f, indent=2, ensure_ascii=False)
    
    print(f"é…ç½®æ–‡ä»¶å·²ä¿®å¤: {config_path}")
    if os.path.exists(backup_path):
        print(f"åŸæ–‡ä»¶å¤‡ä»½: {backup_path}")
```

---

## âš¡ æ€§èƒ½é—®é¢˜

### é—®é¢˜9: ç³»ç»Ÿè¿è¡Œç¼“æ…¢

**ç—‡çŠ¶**:
```
æ•°æ®åŠ è½½è€—æ—¶è¿‡é•¿
ç­–ç•¥åˆ†æè¶…æ—¶
å†…å­˜ä½¿ç”¨è¿‡é«˜
CPUå ç”¨ç‡100%
```

**è§£å†³æ–¹æ¡ˆ**:

1. **æ€§èƒ½ç›‘æ§å·¥å…·**:
```python
import psutil
import time
from functools import wraps

def monitor_performance(func):
    """æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
    
    @wraps(func)
    def wrapper(*args, **kwargs):
        # è®°å½•å¼€å§‹çŠ¶æ€
        start_time = time.time()
        start_memory = psutil.Process().memory_info().rss / 1024 / 1024
        start_cpu = psutil.cpu_percent()
        
        try:
            result = func(*args, **kwargs)
            
            # è®°å½•ç»“æŸçŠ¶æ€
            end_time = time.time()
            end_memory = psutil.Process().memory_info().rss / 1024 / 1024
            end_cpu = psutil.cpu_percent()
            
            # è¾“å‡ºæ€§èƒ½ç»Ÿè®¡
            print(f"ğŸ” æ€§èƒ½ç»Ÿè®¡ - {func.__name__}")
            print(f"  æ‰§è¡Œæ—¶é—´: {end_time - start_time:.2f}ç§’")
            print(f"  å†…å­˜å˜åŒ–: {end_memory - start_memory:+.1f}MB")
            print(f"  CPUä½¿ç”¨: {end_cpu:.1f}%")
            
            return result
            
        except Exception as e:
            print(f"âŒ å‡½æ•°æ‰§è¡Œå¤±è´¥: {func.__name__} - {str(e)}")
            raise
    
    return wrapper
```

2. **ç¼“å­˜ä¼˜åŒ–**:
```python
def optimize_data_cache():
    """ä¼˜åŒ–æ•°æ®ç¼“å­˜"""
    
    from backend.data_loader import DataLoader
    
    loader = DataLoader()
    
    # æ£€æŸ¥ç¼“å­˜çŠ¶æ€
    cache_stats = loader.cache_manager.get_stats()
    print(f"ç¼“å­˜ç»Ÿè®¡:")
    print(f"  ç¼“å­˜å¤§å°: {cache_stats['cache_size']}/{cache_stats['max_size']}")
    print(f"  å†…å­˜ä½¿ç”¨: {cache_stats['memory_usage_mb']:.1f}MB")
    print(f"  å‘½ä¸­ç‡: {cache_stats['hit_rate']:.2%}")
    
    # å¦‚æœå†…å­˜ä½¿ç”¨è¿‡é«˜ï¼Œæ¸…ç†ç¼“å­˜
    if cache_stats['memory_usage_mb'] > 500:  # è¶…è¿‡500MB
        print("å†…å­˜ä½¿ç”¨è¿‡é«˜ï¼Œæ¸…ç†ç¼“å­˜...")
        loader.cache_manager.clear()
        print("ç¼“å­˜å·²æ¸…ç†")
```

3. **å¹¶è¡Œå¤„ç†ä¼˜åŒ–**:
```python
def optimize_parallel_processing():
    """ä¼˜åŒ–å¹¶è¡Œå¤„ç†"""
    
    import multiprocessing as mp
    
    # æ£€æŸ¥CPUæ ¸å¿ƒæ•°
    cpu_count = mp.cpu_count()
    print(f"CPUæ ¸å¿ƒæ•°: {cpu_count}")
    
    # æ¨èçš„å·¥ä½œè¿›ç¨‹æ•°
    recommended_workers = max(1, cpu_count - 1)
    print(f"æ¨èå·¥ä½œè¿›ç¨‹æ•°: {recommended_workers}")
    
    # æ£€æŸ¥å†…å­˜é™åˆ¶
    memory_gb = psutil.virtual_memory().total / 1024 / 1024 / 1024
    print(f"ç³»ç»Ÿå†…å­˜: {memory_gb:.1f}GB")
    
    # æ ¹æ®å†…å­˜è°ƒæ•´è¿›ç¨‹æ•°
    if memory_gb < 8:
        recommended_workers = min(recommended_workers, 2)
        print("å†…å­˜ä¸è¶³ï¼Œå»ºè®®å‡å°‘å¹¶è¡Œè¿›ç¨‹æ•°")
    
    return recommended_workers
```

---

## ğŸ› ï¸ ç»¼åˆè¯Šæ–­å·¥å…·

### ç³»ç»Ÿå¥åº·æ£€æŸ¥
```python
def system_health_check():
    """ç³»ç»Ÿå¥åº·æ£€æŸ¥"""
    
    print("ğŸ¥ ç³»ç»Ÿå¥åº·æ£€æŸ¥")
    print("=" * 50)
    
    health_score = 100
    issues = []
    
    # 1. æ•°æ®æ£€æŸ¥
    try:
        loader = DataLoader()
        stock_list = loader.get_stock_list()
        if len(stock_list) > 0:
            print("âœ… æ•°æ®ç³»ç»Ÿ: æ­£å¸¸")
        else:
            print("âŒ æ•°æ®ç³»ç»Ÿ: æ— è‚¡ç¥¨æ•°æ®")
            health_score -= 30
            issues.append("æ•°æ®ç³»ç»Ÿå¼‚å¸¸")
    except Exception as e:
        print(f"âŒ æ•°æ®ç³»ç»Ÿ: {str(e)}")
        health_score -= 30
        issues.append("æ•°æ®ç³»ç»Ÿå¼‚å¸¸")
    
    # 2. é…ç½®æ£€æŸ¥
    config_validation = validate_config_file('workflow_config.json')
    if config_validation['valid']:
        print("âœ… é…ç½®ç³»ç»Ÿ: æ­£å¸¸")
    else:
        print(f"âŒ é…ç½®ç³»ç»Ÿ: {config_validation['error']}")
        health_score -= 20
        issues.append("é…ç½®ç³»ç»Ÿå¼‚å¸¸")
    
    # 3. å·¥ä½œæµæ£€æŸ¥
    dependency_issues = check_phase_dependencies()
    if not dependency_issues:
        print("âœ… å·¥ä½œæµç³»ç»Ÿ: æ­£å¸¸")
    else:
        print("âŒ å·¥ä½œæµç³»ç»Ÿ: å­˜åœ¨ä¾èµ–é—®é¢˜")
        for issue in dependency_issues:
            print(f"  - {issue}")
        health_score -= 25
        issues.append("å·¥ä½œæµç³»ç»Ÿå¼‚å¸¸")
    
    # 4. æ€§èƒ½æ£€æŸ¥
    memory_usage = psutil.virtual_memory().percent
    cpu_usage = psutil.cpu_percent(interval=1)
    
    if memory_usage < 80 and cpu_usage < 80:
        print("âœ… ç³»ç»Ÿæ€§èƒ½: æ­£å¸¸")
    else:
        print(f"âš ï¸  ç³»ç»Ÿæ€§èƒ½: å†…å­˜{memory_usage:.1f}% CPU{cpu_usage:.1f}%")
        if memory_usage > 90 or cpu_usage > 90:
            health_score -= 15
            issues.append("ç³»ç»Ÿæ€§èƒ½å¼‚å¸¸")
    
    # 5. ç£ç›˜ç©ºé—´æ£€æŸ¥
    disk_usage = psutil.disk_usage('.').percent
    if disk_usage < 90:
        print("âœ… ç£ç›˜ç©ºé—´: æ­£å¸¸")
    else:
        print(f"âš ï¸  ç£ç›˜ç©ºé—´: {disk_usage:.1f}%å·²ä½¿ç”¨")
        health_score -= 10
        issues.append("ç£ç›˜ç©ºé—´ä¸è¶³")
    
    # æ€»ç»“
    print("\n" + "=" * 50)
    print(f"ğŸ¯ ç³»ç»Ÿå¥åº·è¯„åˆ†: {health_score}/100")
    
    if health_score >= 90:
        print("ğŸŸ¢ ç³»ç»ŸçŠ¶æ€: ä¼˜ç§€")
    elif health_score >= 70:
        print("ğŸŸ¡ ç³»ç»ŸçŠ¶æ€: è‰¯å¥½")
    elif health_score >= 50:
        print("ğŸŸ  ç³»ç»ŸçŠ¶æ€: ä¸€èˆ¬")
    else:
        print("ğŸ”´ ç³»ç»ŸçŠ¶æ€: éœ€è¦ç»´æŠ¤")
    
    if issues:
        print("\nğŸ”§ éœ€è¦è§£å†³çš„é—®é¢˜:")
        for i, issue in enumerate(issues, 1):
            print(f"  {i}. {issue}")
    
    return {
        'health_score': health_score,
        'issues': issues,
        'status': 'healthy' if health_score >= 70 else 'needs_attention'
    }

# è¿è¡Œç³»ç»Ÿå¥åº·æ£€æŸ¥
if __name__ == "__main__":
    system_health_check()
```

### ä¸€é”®ä¿®å¤å·¥å…·
```python
def auto_fix_system():
    """ä¸€é”®ä¿®å¤ç³»ç»Ÿé—®é¢˜"""
    
    print("ğŸ”§ å¼€å§‹è‡ªåŠ¨ä¿®å¤...")
    
    fixed_issues = []
    
    # 1. ä¿®å¤é…ç½®æ–‡ä»¶
    try:
        repair_config_file('workflow_config.json')
        fixed_issues.append("é…ç½®æ–‡ä»¶å·²ä¿®å¤")
    except Exception as e:
        print(f"é…ç½®æ–‡ä»¶ä¿®å¤å¤±è´¥: {e}")
    
    # 2. æ¢å¤å·¥ä½œæµçŠ¶æ€
    try:
        recovery_actions = recover_workflow_state()
        fixed_issues.extend(recovery_actions)
    except Exception as e:
        print(f"å·¥ä½œæµçŠ¶æ€æ¢å¤å¤±è´¥: {e}")
    
    # 3. æ¸…ç†ç¼“å­˜
    try:
        optimize_data_cache()
        fixed_issues.append("ç¼“å­˜å·²ä¼˜åŒ–")
    except Exception as e:
        print(f"ç¼“å­˜ä¼˜åŒ–å¤±è´¥: {e}")
    
    # 4. åˆ›å»ºå¿…è¦ç›®å½•
    required_dirs = ['reports', 'logs', 'cache', 'backups']
    for dir_name in required_dirs:
        if not os.path.exists(dir_name):
            os.makedirs(dir_name)
            fixed_issues.append(f"åˆ›å»ºç›®å½•: {dir_name}")
    
    print(f"\nâœ… ä¿®å¤å®Œæˆï¼Œå…±è§£å†³ {len(fixed_issues)} ä¸ªé—®é¢˜:")
    for issue in fixed_issues:
        print(f"  - {issue}")
    
    # é‡æ–°æ£€æŸ¥ç³»ç»Ÿå¥åº·çŠ¶æ€
    print("\nğŸ”„ é‡æ–°æ£€æŸ¥ç³»ç»ŸçŠ¶æ€...")
    health_result = system_health_check()
    
    return health_result

# ä½¿ç”¨æ–¹æ³•
if __name__ == "__main__":
    # å…ˆæ£€æŸ¥ç³»ç»ŸçŠ¶æ€
    health_result = system_health_check()
    
    # å¦‚æœæœ‰é—®é¢˜ï¼Œå°è¯•è‡ªåŠ¨ä¿®å¤
    if health_result['status'] == 'needs_attention':
        print("\næ£€æµ‹åˆ°ç³»ç»Ÿé—®é¢˜ï¼Œå¼€å§‹è‡ªåŠ¨ä¿®å¤...")
        auto_fix_system()
```

è¿™ä¸ªæ•…éšœæ’é™¤æŒ‡å—æ¶µç›–äº†ç³»ç»Ÿè¿è¡Œä¸­å¯èƒ½é‡åˆ°çš„ä¸»è¦é—®é¢˜ï¼Œæä¾›äº†è¯¦ç»†çš„è¯Šæ–­æ–¹æ³•å’Œè§£å†³æ–¹æ¡ˆã€‚é€šè¿‡ç³»ç»ŸåŒ–çš„é—®é¢˜åˆ†ç±»å’Œè‡ªåŠ¨åŒ–çš„ä¿®å¤å·¥å…·ï¼Œå¯ä»¥å¿«é€Ÿå®šä½å’Œè§£å†³å¤§éƒ¨åˆ†å¸¸è§é—®é¢˜ã€‚
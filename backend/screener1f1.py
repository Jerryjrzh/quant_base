import os
import glob
import json
import pandas as pd
import numpy as np
from multiprocessing import Pool, cpu_count
from datetime import datetime
import logging
import data_loader
import strategies
import backtester
import indicators
from win_rate_filter import WinRateFilter, AdvancedTripleCrossFilter
import talib

# === æœ€ç»ˆä¼˜åŒ–åçš„ç­–ç•¥é€»è¾‘ START ===
# è¿™æ˜¯ç»è¿‡é‡æ„çš„ã€é€»è¾‘æ›´ä¸¥è°¨ã€æ›´æœ‰æ•ˆçš„ä»·å€¼åè½¬ç­–ç•¥
def apply_value_reversal_final(df):
    """
    ä»·å€¼åè½¬ç­–ç•¥ (VALUE_REVERSAL) - æœ€ç»ˆä¼˜åŒ–ç‰ˆ
    æ ¸å¿ƒé€»è¾‘ï¼šå¯»æ‰¾â€œMACDåº•èƒŒç¦»â€è¿™ä¸€æ ¸å¿ƒå½¢æ€ï¼Œå¹¶ç”±â€œRSIåå¼¹â€æˆ–â€œå‡çº¿çªç ´â€æ¥ç¡®è®¤ã€‚

    - ä¿¡å·A (æ ¸å¿ƒ): MACDåº•èƒŒç¦» - ä»·æ ¼åœ¨è¿‘æœŸä½ä½ï¼Œä½†MACDæŒ‡æ ‡å½¢æˆæ›´é«˜ä½ç‚¹ã€‚
    - ä¿¡å·B (ç¡®è®¤): RSIè¶…å–åå¼¹ - RSIä»40ä»¥ä¸‹çš„ä½ä½åŒºå›å‡ã€‚
    - ä¿¡å·C (ç¡®è®¤): åŠ¨é‡ç‚¹ç« - ä»·æ ¼æ”¾é‡çªç ´20æ—¥å‡çº¿ã€‚

    è§¦å‘æ¡ä»¶ï¼š(ä¿¡å·A ä¸” (ä¿¡å·B æˆ– ä¿¡å·C)) æˆ– (ä¿¡å·B ä¸” ä¿¡å·C)
    """
    if len(df) < 60:
        return None

    try:
        # ç»Ÿä¸€è®¡ç®—æ‰€éœ€æŒ‡æ ‡
        df['ma20'] = talib.MA(df['close'], timeperiod=20)
        df['volume_ma20'] = df['volume'].rolling(window=20).mean()
        macd, signal, _ = talib.MACD(df['close'], fastperiod=12, slowperiod=26, signalperiod=9)
        df['macd'] = macd
        df['rsi'] = talib.RSI(df['close'], timeperiod=14)

        signal_series = pd.Series(False, index=df.index)
        
        # åªæ£€æŸ¥æœ€åä¸€ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®
        current_idx = -1
        if pd.isna(df.iloc[current_idx]).any() or pd.isna(df.iloc[current_idx-1]).any():
            return None # å¦‚æœæ•°æ®ä¸å®Œæ•´åˆ™è·³è¿‡

        current_data = df.iloc[current_idx]
        prev_data = df.iloc[current_idx - 1]

        # --- åˆå§‹åŒ–ä¿¡å· ---
        signal_A = False # MACDåº•èƒŒç¦»
        signal_B = False # RSIåå¼¹
        signal_C = False # åŠ¨é‡ç‚¹ç«

        # --- ä¿¡å·A: å‡†ç¡®çš„MACDåº•èƒŒç¦»æ£€æµ‹ ---
        lookback_period = 60
        recent_data = df.iloc[-lookback_period:]
        price_trough_date = recent_data['close'].idxmin()
        
        # åªæœ‰å½“æœ€ä½ç‚¹ä¸æ˜¯ä»Šå¤©æˆ–æ˜¨å¤©æ—¶ï¼ŒèƒŒç¦»æ‰æœ‰æ„ä¹‰
        if (df.index[current_idx] - price_trough_date).days > 2:
            macd_at_trough = df.loc[price_trough_date]['macd']
            # æ¡ä»¶ï¼šå½“å‰ä»·æ ¼ä»æ¥è¿‘å‰æœŸä½ç‚¹ï¼Œä½†MACDå·²æ˜¾è‘—æŠ¬é«˜
            if current_data['close'] < df.loc[price_trough_date]['close'] * 1.15 and current_data['macd'] > macd_at_trough:
                # è¿›ä¸€æ­¥ç¡®è®¤MACDæ˜¯ä¸Šå‡çš„
                if macd_at_trough < 0 and current_data['macd'] > macd_at_trough * 0.5: # å¦‚æœåœ¨æ°´ä¸‹ï¼Œè¦æ±‚åå¼¹æ›´å¤š
                     signal_A = True
                elif macd_at_trough >= 0:
                     signal_A = True

        # --- ä¿¡å·B: RSIè¶…å–åŒºåå¼¹ ---
        if prev_data['rsi'] < 40 and current_data['rsi'] > prev_data['rsi']:
            signal_B = True
            
        # --- ä¿¡å·C: æ”¾é‡çªç ´MA20 ---
        if (prev_data['close'] < prev_data['ma20'] and 
            current_data['close'] > current_data['ma20'] and 
            current_data['volume'] > current_data['volume_ma20'] * 1.5):
            signal_C = True

        # --- æœ€ç»ˆä¿¡å·å†³ç­– ---
        # è§„åˆ™1: å‡ºç°åº•èƒŒç¦»ï¼Œå¹¶ä¸”æœ‰ä»»ä¸€åŠ¨é‡ä¿¡å·ç¡®è®¤
        if signal_A and (signal_B or signal_C):
            signal_series.iloc[current_idx] = True
        
        # è§„åˆ™2: æ²¡æœ‰æ˜æ˜¾èƒŒç¦»ï¼Œä½†æ˜¯RSIå’ŒMAçªç ´ä¿¡å·åŒæ—¶å‡ºç°ï¼Œå½¢æˆå¼ºåŠ›åè½¬
        if signal_B and signal_C:
            signal_series.iloc[current_idx] = True
            
        return signal_series

    except Exception as e:
        return None

# å°†æœ€ç»ˆçš„ç­–ç•¥å‡½æ•°æ³¨å†Œåˆ° strategies æ¨¡å—ï¼ˆæ¨¡æ‹Ÿï¼‰
strategies.apply_value_reversal_strategy = apply_value_reversal_final
# === æœ€ç»ˆä¼˜åŒ–åçš„ç­–ç•¥é€»è¾‘ END ===


# --- é…ç½® ---
BASE_PATH = os.path.expanduser("~/.local/share/tdxcfv/drive_c/tc/vipdoc")
MARKETS = ['sh', 'sz', 'bj']
# --- æ‚¨å¯ä»¥åœ¨è¿™é‡Œåˆ‡æ¢è¦è¿è¡Œçš„ç­–ç•¥ ---
#STRATEGY_TO_RUN = 'MACD_ZERO_AXIS' 
#STRATEGY_TO_RUN = 'TRIPLE_CROSS' 
#STRATEGY_TO_RUN = 'PRE_CROSS'
#STRATEGY_TO_RUN = 'WEEKLY_GOLDEN_CROSS_MA'
STRATEGY_TO_RUN = 'VALUE_REVERSAL' # <--- è¿è¡Œæˆ‘ä»¬æœ€ç»ˆä¼˜åŒ–çš„ç­–ç•¥

# --- è·¯å¾„å®šä¹‰ ---
backend_dir = os.path.dirname(os.path.abspath(__file__))
OUTPUT_PATH = os.path.abspath(os.path.join(backend_dir, '..', 'data', 'result'))

# --- åˆå§‹åŒ–æ—¥å¿— ---
DATE = datetime.now().strftime("%Y%m%d_%H%M")
RESULT_DIR = os.path.join(OUTPUT_PATH, STRATEGY_TO_RUN)
os.makedirs(RESULT_DIR, exist_ok=True)
LOG_FILE = os.path.join(RESULT_DIR, f'log_screener_{DATE}.txt')

file_handler = logging.FileHandler(LOG_FILE, 'a', 'utf-8')
file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
logger = logging.getLogger('screener_logger')
logger.setLevel(logging.INFO)
if logger.hasHandlers():
    logger.handlers.clear()
logger.addHandler(file_handler)

def calculate_backtest_stats(df, signal_series):
    """è®¡ç®—ç»†åŒ–çš„å›æµ‹ç»Ÿè®¡ä¿¡æ¯"""
    try:
        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ˆå›æµ‹éœ€è¦ï¼‰
        macd_values = indicators.calculate_macd(df)
        df['dif'], df['dea'] = macd_values[0], macd_values[1]
        kdj_values = indicators.calculate_kdj(df)
        df['k'], df['d'], df['j'] = kdj_values[0], kdj_values[1], kdj_values[2]
        
        # æ‰§è¡Œç»†åŒ–å›æµ‹
        backtest_results = backtester.run_backtest(df, signal_series)
        
        if isinstance(backtest_results, dict) and backtest_results.get('total_signals', 0) > 0:
            stats = {
                'total_signals': backtest_results.get('total_signals', 0),
                'win_rate': backtest_results.get('win_rate', '0.0%'),
                'avg_max_profit': backtest_results.get('avg_max_profit', '0.0%'),
                'avg_max_drawdown': backtest_results.get('avg_max_drawdown', '0.0%'),
                'avg_days_to_peak': backtest_results.get('avg_days_to_peak', '0.0 å¤©')
            }
            
            # æ·»åŠ å„çŠ¶æ€ç»Ÿè®¡ä¿¡æ¯
            if 'state_statistics' in backtest_results:
                stats['state_statistics'] = backtest_results['state_statistics']
            
            # æ·»åŠ è¯¦ç»†äº¤æ˜“ä¿¡æ¯ï¼ˆç”¨äºè¿›ä¸€æ­¥åˆ†æï¼‰
            if 'trades' in backtest_results:
                # è®¡ç®—ä¸€äº›é¢å¤–çš„ç»Ÿè®¡æŒ‡æ ‡
                trades = backtest_results['trades']
                if trades:
                    # æœ€ä½³è¡¨ç°äº¤æ˜“
                    best_trade = max(trades, key=lambda x: x['actual_max_pnl'])
                    worst_trade = min(trades, key=lambda x: x['actual_max_pnl'])
                    
                    stats.update({
                        'best_trade_profit': f"{best_trade['actual_max_pnl']:.1%}",
                        'worst_trade_profit': f"{worst_trade['actual_max_pnl']:.1%}",
                        'avg_entry_strategy': get_most_common_entry_strategy(trades)
                    })
            
            return stats
        else:
            return {
                'total_signals': 0,
                'win_rate': '0.0%',
                'avg_max_profit': '0.0%',
                'avg_max_drawdown': '0.0%',
                'avg_days_to_peak': '0.0 å¤©'
            }
    except Exception as e:
        logger.error(f"å›æµ‹è®¡ç®—å¤±è´¥: {e}")
        return {
            'total_signals': 0,
            'win_rate': '0.0%',
            'avg_max_profit': '0.0%',
            'avg_max_drawdown': '0.0%',
            'avg_days_to_peak': '0.0 å¤©'
        }

def get_most_common_entry_strategy(trades):
    """è·å–æœ€å¸¸ç”¨çš„å…¥åœºç­–ç•¥"""
    try:
        from collections import Counter
        strategies = [trade.get('entry_strategy', 'æœªçŸ¥') for trade in trades]
        most_common = Counter(strategies).most_common(1)
        return most_common[0][0] if most_common else 'æœªçŸ¥'
    except:
        return 'æœªçŸ¥'

def check_macd_zero_axis_pre_filter(df, signal_idx, signal_state, lookback_days=5):
    """
    MACDé›¶è½´å¯åŠ¨ç­–ç•¥çš„é¢„ç­›é€‰è¿‡æ»¤å™¨ï¼šæ’é™¤äº”æ—¥å†…ä»·æ ¼ä¸Šæ¶¨è¶…è¿‡5%çš„æƒ…å†µ
    """
    try:
        if signal_state not in ['PRE', 'MID', 'POST']:
            return False, ""
        
        start_idx = max(0, signal_idx - lookback_days)
        end_idx = signal_idx
        
        if start_idx >= end_idx:
            return False, ""
        
        lookback_data = df.iloc[start_idx:end_idx + 1]
        if len(lookback_data) < 2:
            return False, ""
        
        base_price = lookback_data.iloc[0]['close']
        current_high = df.iloc[signal_idx]['high']
        price_increase = (current_high - base_price) / base_price
        
        if price_increase > 0.25 or price_increase < 0.05:
            return True, f"äº”æ—¥å†…æ¶¨å¹…{price_increase:.1%}è¶…è¿‡25%æˆ–è€…ä½äº5%ï¼Œæ’é™¤ä¸æ´»è·ƒé£é™©"
        
        return False, ""
        
    except Exception as e:
        print(f"MACDé›¶è½´é¢„ç­›é€‰è¿‡æ»¤å™¨æ£€æŸ¥å¤±è´¥: {e}")
        return False, ""

def check_weekly_golden_cross_ma_filter(df, signal_idx, signal_state, stock_code):
    """
    å‘¨çº¿é‡‘å‰+æ—¥çº¿MAç­–ç•¥çš„è¿‡æ»¤å™¨
    """
    try:
        if signal_state != 'BUY':
            return False, ""
        
        if len(df) < 240:
            return True, "æ•°æ®é•¿åº¦ä¸è¶³ï¼Œæ— æ³•è®¡ç®—é•¿æœŸMA"
        
        current_price = df.iloc[signal_idx]['close']
        ma13 = df['close'].rolling(window=13).mean().iloc[signal_idx]
        
        if pd.isna(ma13):
            return True, "MA13è®¡ç®—å¤±è´¥"
        
        price_distance = (current_price - ma13) / ma13
        if price_distance > 0.05:
            return True, f"ä»·æ ¼è·ç¦»MA13è¿‡è¿œ({price_distance:.1%})ï¼Œæ’é™¤è¿½é«˜é£é™©"
        
        if 'volume' in df.columns:
            current_volume = df.iloc[signal_idx]['volume']
            avg_volume = df['volume'].rolling(window=20).mean().iloc[signal_idx]
            
            if not pd.isna(avg_volume) and avg_volume > 0:
                volume_ratio = current_volume / avg_volume
                if volume_ratio > 5.0:
                    return True, f"æˆäº¤é‡å¼‚å¸¸æ”¾å¤§({volume_ratio:.1f}å€)ï¼Œå¯èƒ½å­˜åœ¨é£é™©"
        
        if signal_idx >= 5:
            price_5_days_ago = df.iloc[signal_idx - 5]['close']
            short_term_gain = (current_price - price_5_days_ago) / price_5_days_ago
            if short_term_gain > 0.15:
                return True, f"çŸ­æœŸæ¶¨å¹…è¿‡å¤§({short_term_gain:.1%})ï¼Œæ’é™¤è¿½é«˜é£é™©"
        
        return False, ""
        
    except Exception as e:
        logger.error(f"å‘¨çº¿é‡‘å‰+æ—¥çº¿MAè¿‡æ»¤å™¨æ£€æŸ¥å¤±è´¥ {stock_code}: {e}")
        return True, f"è¿‡æ»¤å™¨æ‰§è¡Œå¤±è´¥: {e}"

def analyze_ma_trend(df):
    """
    åˆ†æMAè¶‹åŠ¿å¼ºåº¦å’Œç›¸å…³æŒ‡æ ‡
    """
    try:
        ma_periods = [7, 13, 30, 45]
        mas = {}
        for period in ma_periods:
            mas[f'ma_{period}'] = df['close'].rolling(window=period).mean()
        
        current_price = df['close'].iloc[-1]
        ma13_current = mas['ma_13'].iloc[-1]
        
        trend_strength = 0
        if not pd.isna(ma13_current):
            if (mas['ma_7'].iloc[-1] > mas['ma_13'].iloc[-1] and
                mas['ma_13'].iloc[-1] > mas['ma_30'].iloc[-1] and
                mas['ma_30'].iloc[-1] > mas['ma_45'].iloc[-1]):
                trend_strength = 1.0
            elif (mas['ma_7'].iloc[-1] > mas['ma_13'].iloc[-1] and
                  mas['ma_13'].iloc[-1] > mas['ma_30'].iloc[-1]):
                trend_strength = 0.7
            elif mas['ma_7'].iloc[-1] > mas['ma_13'].iloc[-1]:
                trend_strength = 0.4
            else:
                trend_strength = 0.0
        
        ma13_distance = 0
        if not pd.isna(ma13_current) and ma13_current > 0:
            ma13_distance = (current_price - ma13_current) / ma13_current
        
        volume_surge_ratio = 1.0
        if 'volume' in df.columns and len(df) >= 20:
            current_volume = df['volume'].iloc[-1]
            avg_volume = df['volume'].rolling(window=20).mean().iloc[-1]
            if not pd.isna(avg_volume) and avg_volume > 0:
                volume_surge_ratio = current_volume / avg_volume
        
        return {
            'trend_strength': trend_strength,
            'ma13_distance': ma13_distance,
            'volume_surge_ratio': volume_surge_ratio
        }
        
    except Exception as e:
        logger.error(f"MAè¶‹åŠ¿åˆ†æå¤±è´¥: {e}")
        return {
            'trend_strength': 0,
            'ma13_distance': 0,
            'volume_surge_ratio': 1.0
        }

def check_triple_cross_enhanced_filter(df, signal_idx, stock_code):
    """
    TRIPLE_CROSSç­–ç•¥çš„å¢å¼ºè¿‡æ»¤å™¨
    """
    try:
        advanced_filter = AdvancedTripleCrossFilter()
        should_exclude, exclude_reason, quality_score, cross_stage = advanced_filter.enhanced_triple_cross_filter(df, signal_idx)
        
        if should_exclude:
            return True, exclude_reason, {}
        
        signal_series = strategies.apply_triple_cross(df)
        if signal_series is not None:
            win_rate_filter = WinRateFilter(min_win_rate=0.4, min_signals=3, min_avg_profit=0.08)
            should_exclude_wr, exclude_reason_wr, backtest_stats = win_rate_filter.should_exclude_stock(df, signal_series, stock_code)
            
            if should_exclude_wr:
                return True, f"èƒœç‡ç­›é€‰: {exclude_reason_wr}", {'backtest_stats': backtest_stats}
        
        return False, "é€šè¿‡å¢å¼ºç­›é€‰", {'backtest_stats': backtest_stats if 'backtest_stats' in locals() else {}}
        
    except Exception as e:
        return True, f"å¢å¼ºè¿‡æ»¤å™¨æ‰§è¡Œå¤±è´¥: {e}", {}

def worker(args):
    """å¤šè¿›ç¨‹å·¥ä½œå‡½æ•°"""
    file_path, market = args
    stock_code_full = os.path.basename(file_path).split('.')[0]
    stock_code_no_prefix = stock_code_full.replace(market, '')

    valid_prefixes = ('600', '601', '603', '000', '001', '002', '003', '300', '688')
    if not stock_code_no_prefix.startswith(valid_prefixes):
        return None

    try:
        df = data_loader.get_daily_data(file_path)
        if df is None or len(df) < 150:
            return None

        current_timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        latest_date = df.index[-1].strftime('%Y-%m-%d')
        
        result_base = {
            'stock_code': stock_code_full,
            'strategy': STRATEGY_TO_RUN,
            'date': latest_date,
            'scan_timestamp': current_timestamp
        }
        
        if STRATEGY_TO_RUN == 'PRE_CROSS':
            return _process_pre_cross_strategy(df, result_base)
        elif STRATEGY_TO_RUN == 'TRIPLE_CROSS':
            return _process_triple_cross_strategy(df, result_base, stock_code_full)
        elif STRATEGY_TO_RUN == 'MACD_ZERO_AXIS':
            return _process_macd_zero_axis_strategy(df, result_base, stock_code_full)
        elif STRATEGY_TO_RUN == 'WEEKLY_GOLDEN_CROSS_MA':
            return _process_weekly_golden_cross_ma_strategy(df, result_base, stock_code_full)
        elif STRATEGY_TO_RUN == 'VALUE_REVERSAL':
            return _process_value_reversal_strategy(df, result_base)
            
        return None
        
    except Exception as e:
        logger.error(f"å¤„ç† {stock_code_full} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return None

def _process_pre_cross_strategy(df, result_base):
    """å¤„ç†PRE_CROSSç­–ç•¥"""
    try:
        signal_series = strategies.apply_pre_cross(df)
        if signal_series is not None and signal_series.iloc[-1]:
            backtest_stats = calculate_backtest_stats_fast(df, signal_series)
            result_base.update(backtest_stats)
            return result_base
        return None
    except Exception:
        return None

def _process_triple_cross_strategy(df, result_base, stock_code_full):
    """å¤„ç†TRIPLE_CROSSç­–ç•¥"""
    try:
        signal_series = strategies.apply_triple_cross(df)
        if signal_series is not None and signal_series.iloc[-1]:
            should_exclude, exclude_reason, filter_details = check_triple_cross_enhanced_filter(df, len(df) - 1, stock_code_full)
            
            if should_exclude:
                logger.info(f"{stock_code_full} è¢«è¿‡æ»¤: {exclude_reason}")
                return None
            
            backtest_stats = calculate_backtest_stats_fast(df, signal_series)
            result_base.update({
                'filter_status': 'passed',
                **backtest_stats
            })
            return result_base
        return None
    except Exception:
        return None

def _process_macd_zero_axis_strategy(df, result_base, stock_code_full):
    """å¤„ç†MACD_ZERO_AXISç­–ç•¥"""
    try:
        signal_series = strategies.apply_macd_zero_axis_strategy(df)
        signal_state = signal_series.iloc[-1]
        if signal_state in ['PRE', 'MID', 'POST']:
            should_exclude, exclude_reason = check_macd_zero_axis_pre_filter(df, len(df) - 1, signal_state)
            
            if should_exclude:
                logger.info(f"{stock_code_full} è¢«è¿‡æ»¤: {exclude_reason}")
                return None
            
            backtest_stats = calculate_backtest_stats_fast(df, signal_series)
            result_base.update({
                'signal_state': signal_state,
                'filter_status': 'passed',
                **backtest_stats
            })
            return result_base
        return None
    except Exception:
        return None

def _process_weekly_golden_cross_ma_strategy(df, result_base, stock_code_full):
    """å¤„ç†WEEKLY_GOLDEN_CROSS_MAç­–ç•¥"""
    try:
        signal_series = strategies.apply_weekly_golden_cross_ma_strategy(df)
        signal_state = signal_series.iloc[-1]
        
        if signal_state in ['BUY', 'HOLD', 'SELL']:
            should_exclude, exclude_reason = check_weekly_golden_cross_ma_filter(df, len(df) - 1, signal_state, stock_code_full)
            
            if should_exclude:
                logger.info(f"{stock_code_full} è¢«è¿‡æ»¤: {exclude_reason}")
                return None
            
            backtest_stats = calculate_backtest_stats_fast(df, signal_series)
            ma_analysis = analyze_ma_trend(df)
            
            result_base.update({
                'signal_state': signal_state,
                'filter_status': 'passed',
                'ma_trend_strength': ma_analysis.get('trend_strength', 0),
                'ma13_distance': ma_analysis.get('ma13_distance', 0),
                'volume_surge_ratio': ma_analysis.get('volume_surge_ratio', 1.0),
                **backtest_stats
            })
            return result_base
        return None
    except Exception as e:
        logger.error(f"å¤„ç†å‘¨çº¿é‡‘å‰+æ—¥çº¿MAç­–ç•¥å¤±è´¥ {stock_code_full}: {e}")
        return None

def _process_value_reversal_strategy(df, result_base):
    """å¤„ç†VALUE_REVERSALç­–ç•¥"""
    try:
        signal_series = strategies.apply_value_reversal_strategy(df)
        if signal_series is not None and signal_series.iloc[-1]:
            backtest_stats = calculate_backtest_stats_fast(df, signal_series)
            result_base.update({
                'filter_status': 'passed',
                **backtest_stats
            })
            return result_base
        return None
    except Exception as e:
        logger.error(f"å¤„ç†ä»·å€¼åè½¬ç­–ç•¥å¤±è´¥ {result_base.get('stock_code', '')}: {e}")
        return None

def calculate_backtest_stats_fast(df, signal_series):
    """å¿«é€Ÿè®¡ç®—å›æµ‹ç»Ÿè®¡ä¿¡æ¯"""
    try:
        if 'dif' not in df.columns or 'dea' not in df.columns:
            macd_values = indicators.calculate_macd(df)
            df['dif'], df['dea'] = macd_values[0], macd_values[1]
        
        if 'k' not in df.columns or 'd' not in df.columns:
            kdj_values = indicators.calculate_kdj(df)
            df['k'], df['d'], df['j'] = kdj_values[0], kdj_values[1], kdj_values[2]
        
        backtest_results = backtester.run_backtest(df, signal_series)
        
        if isinstance(backtest_results, dict) and backtest_results.get('total_signals', 0) > 0:
            return {
                'total_signals': backtest_results.get('total_signals', 0),
                'win_rate': backtest_results.get('win_rate', '0.0%'),
                'avg_max_profit': backtest_results.get('avg_max_profit', '0.0%'),
                'avg_max_drawdown': backtest_results.get('avg_max_drawdown', '0.0%'),
                'avg_days_to_peak': backtest_results.get('avg_days_to_peak', '0.0 å¤©')
            }
        else:
            return {'total_signals': 0, 'win_rate': '0.0%', 'avg_max_profit': '0.0%', 'avg_max_drawdown': '0.0%', 'avg_days_to_peak': '0.0 å¤©'}
    except Exception as e:
        logger.error(f"å¿«é€Ÿå›æµ‹è®¡ç®—å¤±è´¥: {e}")
        return {'total_signals': 0, 'win_rate': '0.0%', 'avg_max_profit': '0.0%', 'avg_max_drawdown': '0.0%', 'avg_days_to_peak': '0.0 å¤©'}

def generate_summary_report(passed_stocks):
    """ç”Ÿæˆè¯¦ç»†çš„æ±‡æ€»æŠ¥å‘Š"""
    if not passed_stocks:
        return {
            'scan_summary': {'total_signals': 0, 'scan_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'strategy': STRATEGY_TO_RUN, 'total_historical_signals': 0, 'avg_win_rate': '0.0%', 'avg_profit_rate': '0.0%', 'avg_days_to_peak': '0.0 å¤©'},
            'signal_breakdown': {},
            'top_performers': []
        }
    
    total_signals = len(passed_stocks)
    
    signal_states = {}
    if STRATEGY_TO_RUN == 'MACD_ZERO_AXIS':
        for stock in passed_stocks:
            state = stock.get('signal_state', 'UNKNOWN')
            if state not in signal_states:
                signal_states[state] = []
            signal_states[state].append(stock)
    
    total_historical_signals = sum(stock.get('total_signals', 0) for stock in passed_stocks if stock.get('total_signals', 0) > 0)
    
    win_rates = [float(s.get('win_rate', '0.0%').replace('%', '')) for s in passed_stocks if s.get('total_signals', 0) > 0]
    profit_rates = [float(s.get('avg_max_profit', '0.0%').replace('%', '')) for s in passed_stocks if s.get('total_signals', 0) > 0]
    days_to_peak = [float(s.get('avg_days_to_peak', '0.0 å¤©').replace(' å¤©', '')) for s in passed_stocks if s.get('total_signals', 0) > 0]
    
    avg_win_rate = sum(win_rates) / len(win_rates) if win_rates else 0
    avg_profit_rate = sum(profit_rates) / len(profit_rates) if profit_rates else 0
    avg_days_to_peak = sum(days_to_peak) / len(days_to_peak) if days_to_peak else 0
    
    summary = {
        'scan_summary': {
            'total_signals': total_signals, 'scan_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'strategy': STRATEGY_TO_RUN, 'total_historical_signals': total_historical_signals, 'avg_win_rate': f"{avg_win_rate:.1f}%", 'avg_profit_rate': f"{avg_profit_rate:.1f}%", 'avg_days_to_peak': f"{avg_days_to_peak:.1f} å¤©"
        },
        'signal_breakdown': signal_states,
        'top_performers': sorted([s for s in passed_stocks if s.get('total_signals', 0) > 0], key=lambda x: float(x.get('avg_max_profit', '0%').replace('%', '')), reverse=True)[:10]
    }
    
    return summary

def trigger_deep_scan_multithreaded(passed_stocks):
    """è§¦å‘å¤šçº¿ç¨‹æ·±åº¦æ‰«æ"""
    if not passed_stocks:
        print("âš ï¸ æ²¡æœ‰é€šè¿‡ç­›é€‰çš„è‚¡ç¥¨ï¼Œè·³è¿‡æ·±åº¦æ‰«æ")
        return None
    
    print(f"\nğŸ” è§¦å‘å¤šçº¿ç¨‹æ·±åº¦æ‰«æ...")
    print(f"ğŸ“Š ç­›é€‰å‡º {len(passed_stocks)} åªè‚¡ç¥¨è¿›è¡Œæ·±åº¦åˆ†æ")
    
    stock_codes = [stock['stock_code'] for stock in passed_stocks]
    
    try:
        from run_enhanced_screening import deep_scan_stocks
        max_workers = min(cpu_count() * 2, len(stock_codes), 32)
        print(f"ğŸ§µ ä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹è¿›è¡Œæ·±åº¦æ‰«æ")
        deep_scan_results = deep_scan_stocks(stock_codes, use_optimized_params=True, max_workers=max_workers)
        print(f"âœ… å¤šçº¿ç¨‹æ·±åº¦æ‰«æå®Œæˆ")
        return deep_scan_results
        
    except Exception as e:
        print(f"âŒ å¤šçº¿ç¨‹æ·±åº¦æ‰«æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def main():
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    start_time = datetime.now()
    logger.info(f"===== å¼€å§‹æ‰§è¡Œæ‰¹é‡ç­›é€‰, ç­–ç•¥: {STRATEGY_TO_RUN} =====")
    print(f"ğŸš€ å¼€å§‹æ‰§è¡Œæ‰¹é‡ç­›é€‰, ç­–ç•¥: {STRATEGY_TO_RUN}")
    print(f"â° æ‰«ææ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    all_files = []
    for market in MARKETS:
        path = os.path.join(BASE_PATH, market, 'lday', '*.day')
        files = glob.glob(path)
        if not files:
            print(f"âš ï¸ è­¦å‘Š: åœ¨è·¯å¾„ {path} æœªæ‰¾åˆ°ä»»ä½•æ–‡ä»¶ã€‚")
        all_files.extend([(f, market) for f in files])
    
    if not all_files:
        print("âŒ é”™è¯¯: æœªèƒ½åœ¨ä»»ä½•å¸‚åœºç›®å½•ä¸‹æ‰¾åˆ°æ—¥çº¿æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥BASE_PATHé…ç½®ã€‚")
        return

    print(f"ğŸ“Š å…±æ‰¾åˆ° {len(all_files)} ä¸ªæ—¥çº¿æ–‡ä»¶ï¼Œå¼€å§‹å¤šè¿›ç¨‹å¤„ç†...")
    
    with Pool(processes=cpu_count()) as pool:
        results = pool.map(worker, all_files)
    
    passed_stocks = [r for r in results if r is not None]
    processing_time = (datetime.now() - start_time).total_seconds()
    
    print(f"ğŸ“ˆ åˆæ­¥ç­›é€‰å®Œæˆï¼Œé€šè¿‡ç­›é€‰: {len(passed_stocks)} åªè‚¡ç¥¨")
    
    output_file = os.path.join(RESULT_DIR, 'signals_summary.json')
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(passed_stocks, f, ensure_ascii=False, indent=4)
    
    summary_report = generate_summary_report(passed_stocks)
    summary_report['scan_summary']['processing_time'] = f"{processing_time:.2f} ç§’"
    summary_report['scan_summary']['files_processed'] = len(all_files)
    
    summary_file = os.path.join(RESULT_DIR, 'scan_summary_report.json')
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary_report, f, ensure_ascii=False, indent=4)
    
    text_report_file = os.path.join(RESULT_DIR, f'scan_report_{DATE}.txt')
    with open(text_report_file, 'w', encoding='utf-8') as f:
        f.write(f"=== {STRATEGY_TO_RUN} ç­–ç•¥ç­›é€‰æŠ¥å‘Š ===\n")
        f.write(f"æ‰«ææ—¶é—´: {summary_report['scan_summary']['scan_timestamp']}\n")
        f.write(f"å¤„ç†æ–‡ä»¶æ•°: {summary_report['scan_summary']['files_processed']}\n")
        f.write(f"å¤„ç†è€—æ—¶: {summary_report['scan_summary']['processing_time']}\n")
        f.write(f"å‘ç°ä¿¡å·æ•°: {summary_report['scan_summary']['total_signals']}\n")
        f.write(f"å†å²ä¿¡å·æ€»æ•°: {summary_report['scan_summary'].get('total_historical_signals', 0)}\n")
        f.write(f"å¹³å‡èƒœç‡: {summary_report['scan_summary']['avg_win_rate']}\n")
        f.write(f"å¹³å‡æ”¶ç›Šç‡: {summary_report['scan_summary']['avg_profit_rate']}\n")
        f.write(f"å¹³å‡è¾¾å³°å¤©æ•°: {summary_report['scan_summary']['avg_days_to_peak']}\n\n")
        
        if summary_report['signal_breakdown']:
            f.write("=== ä¿¡å·çŠ¶æ€åˆ†å¸ƒ ===\n")
            for state, stocks in summary_report['signal_breakdown'].items():
                f.write(f"{state}: {len(stocks)} ä¸ª\n")
            f.write("\n")
        
        if summary_report['top_performers']:
            f.write("=== å‰10åè¡¨ç°æœ€ä½³è‚¡ç¥¨ ===\n")
            for i, stock in enumerate(summary_report['top_performers'], 1):
                f.write(f"{i:2d}. {stock['stock_code']} - èƒœç‡: {stock.get('win_rate', 'N/A')}, "
                       f"æ”¶ç›Š: {stock.get('avg_max_profit', 'N/A')}, "
                       f"å¤©æ•°: {stock.get('avg_days_to_peak', 'N/A')}\n")
    
    print(f"\nğŸ“Š åˆæ­¥ç­›é€‰å®Œæˆï¼")
    print(f"ğŸ¯ å‘ç°ä¿¡å·: {len(passed_stocks)} ä¸ª")
    print(f"â±ï¸ å¤„ç†è€—æ—¶: {processing_time:.2f} ç§’")
    print(f"ğŸ“ˆ å¹³å‡èƒœç‡: {summary_report['scan_summary']['avg_win_rate']}")
    print(f"ğŸ’° å¹³å‡æ”¶ç›Š: {summary_report['scan_summary']['avg_profit_rate']}")
    print(f"ğŸ“„ ç»“æœå·²ä¿å­˜è‡³:")
    print(f"  - ä¿¡å·åˆ—è¡¨: {output_file}")
    print(f"  - æ±‡æ€»æŠ¥å‘Š: {summary_file}")
    print(f"  - æ–‡æœ¬æŠ¥å‘Š: {text_report_file}")
    
    if len(passed_stocks) > 0:
        print(f"\n" + "="*60)
        print(f"ğŸ” å¯åŠ¨æ·±åº¦æ‰«æé˜¶æ®µ (å¤šçº¿ç¨‹)")
        print(f"="*60)
        
        deep_scan_results = trigger_deep_scan_multithreaded(passed_stocks)
        
        if deep_scan_results:
            valid_deep_results = {k: v for k, v in deep_scan_results.items() if 'error' not in v}
            a_grade_stocks = [k for k, v in valid_deep_results.items() if v.get('overall_score', {}).get('grade') == 'A']
            price_evaluated_stocks = [k for k, v in valid_deep_results.items() if 'price_evaluation' in v]
            buy_recommendations = [k for k, v in valid_deep_results.items() if v.get('recommendation', {}).get('action') == 'BUY']
            
            print(f"\nğŸ‰ æ·±åº¦æ‰«æç»“æœ:")
            print(f"ğŸ“Š æ·±åº¦åˆ†ææˆåŠŸ: {len(valid_deep_results)}/{len(passed_stocks)}")
            print(f"ğŸ† Açº§è‚¡ç¥¨å‘ç°: {len(a_grade_stocks)}")
            print(f"ğŸ’° ä»·æ ¼è¯„ä¼°å®Œæˆ: {len(price_evaluated_stocks)}")
            print(f"ğŸŸ¢ ä¹°å…¥æ¨è: {len(buy_recommendations)}")
            
            if a_grade_stocks:
                print(f"\nğŸŒŸ Açº§è‚¡ç¥¨åˆ—è¡¨:")
                for stock_code in a_grade_stocks:
                    result = valid_deep_results[stock_code]
                    score = result['overall_score']['total_score']
                    price = result['basic_analysis']['current_price']
                    action = result['recommendation']['action']
                    confidence = result['recommendation']['confidence']
                    price_eval_mark = " ğŸ’°" if 'price_evaluation' in result else ""
                    print(f"  ğŸ† {stock_code}: {score:.1f}åˆ†, Â¥{price:.2f}, {action} ({confidence:.1%}){price_eval_mark}")
            
            summary_report['deep_scan_summary'] = {
                'total_analyzed': len(valid_deep_results), 'a_grade_count': len(a_grade_stocks), 'price_evaluated_count': len(price_evaluated_stocks), 'buy_recommendations': len(buy_recommendations), 'a_grade_stocks': a_grade_stocks, 'buy_recommendation_stocks': buy_recommendations
            }
            
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary_report, f, ensure_ascii=False, indent=4)
            
            with open(text_report_file, 'a', encoding='utf-8') as f:
                f.write(f"\n=== æ·±åº¦æ‰«æç»“æœ (å¤šçº¿ç¨‹) ===\n")
                f.write(f"æ·±åº¦åˆ†ææˆåŠŸ: {len(valid_deep_results)}/{len(passed_stocks)}\n")
                f.write(f"Açº§è‚¡ç¥¨å‘ç°: {len(a_grade_stocks)}\n")
                f.write(f"ä»·æ ¼è¯„ä¼°å®Œæˆ: {len(price_evaluated_stocks)}\n")
                f.write(f"ä¹°å…¥æ¨è: {len(buy_recommendations)}\n\n")
                
                if a_grade_stocks:
                    f.write("=== Açº§è‚¡ç¥¨è¯¦æƒ… ===\n")
                    for stock_code in a_grade_stocks:
                        result = valid_deep_results[stock_code]
                        score = result['overall_score']['total_score']
                        price = result['basic_analysis']['current_price']
                        action = result['recommendation']['action']
                        confidence = result['recommendation']['confidence']
                        price_eval_mark = " [å·²è¯„ä¼°]" if 'price_evaluation' in result else ""
                        f.write(f"{stock_code}: {score:.1f}åˆ†, Â¥{price:.2f}, {action} (ä¿¡å¿ƒåº¦: {confidence:.1%}){price_eval_mark}\n")
                
                if buy_recommendations:
                    f.write(f"\n=== ä¹°å…¥æ¨èè‚¡ç¥¨ ===\n")
                    for stock_code in buy_recommendations:
                        result = valid_deep_results[stock_code]
                        score = result['overall_score']['total_score']
                        price = result['basic_analysis']['current_price']
                        confidence = result['recommendation']['confidence']
                        f.write(f"{stock_code}: {score:.1f}åˆ†, Â¥{price:.2f}, ä¿¡å¿ƒåº¦: {confidence:.1%}\n")
    else:
        print(f"\nâš ï¸ æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ï¼Œè·³è¿‡æ·±åº¦æ‰«æ")
    
    total_time = (datetime.now() - start_time).total_seconds()
    print(f"\nğŸ‰ å®Œæ•´æ‰«ææµç¨‹ç»“æŸï¼æ€»è€—æ—¶: {total_time:.2f} ç§’")
    
    logger.info(f"===== å®Œæ•´æ‰«æå®Œæˆï¼åˆæ­¥ç­›é€‰: {len(passed_stocks)} ä¸ªä¿¡å·ï¼Œæ€»è€—æ—¶: {total_time:.2f} ç§’ =====")

if __name__ == '__main__':
    main()
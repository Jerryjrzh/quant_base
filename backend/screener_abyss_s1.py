import os
import glob
import json
import pandas as pd
import numpy as np
from multiprocessing import Pool, cpu_count
from datetime import datetime, timedelta
import logging
import warnings
import struct
import matplotlib.pyplot as plt
import mplfinance as mpf

warnings.filterwarnings('ignore')

# --- å…¨å±€é…ç½® ---
BASE_PATH = os.path.expanduser("~/.local/share/tdxcfv/drive_c/tc/vipdoc")
MARKETS = ['sh', 'sz']
# --- æ ¸å¿ƒä¿®æ”¹ï¼šæ–°å¢V2ç‰ˆå¤šå‘¨æœŸç­–ç•¥ï¼Œå¹¶è®¾ä¸ºé»˜è®¤ ---
STRATEGY_TO_RUN = 'MULTI_TIMEFRAME_PULLBACK_V2' # <--- è¿è¡Œâ€œå‘¨çº¿é€‰è‚¡ã€æ—¥çº¿ç²¾å‡†æ‹©æ—¶â€æ–°ç­–ç•¥
# STRATEGY_TO_RUN = 'MULTI_TIMEFRAME_PULLBACK'    # <--- V1ç‰ˆå¤šå‘¨æœŸç­–ç•¥
# STRATEGY_TO_RUN = 'STRONG_TREND_PULLBACK'       # <--- è¿è¡Œâ€œå¼ºåŠ¿è¶‹åŠ¿å›è°ƒâ€ç­›é€‰ (å•å‘¨æœŸ)
# STRATEGY_TO_RUN = 'ABYSS_WATCHLIST'             # <--- è¿è¡Œâ€œå…³æ³¨æ± â€ç­›é€‰ (å•å‘¨æœŸ)

# --- è·¯å¾„å®šä¹‰ ---
backend_dir = os.path.dirname(os.path.abspath(__file__))
OUTPUT_PATH = os.path.abspath(os.path.join(backend_dir, '..', 'data', 'result'))
CONFIG_FILE = os.path.join(backend_dir, 'abyss_config.json')

# --- åˆå§‹åŒ–æ—¥å¿— ---
DATE = datetime.now().strftime("%Y%m%d_%H%M")
RESULT_DIR = os.path.join(OUTPUT_PATH, STRATEGY_TO_RUN)
os.makedirs(RESULT_DIR, exist_ok=True)
CHART_DIR = os.path.join(RESULT_DIR, 'charts')
os.makedirs(CHART_DIR, exist_ok=True)

LOG_FILE = os.path.join(RESULT_DIR, f'log_screener_{DATE}.txt')
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s',
                    handlers=[logging.FileHandler(LOG_FILE, 'a', 'utf-8'), logging.StreamHandler()])
logger = logging.getLogger('stock_screener_mtf_v2')


# --- å·¥å…·å‡½æ•° (ä¿æŒä¸å˜) ---
def load_config():
    try:
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f: config = json.load(f)
        logger.info(f"æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {config.get('strategy_name')} v{config.get('version')}")
        return config
    except Exception as e:
        logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}, å°†ä½¿ç”¨é»˜è®¤å€¼ã€‚")
        return json.loads('{"core_parameters":{}, "analysis_timeframe": "weekly"}')

CONFIG = load_config()

def read_day_file(file_path):
    try:
        with open(file_path, 'rb') as f:
            buffer = f.read(); count = len(buffer) // 32
            data = [struct.unpack('<IIIIIIII', buffer[i*32:(i+1)*32]) for i in range(count)]
        if not data: return None
        df = pd.DataFrame(data, columns=['date_int', 'open', 'high', 'low', 'close', 'amount', 'volume', '_'])
        df['date'] = pd.to_datetime(df['date_int'].astype(str), format='%Y%m%d')
        df.set_index('date', inplace=True)
        for col in ['open', 'high', 'low', 'close']: df[col] /= 100.0
        return df[['open', 'high', 'low', 'close', 'volume', 'amount']]
    except Exception: return None

def resample_to_weekly(df):
    if df is None or df.empty: return None
    agg_dict = {'open': 'first', 'high': 'max', 'low': 'min', 'close': 'last', 'volume': 'sum', 'amount': 'sum'}
    weekly_df = df.resample('W-FRI').agg(agg_dict)
    weekly_df.dropna(inplace=True)
    return weekly_df

# --- åŸºç¡€ç­–ç•¥ç±» ---
class StrategyBase:
    def __init__(self, config=None, timeframe='weekly'):
        self.config = config or CONFIG
        # (çœç•¥éƒ¨åˆ†åˆå§‹åŒ–ä»£ç ä»¥ä¿æŒç®€æ´)

    def calculate_indicators(self, df):
        df = df.copy()
        ti_config = self.config.get('technical_indicators', {})
        ma_periods = ti_config.get('ma_periods', [7, 13, 30, 45, 60])
        for period in ma_periods:
            if len(df) >= period: df[f'ma{period}'] = df['close'].rolling(window=period).mean()
        return df

# --- æ–°å¢ï¼šV2ç‰ˆå¤šæ—¶é—´å‘¨æœŸç­–ç•¥ï¼Œå¸¦ç²¾å‡†æ—¥çº¿æ‹©æ—¶ ---
class MultiTimeframeStrategyV2(StrategyBase):
    def __init__(self, config=None):
        super().__init__(config, timeframe='weekly')
        logger.info("ç­–ç•¥å·²åˆå§‹åŒ–ä¸ºã€V2å¤šæ—¶é—´å‘¨æœŸã€‘ç­›é€‰æ¨¡å¼ (å‘¨çº¿å®šåŠ¿, æ—¥çº¿ç²¾å‡†æ‹©æ—¶)ã€‚")

    def analyze_weekly(self, df_weekly):
        """ç¬¬ä¸€æ­¥ï¼šåœ¨å‘¨çº¿å›¾ä¸Šå¯»æ‰¾ç¬¦åˆå¼ºåŠ¿å›è°ƒçš„ç»“æ„"""
        try:
            if len(df_weekly) < 60: return False, {}
            df = self.calculate_indicators(df_weekly)
            latest = df.iloc[-1]
            required_mas = ['ma7', 'ma13', 'ma30', 'ma60']
            if latest[required_mas].isnull().any(): return False, {}

            is_strong_trend = (latest['ma7'] > latest['ma13'] > latest['ma30'] and latest['close'] > latest['ma60'])
            ma30_slope = (latest['ma30'] - df['ma30'].iloc[-5]) / 5 if len(df) >= 5 else 0
            is_trend_upward = ma30_slope > 0

            if not (is_strong_trend and is_trend_upward): return False, {}
            
            is_near_ma13 = abs(latest['close'] - latest['ma13']) / latest['ma13'] < 0.05
            if not is_near_ma13: return False, {}

            details = {'weekly_support': latest['ma13'], 'weekly_pressure': df['high'].iloc[-8:].max()}
            return True, details
        except Exception: return False, {}

    def confirm_daily_precise(self, df_daily, weekly_details):
        """ç¬¬äºŒæ­¥ï¼šåœ¨æ—¥çº¿å›¾ä¸Šå¯»æ‰¾ç²¾å‡†çš„çœ‹æ¶¨Kçº¿åè½¬å½¢æ€"""
        try:
            weekly_support = weekly_details.get('weekly_support', 0)
            if weekly_support == 0 or len(df_daily) < 5: return False, {}
            
            recent_days = df_daily.tail(5) # åœ¨æœ€è¿‘5å¤©å†…å¯»æ‰¾ä¿¡å·
            
            # æ£€æŸ¥æœ€è¿‘å‡ å¤©æ˜¯å¦æµ‹è¯•äº†å‘¨çº¿æ”¯æ’‘
            touched_support = (recent_days['low'] < weekly_support * 1.02).any()
            if not touched_support: return False, {}

            # éå†æœ€è¿‘3æ ¹Kçº¿ï¼Œå¯»æ‰¾åè½¬å½¢æ€
            for i in range(-3, 0):
                # å®šä¹‰Kçº¿
                k0 = df_daily.iloc[i]     # å½“å‰Kçº¿
                k1 = df_daily.iloc[i-1]   # å‰ä¸€æ ¹Kçº¿
                
                # å½¢æ€1ï¼šçœ‹æ¶¨åæ²¡
                is_bullish_engulfing = (k1['close'] < k1['open'] and # å‰é˜´
                                        k0['close'] > k0['open'] and # ä»Šé˜³
                                        k0['close'] > k1['open'] and 
                                        k0['open'] < k1['close'])
                if is_bullish_engulfing:
                    return True, {'daily_pattern': 'Bullish_Engulfing'}

                # å½¢æ€2ï¼šé”¤å­çº¿
                body_size = abs(k0['close'] - k0['open'])
                lower_shadow = k0['open'] - k0['low'] if k0['close'] > k0['open'] else k0['close'] - k0['low']
                upper_shadow = k0['high'] - k0['close'] if k0['close'] > k0['open'] else k0['high'] - k0['open']
                is_hammer = (lower_shadow > body_size * 2 and upper_shadow < body_size)
                if is_hammer:
                    return True, {'daily_pattern': 'Hammer'}

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç‰¹å®šå½¢æ€ï¼Œåˆ™è¿”å›å¤±è´¥
            return False, {}
        except Exception:
            return False, {}

# --- ä¿ç•™V1ç‰ˆå¤šå‘¨æœŸç­–ç•¥å’Œå…¶ä»–ç­–ç•¥ä»¥ä¾¿å¯¹æ¯” ---
class MultiTimeframeStrategy(StrategyBase): pass
class StrongTrendPullbackStrategy(StrategyBase): pass
class AbyssWatchlistStrategy(StrategyBase): pass


def visualize_signal(df, stock_code, signal_date_str, details, timeframe='weekly'):
    try:
        df_chart = df.copy(); signal_date = pd.to_datetime(signal_date_str)
        if timeframe == 'weekly': start_date = signal_date - pd.Timedelta(weeks=104)
        else: start_date = signal_date - pd.Timedelta(days=120)
        df_chart = df_chart.loc[start_date:]
        if df_chart.empty: return

        daily_pattern = details.get('daily_pattern', 'N/A')
        title = f"{timeframe.upper()}: {stock_code} on {signal_date_str}\nDaily Pattern: {daily_pattern}"
        
        addplots = [mpf.make_addplot(df_chart[['ma7', 'ma13', 'ma30', 'ma60']], alpha=0.7)]
        arrow_y = pd.Series(float('nan'), index=df_chart.index)
        signal_idx = df_chart.index.get_indexer([signal_date], method='nearest')[0]
        signal_display_date = df_chart.index[signal_idx]
        arrow_y[signal_display_date] = df_chart.loc[signal_display_date]['low'] * 0.95
        addplots.append(mpf.make_addplot(arrow_y, type='scatter', marker='^', color='lime', markersize=150))
        
        fig, _ = mpf.plot(df_chart, type='candle', style='yahoo', title=title, volume=True, addplot=addplots, figsize=(16, 8), returnfig=True)
        
        save_path = os.path.join(CHART_DIR, f"{stock_code}_{signal_date_str}_{timeframe}.png")
        fig.savefig(save_path); plt.close(fig)
    except Exception as e: logger.error(f"å›¾è¡¨ç”Ÿæˆå¤±è´¥ for {stock_code} ({timeframe}): {e}", exc_info=True)


def worker(args):
    file_path, market, strategy_instance = args
    stock_code = os.path.basename(file_path).split('.')[0]
    valid_prefixes = CONFIG.get('market_filters', {}).get('valid_prefixes', {}).get(market, [])
    if not any(stock_code.replace(market, '').startswith(p) for p in valid_prefixes): return None
        
    try:
        df_daily = read_day_file(file_path)
        if df_daily is None or len(df_daily) < 250: return None

        # --- æ ¸å¿ƒä¿®æ”¹ï¼šV2ç‰ˆå¤šå‘¨æœŸç­–ç•¥çš„æ‰§è¡Œæµç¨‹ ---
        if isinstance(strategy_instance, MultiTimeframeStrategyV2):
            df_weekly = resample_to_weekly(df_daily)
            if df_weekly is None or df_weekly.empty: return None

            is_weekly_ok, weekly_details = strategy_instance.analyze_weekly(df_weekly)
            if is_weekly_ok:
                is_daily_confirmed, daily_details = strategy_instance.confirm_daily_precise(df_daily, weekly_details)
                if is_daily_confirmed:
                    details = {**weekly_details, **daily_details, 'signal_state': 'MTF_V2_BUY'}
                    result = {'stock_code': stock_code, 'signal_type': 'MTF_V2_BUY', 'date': df_daily.index[-1].strftime('%Y-%m-%d'),
                              'current_price': float(df_daily['close'].iloc[-1]),
                              'signal_details': json.loads(json.dumps(details, default=str))}
                    logger.info(f"å‘ç°V2ç²¾å‡†ä¿¡å· ({daily_details.get('daily_pattern')}): {stock_code}")
                    return result
        # (å…¶ä»–å•å‘¨æœŸç­–ç•¥çš„é€»è¾‘ä¿æŒä¸å˜, æ­¤å¤„çœç•¥)
        return None
    except Exception as e:
        logger.error(f"å¤„ç†è‚¡ç¥¨å¤±è´¥ {stock_code}: {e}", exc_info=True)
        return None

def main():
    start_time = datetime.now()
    ANALYSIS_TIMEFRAME = CONFIG.get('analysis_timeframe', 'weekly')

    if STRATEGY_TO_RUN == 'MULTI_TIMEFRAME_PULLBACK_V2':
        strategy_instance = MultiTimeframeStrategyV2(CONFIG)
    # (å…¶ä»–ç­–ç•¥çš„å®ä¾‹åŒ–é€»è¾‘ä¿æŒä¸å˜, æ­¤å¤„çœç•¥)
    else:
        logger.error(f"æœªçŸ¥çš„ç­–ç•¥åç§°: {STRATEGY_TO_RUN}"); return
        
    logger.info(f"===== å¼€å§‹æ‰§è¡Œç­–ç•¥ç­›é€‰: {STRATEGY_TO_RUN} =====")
    
    all_files = []
    for m in MARKETS:
        market_path = os.path.join(BASE_PATH, m, 'lday')
        if os.path.exists(market_path):
            all_files.extend([(os.path.join(market_path, f), m, strategy_instance) for f in os.listdir(market_path) if f.endswith('.day')])

    if not all_files: logger.error("æœªæ‰¾åˆ°ä»»ä½•æ—¥çº¿æ–‡ä»¶ã€‚"); return
    logger.info(f"å…±æ‰¾åˆ° {len(all_files)} ä¸ªæ—¥çº¿æ–‡ä»¶è¿›è¡Œå¤„ç†...")
    
    max_workers = CONFIG.get('performance_tuning', {}).get('max_workers', cpu_count())
    with Pool(processes=min(cpu_count(), max_workers)) as pool:
        results = pool.map(worker, all_files)
    
    passed_stocks = [r for r in results if r is not None]
    logger.info(f"ç­›é€‰å®Œæˆï¼Œå‘ç° {len(passed_stocks)} ä¸ªç²¾å‡†ä¿¡å·ã€‚")

    output_file = os.path.join(RESULT_DIR, f'signals_{DATE}.json')
    with open(output_file, 'w', encoding='utf-8') as f: json.dump(passed_stocks, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“Š ç­›é€‰å®Œæˆï¼å‘ç° {len(passed_stocks)} ä¸ªç²¾å‡†ä¿¡å·ã€‚")
    print(f"ğŸ“„ ç»“æœå·²ä¿å­˜è‡³: {RESULT_DIR}")

    if passed_stocks:
        print(f"ğŸ“¸ æ­£åœ¨ç”Ÿæˆ {len(passed_stocks)} ç»„éªŒè¯å›¾è¡¨ (å‘¨çº¿+æ—¥çº¿)...")
        for stock in passed_stocks:
            file_path = os.path.join(BASE_PATH, stock['stock_code'][:2], 'lday', f"{stock['stock_code']}.day")
            df_daily = read_day_file(file_path)
            if df_daily is not None:
                df_weekly = resample_to_weekly(df_daily)
                if df_weekly is not None:
                    # ç”Ÿæˆå‘¨çº¿å›¾
                    df_weekly_indicators = strategy_instance.calculate_indicators(df_weekly)
                    visualize_signal(df_weekly_indicators, stock['stock_code'], stock['date'], stock['signal_details'], timeframe='weekly')
                    # ç”Ÿæˆæ—¥çº¿å›¾
                    df_daily_indicators = strategy_instance.calculate_indicators(df_daily)
                    visualize_signal(df_daily_indicators, stock['stock_code'], stock['date'], stock['signal_details'], timeframe='daily')
        print(f"âœ… æ‰€æœ‰å›¾è¡¨å·²ç”Ÿæˆå®Œæ¯•ï¼Œè¯·æŸ¥çœ‹ç›®å½•: {CHART_DIR}")

    logger.info(f"æ€»è€—æ—¶: {(datetime.now() - start_time).total_seconds():.2f} ç§’")
    print(f"ğŸ‰ å®Œæ•´æµç¨‹ç»“æŸï¼")

if __name__ == '__main__':
    main()
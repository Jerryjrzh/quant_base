import os
import glob
import json
import pandas as pd
from multiprocessing import Pool, cpu_count
from datetime import datetime
import logging
import data_loader
import strategies
import backtester
import indicators
from win_rate_filter import WinRateFilter, AdvancedTripleCrossFilter
import talib # å¼•å…¥talibä»¥æ–¹ä¾¿è®¡ç®—

# === æ–°å¢ START: â€œå‘¨çº¿å®šåŠ¿ï¼Œæ—¥çº¿æ‹©æ—¶â€ç­–ç•¥å®ç° ===

def resample_to_weekly(df):
    """å°†æ—¥çº¿æ•°æ®èšåˆä¸ºå‘¨çº¿æ•°æ®"""
    if df is None or df.empty:
        return None
    agg_dict = {
        'open': 'first',
        'high': 'max',
        'low': 'min',
        'close': 'last',
        'volume': 'sum'
    }
    weekly_df = df.resample('W-FRI').agg(agg_dict)
    weekly_df.dropna(inplace=True)
    return weekly_df

def apply_daily_ma_pullback_strategy(df):
    """
    å‘¨çº¿ç¡®è®¤å¼ºåŠ¿ï¼Œæ—¥çº¿å¯»æ‰¾MA13å›è¸©ä¹°ç‚¹ç­–ç•¥
    """
    if len(df) < 250: return None

    try:
           # 1. æ•°æ®å‡†å¤‡å’ŒæŒ‡æ ‡è®¡ç®—
        df_weekly = resample_to_weekly(df)
        if df_weekly is None or len(df_weekly) < 60: # éœ€è¦æ›´é•¿æ•°æ®è®¡ç®—å‘¨çº¿MA60å’Œé‡æ¯”
            return None

        # è®¡ç®—å‘¨çº¿çº§åˆ«æŒ‡æ ‡
        for p in [13, 30, 60]: df_weekly[f'ma{p}'] = talib.MA(df_weekly['close'], timeperiod=p)
        for p in [20, 60]: df_weekly[f'vol_ma{p}'] = talib.MA(df_weekly['volume'], timeperiod=p)
        # è®¡ç®—æ—¥çº¿çº§åˆ«æŒ‡æ ‡
        df[f'ma13'] = talib.MA(df['close'], timeperiod=13)

        if df_weekly.iloc[-5:].isnull().values.any() or df.iloc[-1].isnull().values.any():
            return None 

        # 2. ã€V2ç‰ˆã€‘é•¿å‘¨æœŸï¼ˆå‘¨çº¿ï¼‰ç¡®è®¤å¼ºåŠ¿è¶‹åŠ¿ (æ–°å¢ä¸¥æ ¼è¿‡æ»¤)
        latest_w = df_weekly.iloc[-1]
        
        # æ¡ä»¶a: å‘¨çº¿å‡çº¿å¤šå¤´æ’åˆ— (åŸºç¡€)
        ma_alignment_ok = latest_w['ma13'] > latest_w['ma30'] > latest_w['ma60']
        
        # ã€æ–°å¢ã€‘æ¡ä»¶b: å‡çº¿æ–œç‡æŒç»­ä¸ºæ­£ (è¦æ±‚è¶‹åŠ¿æŒç»­æ€§)
        ma30_slope_ok = latest_w['ma30'] > df_weekly['ma30'].iloc[-4] # æ£€æŸ¥MA30åœ¨è¿‡å»4å‘¨æ˜¯ä¸Šå‡çš„

        # ã€æ–°å¢ã€‘æ¡ä»¶c: å‡çº¿ä¹‹é—´æœ‰è¶³å¤Ÿå‘æ•£åº¦ (è¿‡æ»¤ç²˜åˆçŠ¶æ€)
        ma_separation_ok = (latest_w['ma13'] / latest_w['ma60'] - 1) > 0.03 # è¦æ±‚MA13è‡³å°‘é«˜äºMA60 3%

        # ã€æ–°å¢ã€‘æ¡ä»¶d: æˆäº¤é‡è¶‹åŠ¿å¥åº· (è¿‘æœŸæ”¾é‡)
        volume_trend_ok = latest_w['vol_ma20'] > latest_w['vol_ma60']

        # æœ€ç»ˆå¼ºåŠ¿åˆ¤æ–­ï¼šå¿…é¡»åŒæ—¶æ»¡è¶³æ‰€æœ‰ä¸¥æ ¼æ¡ä»¶
        is_strong_trend_weekly = ma_alignment_ok and ma30_slope_ok and ma_separation_ok and volume_trend_ok
        
        if not is_strong_trend_weekly:
            return None

        # 3. çŸ­å‘¨æœŸï¼ˆæ—¥çº¿ï¼‰ç¡®è®¤å›è¸©ä¹°ç‚¹
        latest_d = df.iloc[-1]
        LOW_POINT_WINDOW = 2       # æ£€æŸ¥è¿‡å»5å¤©æœ€ä½ç‚¹
        recent_low_min = df['low'].iloc[-LOW_POINT_WINDOW:].min()
        is_low_point = latest_d['low'] <= recent_low_min
        # ã€æ–°å¢ã€‘è®¡ç®—è¿‘æœŸæ—¥çº¿æˆäº¤é‡å‡å€¼
        df['vol_ma5'] = talib.MA(df['volume'], timeperiod=5)
        # æ£€æŸ¥ç¡®ä¿è®¡ç®—ç»“æœæœ‰æ•ˆ
        if df['vol_ma5'].isnull().iloc[-2]: # è‡³å°‘éœ€è¦å‰ä¸€å¤©çš„MA5æ˜¯æœ‰æ•ˆçš„
            return None

        latest_d = df.iloc[-1]
        today_volume = latest_d['volume']

        # ã€å…³é”®ä¿®æ”¹ã€‘è·å–æ˜¨å¤©çš„5æ—¥å‡é‡ä½œä¸ºå¯¹æ¯”åŸºå‡†
        # iloc[-2] å®šä½åˆ°å€’æ•°ç¬¬äºŒè¡Œï¼Œå³æ˜¨å¤©çš„è®°å½•
        previous_day_vol_ma5 = df['vol_ma5'].iloc[-2]

        # æ¡ä»¶a: ä»·æ ¼å›è¸©
        #is_pullback = latest_d['low'] <= latest_d['ma13'] * 1.1
        SHORT_PULLBACK_DAYS = 2
        # æ¡ä»¶b: ä»·æ ¼åå¼¹
        #is_bounce = latest_d['close'] > latest_d['ma13']
        recent_low = df['low'].iloc[-SHORT_PULLBACK_DAYS:].min()
        is_pullback = latest_d['low'] <= latest_d['ma13'] * 1.1
        # ã€ä¿®æ”¹åçš„æ¡ä»¶cã€‘: ç”¨ä»Šå¤©çš„æˆäº¤é‡å’Œæ˜¨å¤©çš„å‡é‡å¯¹æ¯”
        # å»ºè®®ä½¿ç”¨ä¸€ä¸ªæ›´åˆç†çš„æ¯”ç‡ï¼Œä¾‹å¦‚0.8ã€0.7ç­‰
        # 0.7ä»£è¡¨ä»Šå¤©æˆäº¤é‡è¦ä½äºè¿‡å»5å¤©å¹³å‡æˆäº¤é‡çš„70%
        recent_pullback = sum(df['low'].iloc[-SHORT_PULLBACK_DAYS:-1] <= df['ma13'].iloc[-SHORT_PULLBACK_DAYS:-1] * 1.1) <= 3
        SHRINK_RATIO = 0.5 
        is_volume_shrinking = today_volume < previous_day_vol_ma5 * SHRINK_RATIO
        # æ–°å¢ï¼šè®¡ç®—MACD, RSI (ç”¨talib)
        macd, signal, hist = talib.MACD(df['close'], fastperiod=12, slowperiod=26, signalperiod=9)
        rsi = talib.RSI(df['close'], timeperiod=14)
        latest_macd = macd.iloc[-1]
        latest_rsi = rsi.iloc[-1]
        if latest_rsi > 75: # RSIå¤§äº70è§†ä¸ºè¶…ä¹°
            return None
        # é¿å…è§é¡¶ï¼šMACD >0 (é‡‘å‰è¶‹åŠ¿), RSI <50 (è¶…å–)
        #is_not_top = latest_macd > 0 and latest_rsi < 50
        # æ–°å¢ï¼šä»·æ ¼ä¸é«˜äºMA60 10%
        df['ma60'] = talib.MA(df['close'], timeperiod=60)
        is_not_high = latest_d['close'] < df['ma60'].iloc[-1] * 1.1

        # æˆäº¤é‡ä¸æ”¾é‡è§é¡¶
        df['vol_ma20'] = talib.MA(df['volume'], timeperiod=20)
        is_volume_healthy = df['vol_ma5'].iloc[-1] < df['vol_ma20'].iloc[-1] * 1.5

        if is_pullback and recent_pullback and is_volume_shrinking and is_low_point  and is_not_high:
            signal_series = pd.Series(False, index=df.index)
            signal_series.iloc[-1] = True
            return signal_series

        return None
    except Exception as e:
        return None

# å°†æ–°ç­–ç•¥å‡½æ•°é™„åŠ åˆ°strategieså¯¹è±¡ä¸Š
strategies.apply_daily_ma_pullback_strategy = apply_daily_ma_pullback_strategy

# === æ–°å¢ END ===


# --- é…ç½® ---
BASE_PATH = os.path.expanduser("~/.local/share/tdxcfv/drive_c/tc/vipdoc")
MARKETS = ['sh', 'sz', 'bj']
# --- ä¿®æ”¹ï¼šå°†æ–°ç­–ç•¥è®¾ä¸ºé»˜è®¤ ---
STRATEGY_TO_RUN = 'DAILY_MA_PULLBACK' 
# STRATEGY_TO_RUN = 'MACD_ZERO_AXIS' 
#STRATEGY_TO_RUN = 'TRIPLE_CROSS' 
#STRATEGY_TO_RUN = 'PRE_CROSS'
#STRATEGY_TO_RUN = 'WEEKLY_GOLDEN_CROSS_MA'
# --- è·¯å¾„å®šä¹‰ ---
backend_dir = os.path.dirname(os.path.abspath(__file__))
OUTPUT_PATH = os.path.abspath(os.path.join(backend_dir, '..', 'data', 'result'))

# --- åˆå§‹åŒ–æ—¥å¿— ---
DATE = datetime.now().strftime("%Y%m%d_%H%M")
RESULT_DIR = os.path.join(OUTPUT_PATH, STRATEGY_TO_RUN)
os.makedirs(RESULT_DIR, exist_ok=True)
LOG_FILE = os.path.join(RESULT_DIR, f'log_screener_{DATE}.txt')

file_handler = logging.FileHandler(LOG_FILE, 'a', 'utf-8')
file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
logger = logging.getLogger('screener_logger')
logger.setLevel(logging.INFO)
if logger.hasHandlers():
    logger.handlers.clear()
logger.addHandler(file_handler)

def calculate_backtest_stats(df, signal_series):
    """è®¡ç®—ç»†åŒ–çš„å›æµ‹ç»Ÿè®¡ä¿¡æ¯"""
    try:
        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ˆå›æµ‹éœ€è¦ï¼‰
        macd_values = indicators.calculate_macd(df)
        df['dif'], df['dea'] = macd_values[0], macd_values[1]
        kdj_values = indicators.calculate_kdj(df)
        df['k'], df['d'], df['j'] = kdj_values[0], kdj_values[1], kdj_values[2]
        
        # æ‰§è¡Œç»†åŒ–å›æµ‹
        backtest_results = backtester.run_backtest(df, signal_series)
        
        if isinstance(backtest_results, dict) and backtest_results.get('total_signals', 0) > 0:
            stats = {
                'total_signals': backtest_results.get('total_signals', 0),
                'win_rate': backtest_results.get('win_rate', '0.0%'),
                'avg_max_profit': backtest_results.get('avg_max_profit', '0.0%'),
                'avg_max_drawdown': backtest_results.get('avg_max_drawdown', '0.0%'),
                'avg_days_to_peak': backtest_results.get('avg_days_to_peak', '0.0 å¤©')
            }
            
            # æ·»åŠ å„çŠ¶æ€ç»Ÿè®¡ä¿¡æ¯
            if 'state_statistics' in backtest_results:
                stats['state_statistics'] = backtest_results['state_statistics']
            
            # æ·»åŠ è¯¦ç»†äº¤æ˜“ä¿¡æ¯ï¼ˆç”¨äºè¿›ä¸€æ­¥åˆ†æï¼‰
            if 'trades' in backtest_results:
                # è®¡ç®—ä¸€äº›é¢å¤–çš„ç»Ÿè®¡æŒ‡æ ‡
                trades = backtest_results['trades']
                if trades:
                    # æœ€ä½³è¡¨ç°äº¤æ˜“
                    best_trade = max(trades, key=lambda x: x['actual_max_pnl'])
                    worst_trade = min(trades, key=lambda x: x['actual_max_pnl'])
                    
                    stats.update({
                        'best_trade_profit': f"{best_trade['actual_max_pnl']:.1%}",
                        'worst_trade_profit': f"{worst_trade['actual_max_pnl']:.1%}",
                        'avg_entry_strategy': get_most_common_entry_strategy(trades)
                    })
            
            return stats
        else:
            return {
                'total_signals': 0,
                'win_rate': '0.0%',
                'avg_max_profit': '0.0%',
                'avg_max_drawdown': '0.0%',
                'avg_days_to_peak': '0.0 å¤©'
            }
    except Exception as e:
        logger.error(f"å›æµ‹è®¡ç®—å¤±è´¥: {e}")
        return {
            'total_signals': 0,
            'win_rate': '0.0%',
            'avg_max_profit': '0.0%',
            'avg_max_drawdown': '0.0%',
            'avg_days_to_peak': '0.0 å¤©'
        }

def get_most_common_entry_strategy(trades):
    """è·å–æœ€å¸¸ç”¨çš„å…¥åœºç­–ç•¥"""
    try:
        from collections import Counter
        strategies = [trade.get('entry_strategy', 'æœªçŸ¥') for trade in trades]
        most_common = Counter(strategies).most_common(1)
        return most_common[0][0] if most_common else 'æœªçŸ¥'
    except:
        return 'æœªçŸ¥'

def check_macd_zero_axis_pre_filter(df, signal_idx, signal_state, lookback_days=5):
    """
    MACDé›¶è½´å¯åŠ¨ç­–ç•¥çš„é¢„ç­›é€‰è¿‡æ»¤å™¨ï¼šæ’é™¤äº”æ—¥å†…ä»·æ ¼ä¸Šæ¶¨è¶…è¿‡5%çš„æƒ…å†µ
    """
    try:
        if signal_state not in ['PRE', 'MID', 'POST']:
            return False, ""
        
        start_idx = max(0, signal_idx - lookback_days)
        end_idx = signal_idx
        
        if start_idx >= end_idx:
            return False, ""
        
        lookback_data = df.iloc[start_idx:end_idx + 1]
        if len(lookback_data) < 2:
            return False, ""
        
        base_price = lookback_data.iloc[0]['close']
        current_high = df.iloc[signal_idx]['high']
        price_increase = (current_high - base_price) / base_price
        
        if price_increase > 0.25 or price_increase < 0.05:
            return True, f"äº”æ—¥å†…æ¶¨å¹…{price_increase:.1%}è¶…è¿‡25%æˆ–è€…ä½äº5%ï¼Œæ’é™¤ä¸æ´»è·ƒé£é™©"
        
        return False, ""
        
    except Exception as e:
        print(f"MACDé›¶è½´é¢„ç­›é€‰è¿‡æ»¤å™¨æ£€æŸ¥å¤±è´¥: {e}")
        return False, ""

def check_weekly_golden_cross_ma_filter(df, signal_idx, signal_state, stock_code):
    """
    å‘¨çº¿é‡‘å‰+æ—¥çº¿MAç­–ç•¥çš„è¿‡æ»¤å™¨
    """
    try:
        if signal_state != 'BUY':
            return False, ""
        
        if len(df) < 240:
            return True, "æ•°æ®é•¿åº¦ä¸è¶³ï¼Œæ— æ³•è®¡ç®—é•¿æœŸMA"
        
        current_price = df.iloc[signal_idx]['close']
        ma13 = df['close'].rolling(window=13).mean().iloc[signal_idx]
        
        if pd.isna(ma13):
            return True, "MA13è®¡ç®—å¤±è´¥"
            
        price_distance = (current_price - ma13) / ma13
        if price_distance > 0.05:
            return True, f"ä»·æ ¼è·ç¦»MA13è¿‡è¿œ({price_distance:.1%})ï¼Œæ’é™¤è¿½é«˜é£é™©"
        
        if 'volume' in df.columns:
            current_volume = df.iloc[signal_idx]['volume']
            avg_volume = df['volume'].rolling(window=20).mean().iloc[signal_idx]
            
            if not pd.isna(avg_volume) and avg_volume > 0:
                volume_ratio = current_volume / avg_volume
                if volume_ratio > 5.0:
                    return True, f"æˆäº¤é‡å¼‚å¸¸æ”¾å¤§({volume_ratio:.1f}å€)ï¼Œå¯èƒ½å­˜åœ¨é£é™©"
        
        if signal_idx >= 5:
            price_5_days_ago = df.iloc[signal_idx - 5]['close']
            short_term_gain = (current_price - price_5_days_ago) / price_5_days_ago
            if short_term_gain > 0.15:
                return True, f"çŸ­æœŸæ¶¨å¹…è¿‡å¤§({short_term_gain:.1%})ï¼Œæ’é™¤è¿½é«˜é£é™©"
        
        return False, ""
        
    except Exception as e:
        logger.error(f"å‘¨çº¿é‡‘å‰+æ—¥çº¿MAè¿‡æ»¤å™¨æ£€æŸ¥å¤±è´¥ {stock_code}: {e}")
        return True, f"è¿‡æ»¤å™¨æ‰§è¡Œå¤±è´¥: {e}"

def analyze_ma_trend(df):
    """
    åˆ†æMAè¶‹åŠ¿å¼ºåº¦å’Œç›¸å…³æŒ‡æ ‡
    """
    try:
        ma_periods = [7, 13, 30, 45]
        mas = {}
        for period in ma_periods:
            mas[f'ma_{period}'] = df['close'].rolling(window=period).mean()
        
        current_price = df['close'].iloc[-1]
        ma13_current = mas['ma_13'].iloc[-1]
        
        trend_strength = 0
        if not pd.isna(ma13_current):
            if (mas['ma_7'].iloc[-1] > mas['ma_13'].iloc[-1] and
                mas['ma_13'].iloc[-1] > mas['ma_30'].iloc[-1] and
                mas['ma_30'].iloc[-1] > mas['ma_45'].iloc[-1]):
                trend_strength = 1.0
            elif (mas['ma_7'].iloc[-1] > mas['ma_13'].iloc[-1] and
                  mas['ma_13'].iloc[-1] > mas['ma_30'].iloc[-1]):
                trend_strength = 0.7
            elif mas['ma_7'].iloc[-1] > mas['ma_13'].iloc[-1]:
                trend_strength = 0.4
            else:
                trend_strength = 0.0
        
        ma13_distance = 0
        if not pd.isna(ma13_current) and ma13_current > 0:
            ma13_distance = (current_price - ma13_current) / ma13_current
        
        volume_surge_ratio = 1.0
        if 'volume' in df.columns and len(df) >= 20:
            current_volume = df['volume'].iloc[-1]
            avg_volume = df['volume'].rolling(window=20).mean().iloc[-1]
            if not pd.isna(avg_volume) and avg_volume > 0:
                volume_surge_ratio = current_volume / avg_volume
        
        return {
            'trend_strength': trend_strength,
            'ma13_distance': ma13_distance,
            'volume_surge_ratio': volume_surge_ratio
        }
        
    except Exception as e:
        logger.error(f"MAè¶‹åŠ¿åˆ†æå¤±è´¥: {e}")
        return {
            'trend_strength': 0,
            'ma13_distance': 0,
            'volume_surge_ratio': 1.0
        }

def check_triple_cross_enhanced_filter(df, signal_idx, stock_code):
    """
    TRIPLE_CROSSç­–ç•¥çš„å¢å¼ºè¿‡æ»¤å™¨
    """
    try:
        advanced_filter = AdvancedTripleCrossFilter()
        should_exclude, exclude_reason, quality_score, cross_stage = advanced_filter.enhanced_triple_cross_filter(df, signal_idx)
        
        if should_exclude:
            return True, exclude_reason, {}
        
        signal_series = strategies.apply_triple_cross(df)
        if signal_series is not None:
            win_rate_filter = WinRateFilter(min_win_rate=0.4, min_signals=3, min_avg_profit=0.08)
            should_exclude_wr, exclude_reason_wr, backtest_stats = win_rate_filter.should_exclude_stock(df, signal_series, stock_code)
            
            if should_exclude_wr:
                return True, f"èƒœç‡ç­›é€‰: {exclude_reason_wr}", {'backtest_stats': backtest_stats}
        
        return False, "é€šè¿‡å¢å¼ºç­›é€‰", {'backtest_stats': backtest_stats if 'backtest_stats' in locals() else {}}
        
    except Exception as e:
        return True, f"å¢å¼ºè¿‡æ»¤å™¨æ‰§è¡Œå¤±è´¥: {e}", {}

def worker(args):
    """å¤šè¿›ç¨‹å·¥ä½œå‡½æ•° - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œæé«˜æ‰§è¡Œæ•ˆç‡"""
    file_path, market = args
    stock_code_full = os.path.basename(file_path).split('.')[0]
    stock_code_no_prefix = stock_code_full.replace(market, '')

    valid_prefixes = ('600', '601', '603', '000', '001', '002', '003', '300', '688')
    if not stock_code_no_prefix.startswith(valid_prefixes):
        return None

    try:
        df = data_loader.get_daily_data(file_path)
        if df is None or len(df) < 150:
            return None

        current_timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        latest_date = df.index[-1].strftime('%Y-%m-%d')
        
        result_base = {
            'stock_code': stock_code_full,
            'strategy': STRATEGY_TO_RUN,
            'date': latest_date,
            'scan_timestamp': current_timestamp
        }
        
        # === ä¿®æ”¹ START: æ–°å¢ç­–ç•¥è°ƒåº¦ ===
        if STRATEGY_TO_RUN == 'DAILY_MA_PULLBACK':
            return _process_daily_ma_pullback_strategy(df, result_base)
        # === ä¿®æ”¹ END ===
        elif STRATEGY_TO_RUN == 'PRE_CROSS':
            return _process_pre_cross_strategy(df, result_base)
        elif STRATEGY_TO_RUN == 'TRIPLE_CROSS':
            return _process_triple_cross_strategy(df, result_base, stock_code_full)
        elif STRATEGY_TO_RUN == 'MACD_ZERO_AXIS':
            return _process_macd_zero_axis_strategy(df, result_base, stock_code_full)
        elif STRATEGY_TO_RUN == 'WEEKLY_GOLDEN_CROSS_MA':
            return _process_weekly_golden_cross_ma_strategy(df, result_base, stock_code_full)
        
        return None
        
    except Exception as e:
        logger.error(f"å¤„ç† {stock_code_full} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return None

# === æ–°å¢ START: æ–°ç­–ç•¥çš„å¤„ç†å‡½æ•° ===
def _process_daily_ma_pullback_strategy(df, result_base):
    """å¤„ç†DAILY_MA_PULLBACKç­–ç•¥"""
    try:
        signal_series = strategies.apply_daily_ma_pullback_strategy(df)
        if signal_series is not None and signal_series.iloc[-1]:
            backtest_stats = calculate_backtest_stats_fast(df, signal_series)
            result_base.update({
                'filter_status': 'passed',
                **backtest_stats
            })
            return result_base
        return None
    except Exception as e:
        logger.error(f"å¤„ç† DAILY_MA_PULLBACK ç­–ç•¥å¤±è´¥ {result_base.get('stock_code', '')}: {e}")
        return None
# === æ–°å¢ END ===

def _process_pre_cross_strategy(df, result_base):
    """å¤„ç†PRE_CROSSç­–ç•¥"""
    try:
        signal_series = strategies.apply_pre_cross(df)
        if signal_series is not None and signal_series.iloc[-1]:
            backtest_stats = calculate_backtest_stats_fast(df, signal_series)
            result_base.update(backtest_stats)
            return result_base
        return None
    except Exception as e:
        return None

def _process_triple_cross_strategy(df, result_base, stock_code_full):
    """å¤„ç†TRIPLE_CROSSç­–ç•¥"""
    try:
        signal_series = strategies.apply_triple_cross(df)
        if signal_series is not None and signal_series.iloc[-1]:
            should_exclude, exclude_reason, filter_details = check_triple_cross_enhanced_filter(df, len(df) - 1, stock_code_full)
            
            if should_exclude:
                logger.info(f"{stock_code_full} è¢«è¿‡æ»¤: {exclude_reason}")
                return None
            
            backtest_stats = calculate_backtest_stats_fast(df, signal_series)
            result_base.update({
                'quality_score': filter_details.get('quality_score', 0),
                'cross_stage': filter_details.get('cross_stage', 'UNKNOWN'),
                'filter_status': 'passed',
                **backtest_stats
            })
            return result_base
        return None
    except Exception as e:
        return None

def _process_macd_zero_axis_strategy(df, result_base, stock_code_full):
    """å¤„ç†MACD_ZERO_AXISç­–ç•¥"""
    try:
        signal_series = strategies.apply_macd_zero_axis_strategy(df)
        signal_state = signal_series.iloc[-1]
        if signal_state in ['PRE', 'MID', 'POST']:
            should_exclude, exclude_reason = check_macd_zero_axis_pre_filter(df, len(df) - 1, signal_state)
            
            if should_exclude:
                logger.info(f"{stock_code_full} è¢«è¿‡æ»¤: {exclude_reason}")
                return None
            
            backtest_stats = calculate_backtest_stats_fast(df, signal_series)
            result_base.update({
                'signal_state': signal_state,
                'filter_status': 'passed',
                **backtest_stats
            })
            return result_base
        return None
    except Exception as e:
        return None

def _process_weekly_golden_cross_ma_strategy(df, result_base, stock_code_full):
    """å¤„ç†WEEKLY_GOLDEN_CROSS_MAç­–ç•¥"""
    try:
        signal_series = strategies.apply_weekly_golden_cross_ma_strategy(df)
        signal_state = signal_series.iloc[-1]
        
        if signal_state in ['BUY', 'HOLD', 'SELL']:
            should_exclude, exclude_reason = check_weekly_golden_cross_ma_filter(df, len(df) - 1, signal_state, stock_code_full)
            
            if should_exclude:
                logger.info(f"{stock_code_full} è¢«è¿‡æ»¤: {exclude_reason}")
                return None
            
            backtest_stats = calculate_backtest_stats_fast(df, signal_series)
            
            ma_analysis = analyze_ma_trend(df)
            
            result_base.update({
                'signal_state': signal_state,
                'filter_status': 'passed',
                'ma_trend_strength': ma_analysis.get('trend_strength', 0),
                'ma13_distance': ma_analysis.get('ma13_distance', 0),
                'volume_surge_ratio': ma_analysis.get('volume_surge_ratio', 1.0),
                **backtest_stats
            })
            return result_base
        return None
    except Exception as e:
        logger.error(f"å¤„ç†å‘¨çº¿é‡‘å‰+æ—¥çº¿MAç­–ç•¥å¤±è´¥ {stock_code_full}: {e}")
        return None

def calculate_backtest_stats_fast(df, signal_series):
    """å¿«é€Ÿè®¡ç®—å›æµ‹ç»Ÿè®¡ä¿¡æ¯ - ä¼˜åŒ–ç‰ˆæœ¬"""
    try:
        if 'dif' not in df.columns or 'dea' not in df.columns:
            macd_values = indicators.calculate_macd(df)
            df['dif'], df['dea'] = macd_values[0], macd_values[1]
        
        if 'k' not in df.columns or 'd' not in df.columns:
            kdj_values = indicators.calculate_kdj(df)
            df['k'], df['d'], df['j'] = kdj_values[0], kdj_values[1], kdj_values[2]
        
        backtest_results = backtester.run_backtest(df, signal_series)
        
        if isinstance(backtest_results, dict) and backtest_results.get('total_signals', 0) > 0:
            return {
                'total_signals': backtest_results.get('total_signals', 0),
                'win_rate': backtest_results.get('win_rate', '0.0%'),
                'avg_max_profit': backtest_results.get('avg_max_profit', '0.0%'),
                'avg_max_drawdown': backtest_results.get('avg_max_drawdown', '0.0%'),
                'avg_days_to_peak': backtest_results.get('avg_days_to_peak', '0.0 å¤©')
            }
        else:
            return {'total_signals': 0, 'win_rate': '0.0%', 'avg_max_profit': '0.0%', 'avg_max_drawdown': '0.0%', 'avg_days_to_peak': '0.0 å¤©'}
    except Exception as e:
        logger.error(f"å¿«é€Ÿå›æµ‹è®¡ç®—å¤±è´¥: {e}")
        return {'total_signals': 0, 'win_rate': '0.0%', 'avg_max_profit': '0.0%', 'avg_max_drawdown': '0.0%', 'avg_days_to_peak': '0.0 å¤©'}

def generate_summary_report(passed_stocks):
    """ç”Ÿæˆè¯¦ç»†çš„æ±‡æ€»æŠ¥å‘Š"""
    if not passed_stocks:
        return {
            'scan_summary': {'total_signals': 0, 'scan_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'strategy': STRATEGY_TO_RUN, 'total_historical_signals': 0, 'avg_win_rate': '0.0%', 'avg_profit_rate': '0.0%', 'avg_days_to_peak': '0.0 å¤©'},
            'signal_breakdown': {},
            'top_performers': []
        }
    
    total_signals = len(passed_stocks)
    
    signal_states = {}
    if STRATEGY_TO_RUN == 'MACD_ZERO_AXIS':
        for stock in passed_stocks:
            state = stock.get('signal_state', 'UNKNOWN')
            if state not in signal_states:
                signal_states[state] = []
            signal_states[state].append(stock)
    
    total_historical_signals = sum(stock.get('total_signals', 0) for stock in passed_stocks if stock.get('total_signals', 0) > 0)
    
    win_rates = [float(s.get('win_rate', '0.0%').replace('%', '')) for s in passed_stocks if s.get('total_signals', 0) > 0]
    profit_rates = [float(s.get('avg_max_profit', '0.0%').replace('%', '')) for s in passed_stocks if s.get('total_signals', 0) > 0]
    days_to_peak = [float(s.get('avg_days_to_peak', '0.0 å¤©').replace(' å¤©', '')) for s in passed_stocks if s.get('total_signals', 0) > 0]
    
    avg_win_rate = sum(win_rates) / len(win_rates) if win_rates else 0
    avg_profit_rate = sum(profit_rates) / len(profit_rates) if profit_rates else 0
    avg_days_to_peak = sum(days_to_peak) / len(days_to_peak) if days_to_peak else 0
    
    summary = {
        'scan_summary': {
            'total_signals': total_signals, 'scan_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'strategy': STRATEGY_TO_RUN, 'total_historical_signals': total_historical_signals, 'avg_win_rate': f"{avg_win_rate:.1f}%", 'avg_profit_rate': f"{avg_profit_rate:.1f}%", 'avg_days_to_peak': f"{avg_days_to_peak:.1f} å¤©"
        },
        'signal_breakdown': signal_states if signal_states else {},
        'top_performers': sorted([s for s in passed_stocks if s.get('total_signals', 0) > 0], key=lambda x: float(x.get('avg_max_profit', '0%').replace('%', '')), reverse=True)[:10] if passed_stocks else []
    }
    
    return summary

def trigger_deep_scan_multithreaded(passed_stocks):
    """è§¦å‘å¤šçº¿ç¨‹æ·±åº¦æ‰«æ"""
    if not passed_stocks:
        print("âš ï¸ æ²¡æœ‰é€šè¿‡ç­›é€‰çš„è‚¡ç¥¨ï¼Œè·³è¿‡æ·±åº¦æ‰«æ")
        return None
    
    print(f"\nğŸ” è§¦å‘å¤šçº¿ç¨‹æ·±åº¦æ‰«æ...")
    print(f"ğŸ“Š ç­›é€‰å‡º {len(passed_stocks)} åªè‚¡ç¥¨è¿›è¡Œæ·±åº¦åˆ†æ")
    
    stock_codes = [stock['stock_code'] for stock in passed_stocks]
    
    try:
        from run_enhanced_screening import deep_scan_stocks
        max_workers = min(cpu_count() * 2, len(stock_codes), 32)
        print(f"ğŸ§µ ä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹è¿›è¡Œæ·±åº¦æ‰«æ")
        deep_scan_results = deep_scan_stocks(stock_codes, use_optimized_params=True, max_workers=max_workers)
        print(f"âœ… å¤šçº¿ç¨‹æ·±åº¦æ‰«æå®Œæˆ")
        return deep_scan_results
        
    except Exception as e:
        print(f"âŒ å¤šçº¿ç¨‹æ·±åº¦æ‰«æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def main():
    """ä¸»æ‰§è¡Œå‡½æ•° - å¢å¼ºç‰ˆæœ¬ï¼Œé›†æˆæ·±åº¦æ‰«æï¼Œå¤šçº¿ç¨‹æ“ä½œ"""
    start_time = datetime.now()
    logger.info(f"===== å¼€å§‹æ‰§è¡Œæ‰¹é‡ç­›é€‰, ç­–ç•¥: {STRATEGY_TO_RUN} =====")
    print(f"ğŸš€ å¼€å§‹æ‰§è¡Œæ‰¹é‡ç­›é€‰, ç­–ç•¥: {STRATEGY_TO_RUN}")
    print(f"â° æ‰«ææ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    all_files = []
    for market in MARKETS:
        path = os.path.join(BASE_PATH, market, 'lday', '*.day')
        files = glob.glob(path)
        if not files:
            print(f"âš ï¸ è­¦å‘Š: åœ¨è·¯å¾„ {path} æœªæ‰¾åˆ°ä»»ä½•æ–‡ä»¶ã€‚")
        all_files.extend([(f, market) for f in files])
    
    if not all_files:
        print("âŒ é”™è¯¯: æœªèƒ½åœ¨ä»»ä½•å¸‚åœºç›®å½•ä¸‹æ‰¾åˆ°æ—¥çº¿æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥BASE_PATHé…ç½®ã€‚")
        return

    print(f"ğŸ“Š å…±æ‰¾åˆ° {len(all_files)} ä¸ªæ—¥çº¿æ–‡ä»¶ï¼Œå¼€å§‹å¤šè¿›ç¨‹å¤„ç†...")
    
    with Pool(processes=cpu_count()) as pool:
        results = pool.map(worker, all_files)
    
    passed_stocks = [r for r in results if r is not None]
    end_time = datetime.now()
    processing_time = (end_time - start_time).total_seconds()
    
    print(f"ğŸ“ˆ åˆæ­¥ç­›é€‰å®Œæˆï¼Œé€šè¿‡ç­›é€‰: {len(passed_stocks)} åªè‚¡ç¥¨")
    
    output_file = os.path.join(RESULT_DIR, 'signals_summary.json')
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(passed_stocks, f, ensure_ascii=False, indent=4)
    
    summary_report = generate_summary_report(passed_stocks)
    summary_report['scan_summary']['processing_time'] = f"{processing_time:.2f} ç§’"
    summary_report['scan_summary']['files_processed'] = len(all_files)
    
    summary_file = os.path.join(RESULT_DIR, 'scan_summary_report.json')
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary_report, f, ensure_ascii=False, indent=4)
    
    text_report_file = os.path.join(RESULT_DIR, f'scan_report_{DATE}.txt')
    with open(text_report_file, 'w', encoding='utf-8') as f:
        f.write(f"=== {STRATEGY_TO_RUN} ç­–ç•¥ç­›é€‰æŠ¥å‘Š ===\n")
        f.write(f"æ‰«ææ—¶é—´: {summary_report['scan_summary']['scan_timestamp']}\n")
        f.write(f"å¤„ç†æ–‡ä»¶æ•°: {summary_report['scan_summary']['files_processed']}\n")
        f.write(f"å¤„ç†è€—æ—¶: {summary_report['scan_summary']['processing_time']}\n")
        f.write(f"å‘ç°ä¿¡å·æ•°: {summary_report['scan_summary']['total_signals']}\n")
        f.write(f"å†å²ä¿¡å·æ€»æ•°: {summary_report['scan_summary'].get('total_historical_signals', 0)}\n")
        f.write(f"å¹³å‡èƒœç‡: {summary_report['scan_summary']['avg_win_rate']}\n")
        f.write(f"å¹³å‡æ”¶ç›Šç‡: {summary_report['scan_summary']['avg_profit_rate']}\n")
        f.write(f"å¹³å‡è¾¾å³°å¤©æ•°: {summary_report['scan_summary']['avg_days_to_peak']}\n\n")
        
        if summary_report['signal_breakdown']:
            f.write("=== ä¿¡å·çŠ¶æ€åˆ†å¸ƒ ===\n")
            for state, stocks in summary_report['signal_breakdown'].items():
                f.write(f"{state}: {len(stocks)} ä¸ª\n")
            f.write("\n")
        
        if summary_report['top_performers']:
            f.write("=== å‰10åè¡¨ç°æœ€ä½³è‚¡ç¥¨ ===\n")
            for i, stock in enumerate(summary_report['top_performers'], 1):
                f.write(f"{i:2d}. {stock['stock_code']} - èƒœç‡: {stock.get('win_rate', 'N/A')}, "
                       f"æ”¶ç›Š: {stock.get('avg_max_profit', 'N/A')}, "
                       f"å¤©æ•°: {stock.get('avg_days_to_peak', 'N/A')}\n")
    
    print(f"\nğŸ“Š åˆæ­¥ç­›é€‰å®Œæˆï¼")
    print(f"ğŸ¯ å‘ç°ä¿¡å·: {len(passed_stocks)} ä¸ª")
    print(f"â±ï¸ å¤„ç†è€—æ—¶: {processing_time:.2f} ç§’")
    print(f"ğŸ“ˆ å¹³å‡èƒœç‡: {summary_report['scan_summary']['avg_win_rate']}")
    print(f"ğŸ’° å¹³å‡æ”¶ç›Š: {summary_report['scan_summary']['avg_profit_rate']}")
    print(f"ğŸ“„ ç»“æœå·²ä¿å­˜è‡³:")
    print(f"  - ä¿¡å·åˆ—è¡¨: {output_file}")
    print(f"  - æ±‡æ€»æŠ¥å‘Š: {summary_file}")
    print(f"  - æ–‡æœ¬æŠ¥å‘Š: {text_report_file}")
    
    if len(passed_stocks) > 0:
        print(f"\n" + "="*60)
        print(f"ğŸ” å¯åŠ¨æ·±åº¦æ‰«æé˜¶æ®µ (å¤šçº¿ç¨‹)")
        print(f"="*60)
        
        deep_scan_results = trigger_deep_scan_multithreaded(passed_stocks)
        
        if deep_scan_results:
            valid_deep_results = {k: v for k, v in deep_scan_results.items() if 'error' not in v}
            a_grade_stocks = [k for k, v in valid_deep_results.items() if v.get('overall_score', {}).get('grade') == 'A']
            price_evaluated_stocks = [k for k, v in valid_deep_results.items() if 'price_evaluation' in v]
            buy_recommendations = [k for k, v in valid_deep_results.items() if v.get('recommendation', {}).get('action') == 'BUY']
            
            print(f"\nğŸ‰ æ·±åº¦æ‰«æç»“æœ:")
            print(f"ğŸ“Š æ·±åº¦åˆ†ææˆåŠŸ: {len(valid_deep_results)}/{len(passed_stocks)}")
            print(f"ğŸ† Açº§è‚¡ç¥¨å‘ç°: {len(a_grade_stocks)}")
            print(f"ğŸ’° ä»·æ ¼è¯„ä¼°å®Œæˆ: {len(price_evaluated_stocks)}")
            print(f"ğŸŸ¢ ä¹°å…¥æ¨è: {len(buy_recommendations)}")
            
            if a_grade_stocks:
                print(f"\nğŸŒŸ Açº§è‚¡ç¥¨åˆ—è¡¨:")
                for stock_code in a_grade_stocks:
                    result = valid_deep_results[stock_code]
                    score = result['overall_score']['total_score']
                    price = result['basic_analysis']['current_price']
                    action = result['recommendation']['action']
                    confidence = result['recommendation']['confidence']
                    price_eval_mark = " ğŸ’°" if 'price_evaluation' in result else ""
                    print(f"  ğŸ† {stock_code}: {score:.1f}åˆ†, Â¥{price:.2f}, {action} ({confidence:.1%}){price_eval_mark}")
            
            summary_report['deep_scan_summary'] = {
                'total_analyzed': len(valid_deep_results), 'a_grade_count': len(a_grade_stocks), 'price_evaluated_count': len(price_evaluated_stocks), 'buy_recommendations': len(buy_recommendations), 'a_grade_stocks': a_grade_stocks, 'buy_recommendation_stocks': buy_recommendations
            }
            
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary_report, f, ensure_ascii=False, indent=4)
            
            with open(text_report_file, 'a', encoding='utf-8') as f:
                f.write(f"\n=== æ·±åº¦æ‰«æç»“æœ (å¤šçº¿ç¨‹) ===\n")
                f.write(f"æ·±åº¦åˆ†ææˆåŠŸ: {len(valid_deep_results)}/{len(passed_stocks)}\n")
                f.write(f"Açº§è‚¡ç¥¨å‘ç°: {len(a_grade_stocks)}\n")
                f.write(f"ä»·æ ¼è¯„ä¼°å®Œæˆ: {len(price_evaluated_stocks)}\n")
                f.write(f"ä¹°å…¥æ¨è: {len(buy_recommendations)}\n\n")
                
                if a_grade_stocks:
                    f.write("=== Açº§è‚¡ç¥¨è¯¦æƒ… ===\n")
                    for stock_code in a_grade_stocks:
                        result = valid_deep_results[stock_code]
                        score = result['overall_score']['total_score']
                        price = result['basic_analysis']['current_price']
                        action = result['recommendation']['action']
                        confidence = result['recommendation']['confidence']
                        price_eval_mark = " [å·²è¯„ä¼°]" if 'price_evaluation' in result else ""
                        f.write(f"{stock_code}: {score:.1f}åˆ†, Â¥{price:.2f}, {action} (ä¿¡å¿ƒåº¦: {confidence:.1%}){price_eval_mark}\n")
                
                if buy_recommendations:
                    f.write(f"\n=== ä¹°å…¥æ¨èè‚¡ç¥¨ ===\n")
                    for stock_code in buy_recommendations:
                        result = valid_deep_results[stock_code]
                        score = result['overall_score']['total_score']
                        price = result['basic_analysis']['current_price']
                        confidence = result['recommendation']['confidence']
                        f.write(f"{stock_code}: {score:.1f}åˆ†, Â¥{price:.2f}, ä¿¡å¿ƒåº¦: {confidence:.1%}\n")
    else:
        print(f"\nâš ï¸ æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ï¼Œè·³è¿‡æ·±åº¦æ‰«æ")
    
    total_time = (datetime.now() - start_time).total_seconds()
    print(f"\nğŸ‰ å®Œæ•´æ‰«ææµç¨‹ç»“æŸï¼æ€»è€—æ—¶: {total_time:.2f} ç§’")
    
    logger.info(f"===== å®Œæ•´æ‰«æå®Œæˆï¼åˆæ­¥ç­›é€‰: {len(passed_stocks)} ä¸ªä¿¡å·ï¼Œæ€»è€—æ—¶: {total_time:.2f} ç§’ =====")

if __name__ == '__main__':
    main()
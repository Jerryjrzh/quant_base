import os
import glob
import json
import pandas as pd
import numpy as np
from multiprocessing import Pool, cpu_count
from datetime import datetime, timedelta
import logging
import warnings
import struct
warnings.filterwarnings('ignore')

# --- é…ç½® ---
BASE_PATH = os.path.expanduser("~/.local/share/tdxcfv/drive_c/tc/vipdoc")
MARKETS = ['sh', 'sz', 'bj']
STRATEGY_TO_RUN = 'ABYSS_BOTTOMING_OPTIMIZED'

# --- è·¯å¾„å®šä¹‰ ---
backend_dir = os.path.dirname(os.path.abspath(__file__))
OUTPUT_PATH = os.path.abspath(os.path.join(backend_dir, '..', 'data', 'result'))
CONFIG_FILE = os.path.join(backend_dir, 'abyss_config.json')

# --- åˆå§‹åŒ–æ—¥å¿— ---
DATE = datetime.now().strftime("%Y%m%d_%H%M")
RESULT_DIR = os.path.join(OUTPUT_PATH, STRATEGY_TO_RUN)
os.makedirs(RESULT_DIR, exist_ok=True)
LOG_FILE = os.path.join(RESULT_DIR, f'log_screener_{DATE}.txt')

# è®¾ç½®æ›´è¯¦ç»†çš„æ—¥å¿—è®°å½•
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(LOG_FILE, 'a', 'utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('abyss_screener')

# --- åŠ è½½é…ç½® ---
def load_config():
    """åŠ è½½ç­–ç•¥é…ç½®"""
    try:
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
            config = json.load(f)
            logger.info(f"æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {config['strategy_name']} v{config['version']}")
            return config
    except Exception as e:
        logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        # è¿”å›é»˜è®¤é…ç½®
        return {
            "core_parameters": {
                "deep_decline_phase": {
                    "long_term_days": 400,
                    "min_drop_percent": 0.40,
                    "price_low_percentile": 0.35
                },
                "volume_analysis": {
                    "volume_shrink_threshold": 0.70,
                    "volume_consistency_threshold": 0.30,
                    "volume_analysis_days": 30
                }
            }
        }

CONFIG = load_config()


def read_day_file(file_path):
    """
    è¯»å–é€šè¾¾ä¿¡.dayæ–‡ä»¶
    """
    try:
        with open(file_path, 'rb') as f:
            data = []
            while True:
                chunk = f.read(32)  # æ¯æ¡è®°å½•32å­—èŠ‚
                if len(chunk) < 32:
                    break
                
                # è§£ææ•°æ®ç»“æ„
                date, open_price, high, low, close, amount, volume, _ = struct.unpack('<IIIIIIII', chunk)
                
                # è½¬æ¢æ—¥æœŸæ ¼å¼
                year = date // 10000
                month = (date % 10000) // 100
                day = date % 100
                
                # ä»·æ ¼éœ€è¦é™¤ä»¥100
                data.append({
                    'date': f"{year:04d}-{month:02d}-{day:02d}",
                    'open': open_price / 100.0,
                    'high': high / 100.0,
                    'low': low / 100.0,
                    'close': close / 100.0,
                    'volume': volume,
                    'amount': amount
                })
        
        if not data:
            return None
            
        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame(data)
        df['date'] = pd.to_datetime(df['date'])
        df.set_index('date', inplace=True)
        df.sort_index(inplace=True)
        
        return df
        
    except Exception as e:
        logger.error(f"è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return None


class AbyssBottomingStrategy:
    """
    æ·±æ¸Šç­‘åº•ç­–ç•¥ - ç»è¿‡æµ‹è¯•éªŒè¯çš„ä¼˜åŒ–ç‰ˆæœ¬
    """
    
    def __init__(self, config=None):
        if config is None:
            config = CONFIG
        
        # æå–æ ¸å¿ƒå‚æ•°
        core_params = config.get('core_parameters', {})
        
        self.config = {
            # æ·±è·Œç­‘åº•å‚æ•°
            'long_term_days': core_params.get('deep_decline_phase', {}).get('long_term_days', 400),
            'min_drop_percent': core_params.get('deep_decline_phase', {}).get('min_drop_percent', 0.40),
            'price_low_percentile': core_params.get('deep_decline_phase', {}).get('price_low_percentile', 0.35),
            
            # æˆäº¤é‡åˆ†æå‚æ•°
            'volume_shrink_threshold': core_params.get('volume_analysis', {}).get('volume_shrink_threshold', 0.70),
            'volume_consistency_threshold': core_params.get('volume_analysis', {}).get('volume_consistency_threshold', 0.30),
            'volume_analysis_days': core_params.get('volume_analysis', {}).get('volume_analysis_days', 30),
            
            # å…¶ä»–å‚æ•°
            'hibernation_days': core_params.get('hibernation_phase', {}).get('hibernation_days', 40),
            'hibernation_volatility_max': core_params.get('hibernation_phase', {}).get('hibernation_volatility_max', 0.40),
            'washout_days': core_params.get('washout_phase', {}).get('washout_days', 15),
            'washout_volume_shrink_ratio': core_params.get('washout_phase', {}).get('washout_volume_shrink_ratio', 0.85),
            'max_rise_from_bottom': core_params.get('liftoff_phase', {}).get('max_rise_from_bottom', 0.18),
            'liftoff_volume_increase_ratio': core_params.get('liftoff_phase', {}).get('liftoff_volume_increase_ratio', 1.15),
        }
        
        logger.info(f"ç­–ç•¥åˆå§‹åŒ–å®Œæˆï¼Œå‚æ•°: {self.config}")
    
    def calculate_technical_indicators(self, df):
        """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡"""
        try:
            # ç§»åŠ¨å¹³å‡çº¿
            df['ma7'] = df['close'].rolling(window=7).mean()
            df['ma13'] = df['close'].rolling(window=13).mean()
            df['ma30'] = df['close'].rolling(window=30).mean()
            df['ma45'] = df['close'].rolling(window=45).mean()
            
            # RSIæŒ‡æ ‡
            delta = df['close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            df['rsi'] = 100 - (100 / (1 + rs))
            
            # MACDæŒ‡æ ‡
            exp1 = df['close'].ewm(span=12).mean()
            exp2 = df['close'].ewm(span=26).mean()
            df['macd'] = exp1 - exp2
            df['macd_signal'] = df['macd'].ewm(span=9).mean()
            df['macd_histogram'] = df['macd'] - df['macd_signal']
            
            # æˆäº¤é‡ç§»åŠ¨å¹³å‡
            df['volume_ma20'] = df['volume'].rolling(window=20).mean()
            df['volume_ma60'] = df['volume'].rolling(window=60).mean()
            
            return df
        except Exception as e:
            logger.error(f"è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å¤±è´¥: {e}")
            return df
    
    def analyze_volume_shrinkage(self, df):
        """
        åˆ†ææˆäº¤é‡èç¼©æƒ…å†µ - æ ¸å¿ƒä¼˜åŒ–é€»è¾‘
        """
        try:
            if len(df) < 250:
                return False, "æ•°æ®ä¸è¶³"
            
            volumes = df['volume'].values
            
            # 1. è®¡ç®—å†å²å¹³å‡æˆäº¤é‡ï¼ˆä½¿ç”¨å‰åŠæ®µæ•°æ®ä½œä¸ºåŸºå‡†ï¼‰
            historical_volumes = volumes[:len(volumes)//2]
            historical_avg = np.mean(historical_volumes)
            
            # 2. è®¡ç®—æœ€è¿‘æˆäº¤é‡
            recent_days = self.config['volume_analysis_days']
            recent_volumes = volumes[-recent_days:]
            recent_avg = np.mean(recent_volumes)
            
            # 3. è®¡ç®—èç¼©æ¯”ä¾‹
            shrink_ratio = recent_avg / historical_avg if historical_avg > 0 else 1.0
            is_volume_shrunk = shrink_ratio <= self.config['volume_shrink_threshold']
            
            # 4. æ£€æŸ¥åœ°é‡çš„æŒç»­æ€§
            threshold_volume = historical_avg * self.config['volume_shrink_threshold']
            low_volume_days = sum(1 for v in recent_volumes if v <= threshold_volume)
            consistency_ratio = low_volume_days / len(recent_volumes)
            is_consistent = consistency_ratio >= self.config['volume_consistency_threshold']
            
            # 5. é¢å¤–æ£€æŸ¥ï¼šæœ€è¿‘æˆäº¤é‡åº”è¯¥æ˜æ˜¾ä½äºé•¿æœŸä¸­ä½æ•°
            long_term_median = np.percentile(volumes, 50)
            recent_vs_median = recent_avg / long_term_median if long_term_median > 0 else 1.0
            
            details = {
                'historical_avg': historical_avg,
                'recent_avg': recent_avg,
                'shrink_ratio': shrink_ratio,
                'consistency_ratio': consistency_ratio,
                'long_term_median': long_term_median,
                'recent_vs_median': recent_vs_median,
                'is_volume_shrunk': is_volume_shrunk,
                'is_consistent': is_consistent,
                'threshold_volume': threshold_volume
            }
            
            # ç»¼åˆåˆ¤æ–­ï¼šæˆäº¤é‡èç¼© ä¸” æœ‰æŒç»­æ€§
            volume_ok = is_volume_shrunk and is_consistent
            
            return volume_ok, details
            
        except Exception as e:
            logger.error(f"æˆäº¤é‡åˆ†æå¤±è´¥: {e}")
            return False, str(e)
    
    def check_deep_decline_phase(self, df):
        """
        ç¬¬é›¶é˜¶æ®µï¼šæ·±è·Œç­‘åº•æ£€æŸ¥ - ç»è¿‡æµ‹è¯•éªŒè¯çš„é€»è¾‘
        """
        try:
            long_term_days = self.config['long_term_days']
            if len(df) < long_term_days:
                return False, "æ•°æ®é•¿åº¦ä¸è¶³"
            
            # è·å–é•¿æœŸæ•°æ®
            long_term_data = df.tail(long_term_days)
            long_term_high = long_term_data['high'].max()
            long_term_low = long_term_data['low'].min()
            current_price = df['close'].iloc[-1]
            
            # 1. æ£€æŸ¥ä»·æ ¼ä½ç½®
            price_range = long_term_high - long_term_low
            if price_range == 0:
                return False, "ä»·æ ¼æ— æ³¢åŠ¨"
            
            price_position = (current_price - long_term_low) / price_range
            price_position_ok = price_position <= self.config['price_low_percentile']
            
            # 2. æ£€æŸ¥ä¸‹è·Œå¹…åº¦
            drop_percent = (long_term_high - current_price) / long_term_high
            drop_percent_ok = drop_percent >= self.config['min_drop_percent']
            
            # 3. ä½¿ç”¨ä¼˜åŒ–çš„æˆäº¤é‡åˆ†æ
            volume_ok, volume_details = self.analyze_volume_shrinkage(df)
            
            # ç»¼åˆåˆ¤æ–­
            conditions = {
                'price_position_ok': price_position_ok,
                'drop_percent_ok': drop_percent_ok,
                'volume_ok': volume_ok
            }
            
            all_ok = all(conditions.values())
            
            details = {
                'drop_percent': drop_percent,
                'price_position': price_position,
                'long_term_high': long_term_high,
                'long_term_low': long_term_low,
                'current_price': current_price,
                'conditions': conditions,
                'volume_analysis': volume_details
            }
            
            return all_ok, details
            
        except Exception as e:
            logger.error(f"æ·±è·Œç­‘åº•æ£€æŸ¥å¤±è´¥: {e}")
            return False, str(e)
    
    def check_hibernation_phase(self, df):
        """ç¬¬ä¸€é˜¶æ®µï¼šæ¨ªç›˜è“„åŠ¿æ£€æŸ¥"""
        try:
            washout_days = self.config['washout_days']
            hibernation_days = self.config['hibernation_days']
            
            # è·å–æ¨ªç›˜æœŸæ•°æ®
            start_idx = -(washout_days + hibernation_days)
            end_idx = -washout_days if washout_days > 0 else len(df)
            hibernation_data = df.iloc[start_idx:end_idx]
            
            if hibernation_data.empty:
                return False, "æ¨ªç›˜æœŸæ•°æ®ä¸ºç©º"
            
            # è®¡ç®—æ¨ªç›˜åŒºé—´
            support_level = hibernation_data['low'].min()
            resistance_level = hibernation_data['high'].max()
            
            # æ£€æŸ¥æ³¢åŠ¨ç‡
            volatility = (resistance_level - support_level) / support_level if support_level > 0 else float('inf')
            volatility_ok = volatility <= self.config['hibernation_volatility_max']
            
            # æ£€æŸ¥å‡çº¿æ”¶æ•›
            if 'ma7' in hibernation_data.columns and 'ma30' in hibernation_data.columns:
                ma_values = hibernation_data[['ma7', 'ma13', 'ma30', 'ma45']].iloc[-1]
                ma_range = (ma_values.max() - ma_values.min()) / ma_values.mean()
                ma_convergence_ok = ma_range <= 0.05
            else:
                ma_convergence_ok = True
            
            # æ£€æŸ¥æˆäº¤é‡ç¨³å®šæ€§
            avg_volume = hibernation_data['volume'].mean()
            volume_stability = hibernation_data['volume'].std() / avg_volume if avg_volume > 0 else float('inf')
            
            details = {
                'support_level': support_level,
                'resistance_level': resistance_level,
                'volatility': volatility,
                'volatility_ok': volatility_ok,
                'ma_convergence_ok': ma_convergence_ok,
                'avg_volume': avg_volume,
                'volume_stability': volume_stability
            }
            
            return volatility_ok and ma_convergence_ok, details
            
        except Exception as e:
            logger.error(f"æ¨ªç›˜è“„åŠ¿æ£€æŸ¥å¤±è´¥: {e}")
            return False, str(e)
    
    def check_washout_phase(self, df, hibernation_info):
        """ç¬¬äºŒé˜¶æ®µï¼šç¼©é‡æŒ–å‘æ£€æŸ¥"""
        try:
            washout_days = self.config['washout_days']
            washout_data = df.tail(washout_days)
            
            if washout_data.empty:
                return False, "æŒ–å‘æœŸæ•°æ®ä¸ºç©º"
            
            support_level = hibernation_info['support_level']
            hibernation_avg_volume = hibernation_info['avg_volume']
            
            # æ£€æŸ¥æ˜¯å¦è·Œç ´æ”¯æ’‘
            washout_low = washout_data['low'].min()
            support_broken = washout_low < support_level * 0.95
            
            # æ£€æŸ¥æŒ–å‘æœŸçš„ç¼©é‡ç‰¹å¾
            pit_days = washout_data[washout_data['low'] < support_level]
            if pit_days.empty:
                return False, "æ— æœ‰æ•ˆæŒ–å‘æ•°æ®"
            
            pit_avg_volume = pit_days['volume'].mean()
            volume_shrink_ratio = pit_avg_volume / hibernation_avg_volume if hibernation_avg_volume > 0 else float('inf')
            volume_shrink_ok = volume_shrink_ratio <= self.config['washout_volume_shrink_ratio']
            
            conditions = {
                'support_broken': support_broken,
                'volume_shrink_ok': volume_shrink_ok
            }
            
            all_ok = all(conditions.values())
            
            details = {
                'washout_low': washout_low,
                'support_break': (support_level - washout_low) / support_level if support_level > 0 else 0,
                'volume_shrink_ratio': volume_shrink_ratio,
                'pit_days_count': len(pit_days),
                'conditions': conditions
            }
            
            return all_ok, details
            
        except Exception as e:
            logger.error(f"ç¼©é‡æŒ–å‘æ£€æŸ¥å¤±è´¥: {e}")
            return False, str(e)
    
    def check_liftoff_confirmation(self, df, washout_info):
        """ç¬¬ä¸‰é˜¶æ®µï¼šç¡®è®¤æ‹‰å‡æ£€æŸ¥"""
        try:
            washout_low = washout_info['washout_low']
            recent_data = df.tail(3)  # æœ€è¿‘3å¤©
            
            if recent_data.empty:
                return False, "ç¡®è®¤æœŸæ•°æ®ä¸è¶³"
            
            latest = recent_data.iloc[-1]
            prev = recent_data.iloc[-2] if len(recent_data) > 1 else latest
            
            # æ¡ä»¶1ï¼šä»·æ ¼ä¼ç¨³å›å‡
            is_price_recovering = (
                latest['close'] > latest['open'] and  # å½“æ—¥é˜³çº¿
                latest['close'] > prev['close'] and   # ä»·æ ¼ä¸Šæ¶¨
                latest['low'] >= washout_low * 0.98   # æœªåˆ›æ–°ä½
            )
            
            # æ¡ä»¶2ï¼šå°šæœªè¿œç¦»å‘åº•
            rise_from_bottom = (latest['close'] - washout_low) / washout_low if washout_low > 0 else 0
            is_near_bottom = rise_from_bottom <= self.config['max_rise_from_bottom']
            
            # æ¡ä»¶3ï¼šæˆäº¤é‡æ¸©å’Œæ”¾å¤§
            recent_volumes = df['volume'].tail(10).mean()
            volume_increase = latest['volume'] / recent_volumes if recent_volumes > 0 else 0
            is_volume_confirming = volume_increase >= self.config['liftoff_volume_increase_ratio']
            
            # æ¡ä»¶4ï¼šæŠ€æœ¯æŒ‡æ ‡é…åˆ
            rsi_ok = 25 <= latest.get('rsi', 50) <= 60 if 'rsi' in latest else True
            macd_improving = latest.get('macd', 0) > prev.get('macd', 0) if 'macd' in latest else True
            
            conditions = {
                'price_recovering': is_price_recovering,
                'near_bottom': is_near_bottom,
                'volume_confirming': is_volume_confirming,
                'rsi_ok': rsi_ok,
                'macd_improving': macd_improving
            }
            
            conditions_met = sum(conditions.values())
            all_ok = conditions_met >= 3  # è‡³å°‘æ»¡è¶³3ä¸ªæ¡ä»¶
            
            details = {
                'rise_from_bottom': rise_from_bottom,
                'volume_increase': volume_increase,
                'conditions_met': conditions_met,
                'total_conditions': len(conditions),
                'conditions': conditions
            }
            
            return all_ok, details
            
        except Exception as e:
            logger.error(f"æ‹‰å‡ç¡®è®¤æ£€æŸ¥å¤±è´¥: {e}")
            return False, str(e)
    
    def apply_strategy(self, df):
        """
        åº”ç”¨å®Œæ•´çš„æ·±æ¸Šç­‘åº•ç­–ç•¥
        """
        try:
            if len(df) < self.config['long_term_days']:
                return None, None
            
            # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
            df = self.calculate_technical_indicators(df)
            
            # ç¬¬é›¶é˜¶æ®µï¼šæ·±è·Œç­‘åº•æ£€æŸ¥ï¼ˆå¿…é¡»é€šè¿‡ï¼‰
            deep_decline_ok, deep_decline_info = self.check_deep_decline_phase(df)
            if not deep_decline_ok:
                return None, None
            
            # ç¬¬ä¸€é˜¶æ®µï¼šæ¨ªç›˜è“„åŠ¿æ£€æŸ¥
            hibernation_ok, hibernation_info = self.check_hibernation_phase(df)
            if not hibernation_ok:
                # å¦‚æœæ¨ªç›˜æ£€æŸ¥æœªé€šè¿‡ï¼Œä½†æ·±è·Œæ£€æŸ¥é€šè¿‡ï¼Œä»å¯ä»¥ä½œä¸ºæ½œåœ¨ä¿¡å·
                signal_series = pd.Series(index=df.index, dtype=object).fillna('')
                signal_series.iloc[-1] = 'POTENTIAL_BUY'
                
                signal_details = {
                    'signal_state': 'DEEP_DECLINE_ONLY',
                    'stage_passed': 1,
                    'deep_decline': deep_decline_info,
                    'hibernation': hibernation_info,
                    'strategy_version': 'optimized_v2.0'
                }
                
                return signal_series, signal_details
            
            # ç¬¬äºŒé˜¶æ®µï¼šç¼©é‡æŒ–å‘æ£€æŸ¥
            washout_ok, washout_info = self.check_washout_phase(df, hibernation_info)
            if not washout_ok:
                # å‰ä¸¤é˜¶æ®µé€šè¿‡ï¼Œä½œä¸ºè¾ƒå¼ºä¿¡å·
                signal_series = pd.Series(index=df.index, dtype=object).fillna('')
                signal_series.iloc[-1] = 'BUY'
                
                signal_details = {
                    'signal_state': 'HIBERNATION_CONFIRMED',
                    'stage_passed': 2,
                    'deep_decline': deep_decline_info,
                    'hibernation': hibernation_info,
                    'washout': washout_info,
                    'strategy_version': 'optimized_v2.0'
                }
                
                return signal_series, signal_details
            
            # ç¬¬ä¸‰é˜¶æ®µï¼šç¡®è®¤æ‹‰å‡æ£€æŸ¥
            liftoff_ok, liftoff_info = self.check_liftoff_confirmation(df, washout_info)
            
            # ç”Ÿæˆæœ€ç»ˆä¿¡å·
            signal_series = pd.Series(index=df.index, dtype=object).fillna('')
            
            if liftoff_ok:
                signal_series.iloc[-1] = 'STRONG_BUY'
                signal_state = 'FULL_ABYSS_CONFIRMED'
                stage_passed = 4
            else:
                signal_series.iloc[-1] = 'BUY'
                signal_state = 'WASHOUT_CONFIRMED'
                stage_passed = 3
            
            # æ•´åˆæ‰€æœ‰é˜¶æ®µä¿¡æ¯
            signal_details = {
                'signal_state': signal_state,
                'stage_passed': stage_passed,
                'deep_decline': deep_decline_info,
                'hibernation': hibernation_info,
                'washout': washout_info,
                'liftoff': liftoff_info,
                'strategy_version': 'optimized_v2.0'
            }
            
            return signal_series, signal_details
            
        except Exception as e:
            logger.error(f"æ·±æ¸Šç­‘åº•ç­–ç•¥æ‰§è¡Œå¤±è´¥: {e}")
            return None, None


# å…¨å±€ç­–ç•¥å®ä¾‹
abyss_strategy = AbyssBottomingStrategy()


def is_valid_stock_code(stock_code, market):
    """æ£€æŸ¥è‚¡ç¥¨ä»£ç æ˜¯å¦æœ‰æ•ˆ"""
    try:
        # è·å–é…ç½®ä¸­çš„æœ‰æ•ˆå‰ç¼€
        valid_prefixes = CONFIG.get('market_filters', {}).get('valid_prefixes', {})
        market_prefixes = valid_prefixes.get(market, [])
        
        if not market_prefixes:
            # é»˜è®¤å‰ç¼€
            if market == 'sh':
                market_prefixes = ['600', '601', '603', '605', '688']
            elif market == 'sz':
                market_prefixes = ['000', '001', '002', '003', '300']
            elif market == 'bj':
                market_prefixes = ['430', '831', '832', '833', '834', '835', '836', '837', '838', '839']
        
        stock_code_no_prefix = stock_code.replace(market, '')
        return any(stock_code_no_prefix.startswith(prefix) for prefix in market_prefixes)
        
    except Exception as e:
        logger.error(f"æ£€æŸ¥è‚¡ç¥¨ä»£ç å¤±è´¥ {stock_code}: {e}")
        return False


def worker(args):
    """å¤šè¿›ç¨‹å·¥ä½œå‡½æ•°"""
    file_path, market = args
    stock_code_full = os.path.basename(file_path).split('.')[0]
    
    # æ£€æŸ¥è‚¡ç¥¨ä»£ç æœ‰æ•ˆæ€§
    if not is_valid_stock_code(stock_code_full, market):
        return None

    try:
        # è¯»å–è‚¡ç¥¨æ•°æ®
        df = read_day_file(file_path)
        if df is None or len(df) < abyss_strategy.config['long_term_days']:
            return None

        # åº”ç”¨ç­–ç•¥
        signal_series, details = abyss_strategy.apply_strategy(df)
        
        if signal_series is not None and details is not None:
            # æ£€æŸ¥æœ€æ–°ä¸€å¤©æ˜¯å¦æœ‰ä¿¡å·
            latest_signal = signal_series.iloc[-1]
            if latest_signal in ['POTENTIAL_BUY', 'BUY', 'STRONG_BUY']:
                current_timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                latest_date = df.index[-1].strftime('%Y-%m-%d')
                
                result = {
                    'stock_code': stock_code_full,
                    'strategy': STRATEGY_TO_RUN,
                    'signal_type': latest_signal,
                    'signal_strength': int(details.get('stage_passed', 1)),
                    'date': latest_date,
                    'scan_timestamp': current_timestamp,
                    'current_price': float(df['close'].iloc[-1]),
                    'signal_details': convert_numpy_types(details)
                }
                
                logger.info(f"å‘ç°ä¿¡å·: {stock_code_full} - {latest_signal} (é˜¶æ®µ: {details.get('stage_passed', 1)}/4)")
                return result
        
        return None
        
    except Exception as e:
        logger.error(f"å¤„ç†è‚¡ç¥¨ {stock_code_full} å¤±è´¥: {e}")
        return None


def convert_numpy_types(obj):
    """é€’å½’è½¬æ¢numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹"""
    if isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    elif isinstance(obj, np.bool_):
        return bool(obj)
    elif isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    else:
        return obj


def generate_summary_report(passed_stocks):
    """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
    if not passed_stocks:
        return {
            'scan_summary': {
                'total_signals': 0, 
                'strategy': STRATEGY_TO_RUN,
                'scan_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            },
            'stocks_found': []
        }
    
    # æŒ‰ä¿¡å·å¼ºåº¦åˆ†ç±»
    signal_stats = {}
    for stock in passed_stocks:
        signal_type = stock.get('signal_type', 'UNKNOWN')
        if signal_type not in signal_stats:
            signal_stats[signal_type] = 0
        signal_stats[signal_type] += 1
    
    summary = {
        'scan_summary': {
            'total_signals': len(passed_stocks),
            'scan_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'strategy': STRATEGY_TO_RUN,
            'strategy_version': 'optimized_v2.0',
            'signal_distribution': signal_stats,
            'config_used': abyss_strategy.config
        },
        'stocks_found': passed_stocks
    }
    
    # è½¬æ¢numpyç±»å‹
    summary = convert_numpy_types(summary)
    return summary


def main():
    """ä¸»å‡½æ•°"""
    start_time = datetime.now()
    logger.info(f"===== å¼€å§‹æ‰§è¡Œæ·±æ¸Šç­‘åº•ç­–ç•¥ç­›é€‰ =====")
    print(f"ğŸš€ å¼€å§‹æ‰§è¡Œæ·±æ¸Šç­‘åº•ç­–ç•¥ç­›é€‰")
    print(f"â° æ‰«ææ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“‹ ç­–ç•¥ç‰ˆæœ¬: {CONFIG.get('version', '2.0')} - {CONFIG.get('description', '')}")
    
    # æ”¶é›†æ‰€æœ‰è‚¡ç¥¨æ–‡ä»¶
    all_files = []
    for market in MARKETS:
        path = os.path.join(BASE_PATH, market, 'lday', '*.day')
        files = glob.glob(path)
        if not files:
            logger.warning(f"åœ¨è·¯å¾„ {path} æœªæ‰¾åˆ°ä»»ä½•æ–‡ä»¶")
            print(f"âš ï¸ è­¦å‘Š: åœ¨è·¯å¾„ {path} æœªæ‰¾åˆ°ä»»ä½•æ–‡ä»¶")
        all_files.extend([(f, market) for f in files])
    
    if not all_files:
        logger.error("æœªèƒ½åœ¨ä»»ä½•å¸‚åœºç›®å½•ä¸‹æ‰¾åˆ°æ—¥çº¿æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥BASE_PATHé…ç½®")
        print("âŒ é”™è¯¯: æœªèƒ½åœ¨ä»»ä½•å¸‚åœºç›®å½•ä¸‹æ‰¾åˆ°æ—¥çº¿æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥BASE_PATHé…ç½®")
        return

    print(f"ğŸ“Š å…±æ‰¾åˆ° {len(all_files)} ä¸ªæ—¥çº¿æ–‡ä»¶ï¼Œå¼€å§‹å¤šè¿›ç¨‹å¤„ç†...")
    logger.info(f"å¼€å§‹å¤„ç† {len(all_files)} ä¸ªè‚¡ç¥¨æ–‡ä»¶")
    
    # å¤šè¿›ç¨‹å¤„ç†
    try:
        max_workers = CONFIG.get('performance_tuning', {}).get('max_workers', 8)
        with Pool(processes=min(cpu_count(), max_workers)) as pool:
            results = pool.map(worker, all_files)
    except Exception as e:
        logger.error(f"å¤šè¿›ç¨‹å¤„ç†å¤±è´¥: {e}")
        print(f"âš ï¸ å¤šè¿›ç¨‹å¤„ç†å¤±è´¥ï¼Œé™çº§åˆ°å•è¿›ç¨‹: {e}")
        # é™çº§åˆ°å•è¿›ç¨‹å¤„ç†
        results = list(map(worker, all_files))
    
    # è¿‡æ»¤æœ‰æ•ˆç»“æœ
    passed_stocks = [r for r in results if r is not None]
    end_time = datetime.now()
    processing_time = (end_time - start_time).total_seconds()
    
    print(f"ğŸ“ˆ ç­›é€‰å®Œæˆï¼Œå‘ç°ä¿¡å·: {len(passed_stocks)} åªè‚¡ç¥¨")
    logger.info(f"ç­›é€‰å®Œæˆï¼Œå‘ç° {len(passed_stocks)} ä¸ªä¿¡å·")
    
    # æŒ‰ä¿¡å·ç±»å‹ç»Ÿè®¡
    if passed_stocks:
        signal_counts = {}
        for stock in passed_stocks:
            signal_type = stock.get('signal_type', 'UNKNOWN')
            signal_counts[signal_type] = signal_counts.get(signal_type, 0) + 1
        
        print(f"ğŸ“Š ä¿¡å·åˆ†å¸ƒ:")
        for signal_type, count in signal_counts.items():
            print(f"  {signal_type}: {count} åª")
    
    # ä¿å­˜ç»“æœ
    output_file = os.path.join(RESULT_DIR, f'abyss_signals_{DATE}.json')
    with open(output_file, 'w', encoding='utf-8') as f:
        # è½¬æ¢numpyç±»å‹åä¿å­˜
        json_safe_stocks = convert_numpy_types(passed_stocks)
        json.dump(json_safe_stocks, f, ensure_ascii=False, indent=2)
    
    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    summary_report = generate_summary_report(passed_stocks)
    summary_report['scan_summary']['processing_time'] = f"{processing_time:.2f} ç§’"
    summary_report['scan_summary']['files_processed'] = len(all_files)
    
    summary_file = os.path.join(RESULT_DIR, f'abyss_summary_{DATE}.json')
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary_report, f, ensure_ascii=False, indent=2)
    
    # ç”Ÿæˆå¯è¯»æ€§æŠ¥å‘Š
    text_report_file = os.path.join(RESULT_DIR, f'abyss_report_{DATE}.txt')
    with open(text_report_file, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("æ·±æ¸Šç­‘åº•ç­–ç•¥ç­›é€‰æŠ¥å‘Š\n")
        f.write("=" * 80 + "\n")
        f.write(f"æ‰«ææ—¶é—´: {summary_report['scan_summary']['scan_timestamp']}\n")
        f.write(f"ç­–ç•¥ç‰ˆæœ¬: {summary_report['scan_summary']['strategy_version']}\n")
        f.write(f"å¤„ç†æ–‡ä»¶æ•°: {summary_report['scan_summary']['files_processed']}\n")
        f.write(f"å¤„ç†è€—æ—¶: {summary_report['scan_summary']['processing_time']}\n")
        f.write(f"å‘ç°ä¿¡å·æ•°: {summary_report['scan_summary']['total_signals']}\n\n")
        
        if 'signal_distribution' in summary_report['scan_summary']:
            f.write("ä¿¡å·åˆ†å¸ƒ:\n")
            for signal_type, count in summary_report['scan_summary']['signal_distribution'].items():
                f.write(f"  {signal_type}: {count} åª\n")
            f.write("\n")
        
        if passed_stocks:
            f.write("å‘ç°ä¿¡å·çš„è‚¡ç¥¨è¯¦æƒ…:\n")
            f.write("-" * 80 + "\n")
            for i, stock in enumerate(passed_stocks, 1):
                f.write(f"\n{i:2d}. è‚¡ç¥¨ä»£ç : {stock['stock_code']}\n")
                f.write(f"    ä¿¡å·ç±»å‹: {stock['signal_type']}\n")
                f.write(f"    ä¿¡å·å¼ºåº¦: {stock['signal_strength']}/4 é˜¶æ®µ\n")
                f.write(f"    ä¿¡å·æ—¥æœŸ: {stock['date']}\n")
                f.write(f"    å½“å‰ä»·æ ¼: {stock['current_price']:.2f}\n")
                
                details = stock.get('signal_details', {})
                if 'deep_decline' in details:
                    deep_info = details['deep_decline']
                    f.write(f"    ä¸‹è·Œå¹…åº¦: {deep_info.get('drop_percent', 0):.2%}\n")
                    f.write(f"    ä»·æ ¼ä½ç½®: {deep_info.get('price_position', 0):.2%}\n")
                    
                    volume_analysis = deep_info.get('volume_analysis', {})
                    if volume_analysis:
                        f.write(f"    æˆäº¤é‡èç¼©: {volume_analysis.get('shrink_ratio', 0):.2f}\n")
                        f.write(f"    åœ°é‡æŒç»­: {volume_analysis.get('consistency_ratio', 0):.2%}\n")

    print(f"\nğŸ“Š ç­›é€‰å®Œæˆï¼")
    print(f"ğŸ¯ å‘ç°ä¿¡å·: {len(passed_stocks)} ä¸ª")
    print(f"â±ï¸ å¤„ç†è€—æ—¶: {processing_time:.2f} ç§’")
    print(f"ğŸ“„ ç»“æœå·²ä¿å­˜è‡³:")
    print(f"  - è¯¦ç»†ä¿¡å·: {output_file}")
    print(f"  - æ±‡æ€»æŠ¥å‘Š: {summary_file}")
    print(f"  - æ–‡æœ¬æŠ¥å‘Š: {text_report_file}")
    
    logger.info(f"===== ç­›é€‰å®Œæˆï¼å‘ç° {len(passed_stocks)} ä¸ªä¿¡å·ï¼Œæ€»è€—æ—¶: {processing_time:.2f} ç§’ =====")


if __name__ == '__main__':
    main()
"""
å¹¶è¡Œå‚æ•°ä¼˜åŒ–æ¨¡å— - å¤šåªè‚¡ç¥¨åŒæ—¶è¿›è¡Œå‚æ•°ä¼˜åŒ–
(ä¿®æ”¹ç‰ˆ: ä½¿ç”¨ ProcessPoolExecutor è§£å†³ GIL æ€§èƒ½é—®é¢˜)
"""

import os
import json
import time
import threading
from datetime import datetime
# å…³é”®æ”¹åŠ¨: å¼•å…¥ ProcessPoolExecutor
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
import multiprocessing
import itertools
import hashlib
import gc

# å…³é”®æ”¹åŠ¨: å°†å‚æ•°æµ‹è¯•é€»è¾‘å®šä¹‰ä¸ºé¡¶å±‚å‡½æ•°
# è¿™å¯¹äº ProcessPoolExecutor çš„æ­£å¸¸å·¥ä½œè‡³å…³é‡è¦ï¼Œå› ä¸ºå®ƒéœ€è¦èƒ½å¤Ÿ "pickle" (åºåˆ—åŒ–) è¿™ä¸ªå‡½æ•°
# ä»¥ä¾¿å‘é€åˆ°å­è¿›ç¨‹ä¸­æ‰§è¡Œã€‚
def _test_combination_worker(df, signals, combination):
    """
    åœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­è¿è¡Œçš„å·¥ä½œå‡½æ•°ã€‚
    æ³¨æ„: è¿™æ˜¯æ‚¨åŸå§‹çš„ _test_parameter_combination æ–¹æ³•çš„é€»è¾‘ã€‚
    """
    try:
        # åœ¨å­è¿›ç¨‹ä¸­é‡æ–°å¯¼å…¥å¿…è¦çš„æ¨¡å—
        from parametric_advisor import TradingParameters, ParametricTradingAdvisor

        test_params = TradingParameters()
        test_params.pre_entry_discount = combination[0]
        test_params.moderate_stop = combination[1]
        test_params.moderate_profit = combination[2]
        test_params.max_holding_days = combination[3]

        test_advisor = ParametricTradingAdvisor(test_params)
        result = test_advisor.backtest_parameters(df, signals, 'moderate')

        if 'error' not in result and result['total_trades'] >= 1:
            # ç»¼åˆè¯„åˆ†ï¼šèƒœç‡ * 0.6 + å¹³å‡æ”¶ç›Š * 0.4
            score = result['win_rate'] * 0.6 + max(0, result['avg_pnl']) * 0.4
            return (score, test_params, result)
        else:
            return (0, None, None)
    except Exception as e:
        # å‘ç”Ÿå¼‚å¸¸æ—¶è¿”å›ä¸€ä¸ªä¸€è‡´çš„ç»“æ„ï¼Œé¿å…ä¸»è¿›ç¨‹å‡ºé”™
        return (0, None, None)


class ParallelStockOptimizer:
    """å¹¶è¡Œè‚¡ç¥¨å‚æ•°ä¼˜åŒ–å™¨ - åŒæ—¶ä¼˜åŒ–å¤šåªè‚¡ç¥¨çš„å‚æ•°"""

    def __init__(self, max_workers=None, max_stocks_parallel=8, cache_dir="analysis_cache"):
        """
        åˆå§‹åŒ–å¹¶è¡Œè‚¡ç¥¨å‚æ•°ä¼˜åŒ–å™¨

        Args:
            max_workers: æ¯åªè‚¡ç¥¨çš„å‚æ•°ä¼˜åŒ–ä½¿ç”¨çš„æœ€å¤§è¿›ç¨‹æ•° (åŸä¸ºçº¿ç¨‹æ•°)
            max_stocks_parallel: åŒæ—¶å¤„ç†çš„æœ€å¤§è‚¡ç¥¨æ•°
            cache_dir: ç¼“å­˜ç›®å½•
        """
        if max_workers is None:
            cpu_count = multiprocessing.cpu_count()
            # æ¯åªè‚¡ç¥¨ä½¿ç”¨çš„è¿›ç¨‹æ•° = æ€»CPUæ ¸å¿ƒæ•° / å¹¶è¡Œè‚¡ç¥¨æ•°
            # ç¡®ä¿è‡³å°‘æœ‰1ä¸ªå·¥ä½œè¿›ç¨‹
            max_workers = max(1, cpu_count // max_stocks_parallel)

        self.max_workers = max_workers
        self.max_stocks_parallel = max_stocks_parallel
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)

        self.optimization_cache = {}
        self.cache_lock = threading.Lock()

        print(f"ğŸš€ å¹¶è¡Œè‚¡ç¥¨ä¼˜åŒ–å™¨åˆå§‹åŒ–: åŒæ—¶å¤„ç† {max_stocks_parallel} åªè‚¡ç¥¨, æ¯åªè‚¡ç¥¨ {max_workers} ä¸ªè¿›ç¨‹")

    def optimize_stocks_batch(self, stock_data_list):
        """
        æ‰¹é‡ä¼˜åŒ–å¤šåªè‚¡ç¥¨çš„å‚æ•°

        Args:
            stock_data_list: è‚¡ç¥¨æ•°æ®åˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å« stock_code, df, signals

        Returns:
            Dict[str, Any]: è‚¡ç¥¨ä»£ç åˆ°ä¼˜åŒ–ç»“æœçš„æ˜ å°„
        """
        start_time = time.time()
        results = {}
        total_stocks = len(stock_data_list)

        print(f"âš™ï¸ å¼€å§‹å¹¶è¡Œä¼˜åŒ– {total_stocks} åªè‚¡ç¥¨çš„å‚æ•°")

        # å¤–å±‚ä»ç„¶ä½¿ç”¨çº¿ç¨‹æ± ï¼Œå› ä¸ºæ¯ä¸ªä»»åŠ¡ (_optimize_single_stock) ä¸»è¦æ˜¯ç­‰å¾…
        # å…¶å†…éƒ¨çš„è¿›ç¨‹æ± å®Œæˆï¼Œè¿™æ˜¯ä¸€ç§ I/O-bound è¡Œä¸ºï¼Œé€‚åˆç”¨çº¿ç¨‹ã€‚
        with ThreadPoolExecutor(max_workers=self.max_stocks_parallel) as executor:
            future_to_stock = {}
            for stock_data in stock_data_list:
                stock_code = stock_data['stock_code']
                df = stock_data['df']
                signals = stock_data['signals']

                cached_result = self._get_cached_result(stock_code)
                if cached_result:
                    print(f"ğŸ“‚ {stock_code}: ä½¿ç”¨ç¼“å­˜çš„ä¼˜åŒ–å‚æ•°")
                    results[stock_code] = cached_result
                    continue

                future = executor.submit(self._optimize_single_stock, stock_code, df, signals)
                future_to_stock[future] = stock_code

            completed = 0
            # ä½¿ç”¨ len(future_to_stock) æ¥è®¡ç®—æ€»ä»»åŠ¡æ•°ï¼Œæ›´å‡†ç¡®
            total_tasks = len(future_to_stock)
            if total_tasks == 0:
                print("âœ… æ‰€æœ‰è‚¡ç¥¨å‡ä½¿ç”¨ç¼“å­˜ï¼Œæ— éœ€ä¼˜åŒ–ã€‚")
                return results

            for future in as_completed(future_to_stock):
                stock_code = future_to_stock[future]
                completed += 1

                try:
                    result = future.result()
                    results[stock_code] = result

                    progress = completed / total_tasks * 100
                    elapsed = time.time() - start_time
                    print(f"âœ… [{completed}/{total_tasks}] {stock_code}: å‚æ•°ä¼˜åŒ–å®Œæˆ "
                          f"(è¿›åº¦: {progress:.1f}%, è€—æ—¶: {elapsed:.1f}ç§’)")

                    self._cache_result(stock_code, result)

                except Exception as e:
                    print(f"âŒ [{completed}/{total_tasks}] {stock_code}: å‚æ•°ä¼˜åŒ–å¤±è´¥ - {e}")
                    results[stock_code] = {'error': f'ä¼˜åŒ–å¤±è´¥: {e}'}

        total_time = time.time() - start_time
        avg_time = total_time / total_stocks if total_stocks > 0 else 0
        print(f"âœ… å¹¶è¡Œå‚æ•°ä¼˜åŒ–å®Œæˆ! æ€»è€—æ—¶: {total_time:.2f}ç§’, å¹³å‡æ¯åªè‚¡ç¥¨: {avg_time:.2f}ç§’")

        gc.collect()

        return results

    def _optimize_single_stock(self, stock_code, df, signals):
        """ä¼˜åŒ–å•åªè‚¡ç¥¨çš„å‚æ•° (ä½¿ç”¨ ProcessPoolExecutor)"""
        try:
            print(f"ğŸ”§ {stock_code}: æ‰§è¡Œå‚æ•°ä¼˜åŒ–...")
            start_time = time.time()

            if signals is None or not signals.any():
                return {'error': 'æ— æœ‰æ•ˆä¿¡å·ï¼Œæ— æ³•ä¼˜åŒ–å‚æ•°'}

            signal_count = len(signals[signals != ''])
            if signal_count < 3:
                return {'error': f'ä¿¡å·æ•°é‡ä¸è¶³ï¼Œéœ€è¦è‡³å°‘3ä¸ªä¿¡å·ï¼Œå½“å‰: {signal_count}'}

            param_ranges = {
                'pre_entry_discount': [0.02, 0.03, 0.05],
                'moderate_stop': [0.03, 0.05, 0.08],
                'moderate_profit': [0.10, 0.15, 0.20],
                'max_holding_days': [20, 30]
            }

            combinations = list(itertools.product(*param_ranges.values()))
            total_combinations = len(combinations)

            print(f"âš™ï¸ {stock_code}: æµ‹è¯• {total_combinations} ç§å‚æ•°ç»„åˆ (è¿›ç¨‹æ•°: {self.max_workers})")

            best_params = None
            best_score = -1
            best_result = None

            # å…³é”®æ”¹åŠ¨: ä½¿ç”¨ ProcessPoolExecutor è¿›è¡Œ CPU å¯†é›†å‹ä»»åŠ¡
            with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
                future_to_combination = {
                    executor.submit(_test_combination_worker, df, signals, combo): combo
                    for combo in combinations
                }

                for future in as_completed(future_to_combination):
                    try:
                        score, params, result = future.result()
                        if score > best_score:
                            best_score = score
                            best_params = params
                            best_result = result
                    except Exception:
                        continue

            total_time = time.time() - start_time

            optimization_result = {
                'best_parameters': best_params.__dict__ if best_params else None,
                'best_score': best_score,
                'best_result': best_result,
                'optimization_target': 'composite_score',
                'combinations_tested': total_combinations,
                'optimization_time': total_time
            }

            self._save_optimization_result(stock_code, optimization_result)

            return optimization_result

        except Exception as e:
            return {'error': f'å‚æ•°ä¼˜åŒ–å¤±è´¥: {e}'}

    # _test_parameter_combination æ–¹æ³•å·²è¢«ç§»é™¤ï¼Œå¹¶ç”±é¡¶å±‚å‡½æ•° _test_combination_worker æ›¿ä»£

    def _get_cached_result(self, stock_code):
        """è·å–ç¼“å­˜çš„ä¼˜åŒ–ç»“æœ"""
        with self.cache_lock:
            if stock_code in self.optimization_cache:
                return self.optimization_cache[stock_code]

        file_path = f"{self.cache_dir}/optimized_parameters_{stock_code}.json"
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                with self.cache_lock:
                    self.optimization_cache[stock_code] = data
                return data
            except:
                pass

        return None

    def _cache_result(self, stock_code, result):
        """ç¼“å­˜ä¼˜åŒ–ç»“æœ"""
        with self.cache_lock:
            self.optimization_cache[stock_code] = result

    def _save_optimization_result(self, stock_code, result):
        """ä¿å­˜ä¼˜åŒ–ç»“æœåˆ°æ–‡ä»¶"""
        try:
            file_path = f"{self.cache_dir}/optimized_parameters_{stock_code}.json"

            save_data = {
                'stock_code': stock_code,
                'optimization_date': datetime.now().isoformat(),
                'best_parameters': result['best_parameters'],
                'best_score': result['best_score'],
                'optimization_target': result['optimization_target']
            }

            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(save_data, f, ensure_ascii=False, indent=2)

        except Exception as e:
            print(f"âŒ ä¿å­˜ä¼˜åŒ–ç»“æœå¤±è´¥: {e}")


def optimize_stocks_parallel(stock_data_list, max_stocks_parallel=8):
    """
    å¹¶è¡Œä¼˜åŒ–å¤šåªè‚¡ç¥¨çš„å‚æ•°ï¼ˆä¾¿æ·å‡½æ•°ï¼‰

    Args:
        stock_data_list: è‚¡ç¥¨æ•°æ®åˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å« stock_code, df, signals
        max_stocks_parallel: åŒæ—¶å¤„ç†çš„æœ€å¤§è‚¡ç¥¨æ•°

    Returns:
        Dict[str, Any]: è‚¡ç¥¨ä»£ç åˆ°ä¼˜åŒ–ç»“æœçš„æ˜ å°„
    """
    optimizer = ParallelStockOptimizer(max_stocks_parallel=max_stocks_parallel)
    return optimizer.optimize_stocks_batch(stock_data_list)

# å…³é”®æ”¹åŠ¨: æ·»åŠ  `if __name__ == '__main__':` ä¿æŠ¤
# è¿™æ˜¯ä½¿ç”¨ `multiprocessing` (åŒ…æ‹¬ ProcessPoolExecutor) æ—¶çš„æœ€ä½³å®è·µï¼Œå°¤å…¶æ˜¯åœ¨ Windows å’Œ macOS ä¸Šã€‚
# å®ƒå¯ä»¥é˜²æ­¢å­è¿›ç¨‹æ— é™é€’å½’åœ°é‡æ–°æ‰§è¡Œä¸»ç¨‹åºä»£ç ã€‚
if __name__ == '__main__':
    print("å¹¶è¡Œä¼˜åŒ–å™¨æ¨¡å—å·²åŠ è½½ã€‚")
    print("è¦è¿è¡Œä¼˜åŒ–ï¼Œè¯·åœ¨æ‚¨çš„ä¸»è„šæœ¬ä¸­å¯¼å…¥å¹¶è°ƒç”¨ optimize_stocks_parallel å‡½æ•°ã€‚")

    # è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼Œå±•ç¤ºå¦‚ä½•åœ¨æ‚¨çš„ä¸»è„šæœ¬ä¸­ä½¿ç”¨è¿™ä¸ªæ¨¡å—ï¼š
    #
    # from parallel_optimizer import optimize_stocks_parallel
    # import pandas as pd
    #
    # # 1. å‡†å¤‡æ‚¨çš„æ•°æ®
    # # è¿™æ˜¯ä¸€ä¸ªä¼ªé€ çš„æ•°æ®åˆ—è¡¨ï¼Œæ‚¨éœ€è¦ç”¨çœŸå®æ•°æ®æ›¿æ¢
    # fake_stock_data = [
    #     {
    #         "stock_code": "STOCK_A",
    #         "df": pd.DataFrame({'close': range(100)}), # ä½¿ç”¨æ‚¨çš„çœŸå®è¡Œæƒ… DataFrame
    #         "signals": pd.Series(['buy', '', 'buy', ''] * 25) # ä½¿ç”¨æ‚¨çš„çœŸå®ä¿¡å· Series
    #     },
    #     {
    #         "stock_code": "STOCK_B",
    #         "df": pd.DataFrame({'close': range(100, 200)}),
    #         "signals": pd.Series(['', 'buy', '', 'buy'] * 25)
    #     }
    # ]
    #
    # # 2. è¿è¡Œå¹¶è¡Œä¼˜åŒ–
    # # æ³¨æ„: æ‚¨éœ€è¦æœ‰ä¸€ä¸ªåä¸º `parametric_advisor.py` çš„æ–‡ä»¶ï¼Œå…¶ä¸­åŒ…å«
    # # `TradingParameters` å’Œ `ParametricTradingAdvisor` ç±»ï¼Œå¦åˆ™ä¼šå¼•å‘ ImportErrorã€‚
    # #
    # # try:
    # #     optimization_results = optimize_stocks_parallel(
    # #         stock_data_list=fake_stock_data,
    # #         max_stocks_parallel=4 # åŒæ—¶ä¼˜åŒ–4åªè‚¡ç¥¨
    # #     )
    # #     print("\n--- ä¼˜åŒ–ç»“æœ ---")
    # #     print(json.dumps(optimization_results, indent=2))
    # # except ImportError:
    # #     print("\né”™è¯¯: æ— æ³•å¯¼å…¥ 'parametric_advisor'ã€‚è¯·ç¡®ä¿è¯¥æ–‡ä»¶å­˜åœ¨ä¸”å¯è®¿é—®ã€‚")
    # # except Exception as e:
    # #     print(f"\nè¿è¡Œæ—¶å‘ç”Ÿé”™è¯¯: {e}")
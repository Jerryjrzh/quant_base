import os
import glob
import json
import pandas as pd
from multiprocessing import Pool, cpu_count
from datetime import datetime
import logging
import data_loader
import strategies
import backtester
import indicators
from win_rate_filter import WinRateFilter, AdvancedTripleCrossFilter
import talib

# === ä¼˜åŒ–åçš„æ–°ç­–ç•¥é€»è¾‘ START ===
# æˆ‘é‡å†™äº†ç­–ç•¥é€»è¾‘ï¼Œä½¿å…¶æ›´ç§‘å­¦ä¸”èƒ½ç­›é€‰å‡ºç»“æœ
def apply_reversed_short_optimized(df):
    """
    ä¼˜åŒ–åçš„åè½¬åšç©ºç­–ç•¥ï¼ˆç”¨äºåšå¤šé€‰è‚¡ï¼‰
    æ ¸å¿ƒé€»è¾‘ï¼šå¯»æ‰¾æ»¡è¶³ä»¥ä¸‹æ¡ä»¶ä¸­è‡³å°‘ä¸¤ä¸ªçš„è‚¡ç¥¨ï¼Œè¡¨æ˜ä¸‹è·ŒåŠ¨èƒ½è¡°ç«­ï¼Œå¯èƒ½åè½¬ã€‚

    1. ä¿®æ­£çš„MACDåº•èƒŒç¦»ï¼šä»·æ ¼åœ¨è¿‘æœŸä½ä½ï¼Œä½†MACDæŒ‡æ ‡å·²æ˜æ˜¾å›å‡ã€‚
    2. å¯é çš„æ”¾é‡çªç ´ï¼šä»·æ ¼ä¸Šç©¿MA20ï¼Œä¸”æˆäº¤é‡æ˜¾è‘—å¤§äº20æ—¥å‡é‡ã€‚
    3. æ”¾å®½çš„RSIè¶…å–å¯åŠ¨ï¼šRSIä»35ä»¥ä¸‹çš„è¶…å–/ä½ä½åŒºé‡‘å‰å›å‡ã€‚
    """
    if len(df) < 60:  # éœ€è¦è¶³å¤Ÿæ•°æ®æ¥è®¡ç®—æŒ‡æ ‡å’Œåˆ¤æ–­èƒŒç¦»
        return None

    try:
        # ç»Ÿä¸€è®¡ç®—æ‰€éœ€æŒ‡æ ‡
        df['ma20'] = talib.MA(df['close'], timeperiod=20)
        df['volume_ma20'] = df['volume'].rolling(window=20).mean()
        macd, signal, _ = talib.MACD(df['close'], fastperiod=12, slowperiod=26, signalperiod=9)
        df['macd'] = macd
        df['rsi'] = talib.RSI(df['close'], timeperiod=14)

        signal_series = pd.Series(False, index=df.index)
        
        # åªæ£€æŸ¥æœ€åä¸€ä¸ªäº¤æ˜“æ—¥
        current_idx = -1
        current_data = df.iloc[current_idx]
        prev_data = df.iloc[current_idx - 1]

        conditions_met = 0
        
        # --- æ¡ä»¶1ï¼šä¼˜åŒ–çš„MACDåº•èƒŒç¦»æ£€æŸ¥ ---
        lookback_period = 60
        recent_data = df.iloc[-lookback_period:]
        price_trough_date = recent_data['close'].idxmin()
        macd_at_trough = df.loc[price_trough_date]['macd']
        
        # å¦‚æœæœ€ä½ç‚¹å‘ç”Ÿåœ¨3å¤©å‰æˆ–æ›´æ—©ï¼Œä¸”å½“å‰MACDé«˜äºæœ€ä½ç‚¹æ—¶çš„MACD 30%ä»¥ä¸Šï¼Œè§†ä¸ºèƒŒç¦»
        if (df.index[current_idx] - price_trough_date).days > 3:
            if current_data['macd'] > macd_at_trough * 1.3 and current_data['close'] < df.loc[price_trough_date]['close'] * 1.15:
                conditions_met += 1

        # --- æ¡ä»¶2ï¼šRSIè¶…å–åŒºå¯åŠ¨ ---
        if prev_data['rsi'] < 35 and current_data['rsi'] > prev_data['rsi']:
            conditions_met += 1
            
        # --- æ¡ä»¶3ï¼šå¯é çš„æ”¾é‡çªç ´MA20 ---
        if (prev_data['close'] < prev_data['ma20'] and 
            current_data['close'] > current_data['ma20'] and 
            current_data['volume'] > current_data['volume_ma20'] * 1.5):
            conditions_met += 1

        # å¦‚æœæ»¡è¶³è‡³å°‘2ä¸ªæ¡ä»¶ï¼Œåˆ™äº§ç”Ÿä¿¡å·
        if conditions_met >= 2:
            signal_series.iloc[current_idx] = True
            
        return signal_series

    except Exception as e:
        # å…è®¸åœ¨æ—¥å¿—ä¸­çœ‹åˆ°é”™è¯¯ï¼Œä½†ç¨‹åºä¸ä¸­æ–­
        # logger.warning(f"ç­–ç•¥ 'REVERSED_SHORT_OPTIMIZED' è®¡ç®—å¤±è´¥: {e}")
        return None
# === ä¼˜åŒ–åçš„æ–°ç­–ç•¥é€»è¾‘ END ===


# --- é…ç½® ---
BASE_PATH = os.path.expanduser("~/.local/share/tdxcfv/drive_c/tc/vipdoc")
MARKETS = ['sh', 'sz', 'bj']
# --- ä¸»è¦ä¿®æ”¹ç‚¹ï¼šç¡®ä¿æ‚¨æ­£åœ¨è¿è¡Œæ–°ç­–ç•¥ ---
STRATEGY_TO_RUN = 'REVERSED_SHORT'  # ä¿æŒè¿™ä¸ªè®¾ç½®æ¥è¿è¡Œä¼˜åŒ–åçš„ç­–ç•¥

# --- è·¯å¾„å®šä¹‰ ---
backend_dir = os.path.dirname(os.path.abspath(__file__))
OUTPUT_PATH = os.path.abspath(os.path.join(backend_dir, '..', 'data', 'result'))

# --- åˆå§‹åŒ–æ—¥å¿— ---
DATE = datetime.now().strftime("%Y%m%d_%H%M")
RESULT_DIR = os.path.join(OUTPUT_PATH, STRATEGY_TO_RUN)
os.makedirs(RESULT_DIR, exist_ok=True)
LOG_FILE = os.path.join(RESULT_DIR, f'log_screener_{DATE}.txt')

file_handler = logging.FileHandler(LOG_FILE, 'a', 'utf-8')
file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
logger = logging.getLogger('screener_logger')
logger.setLevel(logging.INFO)
if logger.hasHandlers():
    logger.handlers.clear()
logger.addHandler(file_handler)

def calculate_backtest_stats(df, signal_series):
    """è®¡ç®—ç»†åŒ–çš„å›æµ‹ç»Ÿè®¡ä¿¡æ¯"""
    try:
        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ˆå›æµ‹éœ€è¦ï¼‰
        macd_values = indicators.calculate_macd(df)
        df['dif'], df['dea'] = macd_values[0], macd_values[1]
        kdj_values = indicators.calculate_kdj(df)
        df['k'], df['d'], df['j'] = kdj_values[0], kdj_values[1], kdj_values[2]
        
        # æ‰§è¡Œç»†åŒ–å›æµ‹
        backtest_results = backtester.run_backtest(df, signal_series)
        
        if isinstance(backtest_results, dict) and backtest_results.get('total_signals', 0) > 0:
            stats = {
                'total_signals': backtest_results.get('total_signals', 0),
                'win_rate': backtest_results.get('win_rate', '0.0%'),
                'avg_max_profit': backtest_results.get('avg_max_profit', '0.0%'),
                'avg_max_drawdown': backtest_results.get('avg_max_drawdown', '0.0%'),
                'avg_days_to_peak': backtest_results.get('avg_days_to_peak', '0.0 å¤©')
            }
            
            # æ·»åŠ å„çŠ¶æ€ç»Ÿè®¡ä¿¡æ¯
            if 'state_statistics' in backtest_results:
                stats['state_statistics'] = backtest_results['state_statistics']
            
            # æ·»åŠ è¯¦ç»†äº¤æ˜“ä¿¡æ¯ï¼ˆç”¨äºè¿›ä¸€æ­¥åˆ†æï¼‰
            if 'trades' in backtest_results:
                # è®¡ç®—ä¸€äº›é¢å¤–çš„ç»Ÿè®¡æŒ‡æ ‡
                trades = backtest_results['trades']
                if trades:
                    # æœ€ä½³è¡¨ç°äº¤æ˜“
                    best_trade = max(trades, key=lambda x: x['actual_max_pnl'])
                    worst_trade = min(trades, key=lambda x: x['actual_max_pnl'])
                    
                    stats.update({
                        'best_trade_profit': f"{best_trade['actual_max_pnl']:.1%}",
                        'worst_trade_profit': f"{worst_trade['actual_max_pnl']:.1%}",
                        'avg_entry_strategy': get_most_common_entry_strategy(trades)
                    })
            
            return stats
        else:
            return {
                'total_signals': 0,
                'win_rate': '0.0%',
                'avg_max_profit': '0.0%',
                'avg_max_drawdown': '0.0%',
                'avg_days_to_peak': '0.0 å¤©'
            }
    except Exception as e:
        logger.error(f"å›æµ‹è®¡ç®—å¤±è´¥: {e}")
        return {
            'total_signals': 0,
            'win_rate': '0.0%',
            'avg_max_profit': '0.0%',
            'avg_max_drawdown': '0.0%',
            'avg_days_to_peak': '0.0 å¤©'
        }

def get_most_common_entry_strategy(trades):
    """è·å–æœ€å¸¸ç”¨çš„å…¥åœºç­–ç•¥"""
    try:
        from collections import Counter
        strategies = [trade.get('entry_strategy', 'æœªçŸ¥') for trade in trades]
        most_common = Counter(strategies).most_common(1)
        return most_common[0][0] if most_common else 'æœªçŸ¥'
    except:
        return 'æœªçŸ¥'

def check_macd_zero_axis_pre_filter(df, signal_idx, signal_state, lookback_days=5):
    """
    MACDé›¶è½´å¯åŠ¨ç­–ç•¥çš„é¢„ç­›é€‰è¿‡æ»¤å™¨ï¼šæ’é™¤äº”æ—¥å†…ä»·æ ¼ä¸Šæ¶¨è¶…è¿‡5%çš„æƒ…å†µ
    """
    try:
        if signal_state not in ['PRE', 'MID', 'POST']:
            return False, ""
        
        start_idx = max(0, signal_idx - lookback_days)
        end_idx = signal_idx
        
        if start_idx >= end_idx:
            return False, ""
        
        lookback_data = df.iloc[start_idx:end_idx + 1]
        if len(lookback_data) < 2:
            return False, ""
        
        base_price = lookback_data.iloc[0]['close']
        current_high = df.iloc[signal_idx]['high']
        price_increase = (current_high - base_price) / base_price
        
        if price_increase > 0.25 or price_increase < 0.05:
            return True, f"äº”æ—¥å†…æ¶¨å¹…{price_increase:.1%}è¶…è¿‡25%æˆ–è€…ä½äº5%ï¼Œæ’é™¤ä¸æ´»è·ƒé£é™©"
        
        return False, ""
        
    except Exception as e:
        print(f"MACDé›¶è½´é¢„ç­›é€‰è¿‡æ»¤å™¨æ£€æŸ¥å¤±è´¥: {e}")
        return False, ""

def check_weekly_golden_cross_ma_filter(df, signal_idx, signal_state, stock_code):
    """
    å‘¨çº¿é‡‘å‰+æ—¥çº¿MAç­–ç•¥çš„è¿‡æ»¤å™¨
    """
    try:
        if signal_state != 'BUY':
            return False, ""
        
        if len(df) < 240:
            return True, "æ•°æ®é•¿åº¦ä¸è¶³ï¼Œæ— æ³•è®¡ç®—é•¿æœŸMA"
        
        current_price = df.iloc[signal_idx]['close']
        ma13 = df['close'].rolling(window=13).mean().iloc[signal_idx]
        
        if pd.isna(ma13):
            return True, "MA13è®¡ç®—å¤±è´¥"
        
        price_distance = (current_price - ma13) / ma13
        if price_distance > 0.05:
            return True, f"ä»·æ ¼è·ç¦»MA13è¿‡è¿œ({price_distance:.1%})ï¼Œæ’é™¤è¿½é«˜é£é™©"
        
        if 'volume' in df.columns:
            current_volume = df.iloc[signal_idx]['volume']
            avg_volume = df['volume'].rolling(window=20).mean().iloc[signal_idx]
            
            if not pd.isna(avg_volume) and avg_volume > 0:
                volume_ratio = current_volume / avg_volume
                if volume_ratio > 5.0:
                    return True, f"æˆäº¤é‡å¼‚å¸¸æ”¾å¤§({volume_ratio:.1f}å€)ï¼Œå¯èƒ½å­˜åœ¨é£é™©"
        
        if signal_idx >= 5:
            price_5_days_ago = df.iloc[signal_idx - 5]['close']
            short_term_gain = (current_price - price_5_days_ago) / price_5_days_ago
            if short_term_gain > 0.15:
                return True, f"çŸ­æœŸæ¶¨å¹…è¿‡å¤§({short_term_gain:.1%})ï¼Œæ’é™¤è¿½é«˜é£é™©"
        
        return False, ""
        
    except Exception as e:
        logger.error(f"å‘¨çº¿é‡‘å‰+æ—¥çº¿MAè¿‡æ»¤å™¨æ£€æŸ¥å¤±è´¥ {stock_code}: {e}")
        return True, f"è¿‡æ»¤å™¨æ‰§è¡Œå¤±è´¥: {e}"

def analyze_ma_trend(df):
    """
    åˆ†æMAè¶‹åŠ¿å¼ºåº¦å’Œç›¸å…³æŒ‡æ ‡
    """
    try:
        ma_periods = [7, 13, 30, 45]
        mas = {}
        for period in ma_periods:
            mas[f'ma_{period}'] = df['close'].rolling(window=period).mean()
        
        current_price = df['close'].iloc[-1]
        ma13_current = mas['ma_13'].iloc[-1]
        
        trend_strength = 0
        if not pd.isna(ma13_current):
            if (mas['ma_7'].iloc[-1] > mas['ma_13'].iloc[-1] and
                mas['ma_13'].iloc[-1] > mas['ma_30'].iloc[-1] and
                mas['ma_30'].iloc[-1] > mas['ma_45'].iloc[-1]):
                trend_strength = 1.0
            elif (mas['ma_7'].iloc[-1] > mas['ma_13'].iloc[-1] and
                  mas['ma_13'].iloc[-1] > mas['ma_30'].iloc[-1]):
                trend_strength = 0.7
            elif mas['ma_7'].iloc[-1] > mas['ma_13'].iloc[-1]:
                trend_strength = 0.4
            else:
                trend_strength = 0.0
        
        ma13_distance = 0
        if not pd.isna(ma13_current) and ma13_current > 0:
            ma13_distance = (current_price - ma13_current) / ma13_current
        
        volume_surge_ratio = 1.0
        if 'volume' in df.columns and len(df) >= 20:
            current_volume = df['volume'].iloc[-1]
            avg_volume = df['volume'].rolling(window=20).mean().iloc[-1]
            if not pd.isna(avg_volume) and avg_volume > 0:
                volume_surge_ratio = current_volume / avg_volume
        
        return {
            'trend_strength': trend_strength,
            'ma13_distance': ma13_distance,
            'volume_surge_ratio': volume_surge_ratio
        }
        
    except Exception as e:
        logger.error(f"MAè¶‹åŠ¿åˆ†æå¤±è´¥: {e}")
        return {
            'trend_strength': 0,
            'ma13_distance': 0,
            'volume_surge_ratio': 1.0
        }

def check_triple_cross_enhanced_filter(df, signal_idx, stock_code):
    """
    TRIPLE_CROSSç­–ç•¥çš„å¢å¼ºè¿‡æ»¤å™¨ã€‚
    æ³¨ï¼šgrok4çš„ä¿®æ”¹æ˜¯åˆç†çš„ï¼Œåªæ’é™¤äº†çŸ­æœŸæš´æ¶¨è‚¡ï¼Œæ­¤å¤„ä¿ç•™ã€‚
    """
    try:
        advanced_filter = AdvancedTripleCrossFilter()
        should_exclude, exclude_reason, quality_score, cross_stage = advanced_filter.enhanced_triple_cross_filter(df, signal_idx)
        
        if should_exclude:
            return True, exclude_reason, {}
        
        current_price = df.iloc[signal_idx]['close']
        if signal_idx >= 5:
            price_5_days_ago = df.iloc[signal_idx - 5]['close']
            short_term_gain = (current_price - price_5_days_ago) / price_5_days_ago
            if short_term_gain > 0.30:
                return True, f"äº”æ—¥å†…æ¶¨å¹…{short_term_gain:.1%}è¶…è¿‡30%ï¼Œæ’é™¤è¿½é«˜é£é™©", {}
        
        signal_series = strategies.apply_triple_cross(df)
        if signal_series is not None:
            win_rate_filter = WinRateFilter(min_win_rate=0.4, min_signals=3, min_avg_profit=0.08)
            should_exclude_wr, exclude_reason_wr, backtest_stats = win_rate_filter.should_exclude_stock(df, signal_series, stock_code)
            
            if should_exclude_wr:
                return True, f"èƒœç‡ç­›é€‰: {exclude_reason_wr}", {'backtest_stats': backtest_stats}
        
        return False, "é€šè¿‡å¢å¼ºç­›é€‰", {'backtest_stats': backtest_stats if 'backtest_stats' in locals() else {}}
        
    except Exception as e:
        return True, f"å¢å¼ºè¿‡æ»¤å™¨æ‰§è¡Œå¤±è´¥: {e}", {}

def worker(args):
    """å¤šè¿›ç¨‹å·¥ä½œå‡½æ•°"""
    file_path, market = args
    stock_code_full = os.path.basename(file_path).split('.')[0]
    stock_code_no_prefix = stock_code_full.replace(market, '')

    valid_prefixes = ('600', '601', '603', '000', '001', '002', '003', '300', '688')
    if not stock_code_no_prefix.startswith(valid_prefixes):
        return None

    try:
        df = data_loader.get_daily_data(file_path)
        if df is None or len(df) < 150:
            return None

        current_timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        latest_date = df.index[-1].strftime('%Y-%m-%d')
        
        result_base = {
            'stock_code': stock_code_full,
            'strategy': STRATEGY_TO_RUN,
            'date': latest_date,
            'scan_timestamp': current_timestamp
        }
        
        if STRATEGY_TO_RUN == 'PRE_CROSS':
            return _process_pre_cross_strategy(df, result_base)
        elif STRATEGY_TO_RUN == 'TRIPLE_CROSS':
            return _process_triple_cross_strategy(df, result_base, stock_code_full)
        elif STRATEGY_TO_RUN == 'MACD_ZERO_AXIS':
            return _process_macd_zero_axis_strategy(df, result_base, stock_code_full)
        elif STRATEGY_TO_RUN == 'WEEKLY_GOLDEN_CROSS_MA':
            return _process_weekly_golden_cross_ma_strategy(df, result_base, stock_code_full)
        # --- ä¸»è¦ä¿®æ”¹ç‚¹ï¼šè°ƒç”¨ä¼˜åŒ–åçš„æ–°ç­–ç•¥å¤„ç†å‡½æ•° ---
        elif STRATEGY_TO_RUN == 'REVERSED_SHORT':
            return _process_reversed_short_strategy_optimized(df, result_base, stock_code_full)
        
        return None
        
    except Exception as e:
        logger.error(f"å¤„ç† {stock_code_full} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return None

def _process_pre_cross_strategy(df, result_base):
    """å¤„ç†PRE_CROSSç­–ç•¥"""
    try:
        signal_series = strategies.apply_pre_cross(df)
        if signal_series is not None and signal_series.iloc[-1]:
            backtest_stats = calculate_backtest_stats_fast(df, signal_series)
            result_base.update(backtest_stats)
            return result_base
        return None
    except Exception:
        return None

def _process_triple_cross_strategy(df, result_base, stock_code_full):
    """å¤„ç†TRIPLE_CROSSç­–ç•¥"""
    try:
        signal_series = strategies.apply_triple_cross(df)
        if signal_series is not None and signal_series.iloc[-1]:
            should_exclude, exclude_reason, filter_details = check_triple_cross_enhanced_filter(df, len(df) - 1, stock_code_full)
            
            if should_exclude:
                logger.info(f"{stock_code_full} è¢«è¿‡æ»¤: {exclude_reason}")
                return None
            
            backtest_stats = calculate_backtest_stats_fast(df, signal_series)
            result_base.update({
                'filter_status': 'passed',
                **backtest_stats
            })
            return result_base
        return None
    except Exception:
        return None

def _process_macd_zero_axis_strategy(df, result_base, stock_code_full):
    """å¤„ç†MACD_ZERO_AXISç­–ç•¥"""
    try:
        signal_series = strategies.apply_macd_zero_axis_strategy(df)
        signal_state = signal_series.iloc[-1]
        if signal_state in ['PRE', 'MID', 'POST']:
            should_exclude, exclude_reason = check_macd_zero_axis_pre_filter(df, len(df) - 1, signal_state)
            
            if should_exclude:
                logger.info(f"{stock_code_full} è¢«è¿‡æ»¤: {exclude_reason}")
                return None
            
            backtest_stats = calculate_backtest_stats_fast(df, signal_series)
            result_base.update({
                'signal_state': signal_state,
                'filter_status': 'passed',
                **backtest_stats
            })
            return result_base
        return None
    except Exception:
        return None

def _process_weekly_golden_cross_ma_strategy(df, result_base, stock_code_full):
    """å¤„ç†WEEKLY_GOLDEN_CROSS_MAç­–ç•¥"""
    try:
        signal_series = strategies.apply_weekly_golden_cross_ma_strategy(df)
        signal_state = signal_series.iloc[-1]
        
        if signal_state in ['BUY', 'HOLD', 'SELL']:
            should_exclude, exclude_reason = check_weekly_golden_cross_ma_filter(df, len(df) - 1, signal_state, stock_code_full)
            
            if should_exclude:
                logger.info(f"{stock_code_full} è¢«è¿‡æ»¤: {exclude_reason}")
                return None
            
            backtest_stats = calculate_backtest_stats_fast(df, signal_series)
            ma_analysis = analyze_ma_trend(df)
            
            result_base.update({
                'signal_state': signal_state,
                'filter_status': 'passed',
                'ma_trend_strength': ma_analysis.get('trend_strength', 0),
                'ma13_distance': ma_analysis.get('ma13_distance', 0),
                'volume_surge_ratio': ma_analysis.get('volume_surge_ratio', 1.0),
                **backtest_stats
            })
            return result_base
        return None
    except Exception as e:
        logger.error(f"å¤„ç†å‘¨çº¿é‡‘å‰+æ—¥çº¿MAç­–ç•¥å¤±è´¥ {stock_code_full}: {e}")
        return None

# --- ä¸»è¦ä¿®æ”¹ç‚¹ï¼šæ–°çš„ç­–ç•¥å¤„ç†å‡½æ•° ---
def _process_reversed_short_strategy_optimized(df, result_base, stock_code_full):
    """å¤„ç†ä¼˜åŒ–åçš„REVERSED_SHORTç­–ç•¥"""
    try:
        # è°ƒç”¨æˆ‘ä»¬æ–°ç¼–å†™çš„ã€ä¼˜åŒ–åçš„ç­–ç•¥å‡½æ•°
        signal_series = apply_reversed_short_optimized(df)
        
        if signal_series is not None and signal_series.iloc[-1]:
            # æ­¤ç­–ç•¥æš‚æ—¶ä¸åŠ é¢å¤–è¿‡æ»¤å™¨ï¼Œä»¥ä¿è¯èƒ½é€‰å‡ºå€™é€‰è‚¡
            backtest_stats = calculate_backtest_stats_fast(df, signal_series)
            result_base.update({
                'signal_state': 'BUY_CANDIDATE',
                'filter_status': 'passed_optimized',
                **backtest_stats
            })
            return result_base
        return None
    except Exception as e:
        logger.error(f"å¤„ç†REVERSED_SHORT_OPTIMIZEDç­–ç•¥å¤±è´¥ {stock_code_full}: {e}")
        return None

def calculate_backtest_stats_fast(df, signal_series):
    """å¿«é€Ÿè®¡ç®—å›æµ‹ç»Ÿè®¡ä¿¡æ¯ - ä¼˜åŒ–ç‰ˆæœ¬"""
    try:
        if 'dif' not in df.columns or 'dea' not in df.columns:
            macd_values = indicators.calculate_macd(df)
            df['dif'], df['dea'] = macd_values[0], macd_values[1]
        
        if 'k' not in df.columns or 'd' not in df.columns:
            kdj_values = indicators.calculate_kdj(df)
            df['k'], df['d'], df['j'] = kdj_values[0], kdj_values[1], kdj_values[2]
        
        backtest_results = backtester.run_backtest(df, signal_series)
        
        if isinstance(backtest_results, dict) and backtest_results.get('total_signals', 0) > 0:
            return {
                'total_signals': backtest_results.get('total_signals', 0),
                'win_rate': backtest_results.get('win_rate', '0.0%'),
                'avg_max_profit': backtest_results.get('avg_max_profit', '0.0%'),
                'avg_max_drawdown': backtest_results.get('avg_max_drawdown', '0.0%'),
                'avg_days_to_peak': backtest_results.get('avg_days_to_peak', '0.0 å¤©')
            }
        else:
            return {'total_signals': 0, 'win_rate': '0.0%', 'avg_max_profit': '0.0%', 'avg_max_drawdown': '0.0%', 'avg_days_to_peak': '0.0 å¤©'}
    except Exception as e:
        logger.error(f"å¿«é€Ÿå›æµ‹è®¡ç®—å¤±è´¥: {e}")
        return {'total_signals': 0, 'win_rate': '0.0%', 'avg_max_profit': '0.0%', 'avg_max_drawdown': '0.0%', 'avg_days_to_peak': '0.0 å¤©'}

def generate_summary_report(passed_stocks):
    """ç”Ÿæˆè¯¦ç»†çš„æ±‡æ€»æŠ¥å‘Š"""
    if not passed_stocks:
        return {
            'scan_summary': {'total_signals': 0, 'scan_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'strategy': STRATEGY_TO_RUN, 'total_historical_signals': 0, 'avg_win_rate': '0.0%', 'avg_profit_rate': '0.0%', 'avg_days_to_peak': '0.0 å¤©'},
            'signal_breakdown': {},
            'top_performers': []
        }
    
    total_signals = len(passed_stocks)
    
    signal_states = {}
    if STRATEGY_TO_RUN == 'MACD_ZERO_AXIS':
        for stock in passed_stocks:
            state = stock.get('signal_state', 'UNKNOWN')
            if state not in signal_states:
                signal_states[state] = []
            signal_states[state].append(stock)
    
    total_historical_signals = sum(stock.get('total_signals', 0) for stock in passed_stocks if stock.get('total_signals', 0) > 0)
    
    win_rates = [float(s.get('win_rate', '0.0%').replace('%', '')) for s in passed_stocks if s.get('total_signals', 0) > 0]
    profit_rates = [float(s.get('avg_max_profit', '0.0%').replace('%', '')) for s in passed_stocks if s.get('total_signals', 0) > 0]
    days_to_peak = [float(s.get('avg_days_to_peak', '0.0 å¤©').replace(' å¤©', '')) for s in passed_stocks if s.get('total_signals', 0) > 0]
    
    avg_win_rate = sum(win_rates) / len(win_rates) if win_rates else 0
    avg_profit_rate = sum(profit_rates) / len(profit_rates) if profit_rates else 0
    avg_days_to_peak = sum(days_to_peak) / len(days_to_peak) if days_to_peak else 0
    
    summary = {
        'scan_summary': {
            'total_signals': total_signals, 'scan_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'), 'strategy': STRATEGY_TO_RUN, 'total_historical_signals': total_historical_signals, 'avg_win_rate': f"{avg_win_rate:.1f}%", 'avg_profit_rate': f"{avg_profit_rate:.1f}%", 'avg_days_to_peak': f"{avg_days_to_peak:.1f} å¤©"
        },
        'signal_breakdown': signal_states,
        'top_performers': sorted([s for s in passed_stocks if s.get('total_signals', 0) > 0], key=lambda x: float(x.get('avg_max_profit', '0%').replace('%', '')), reverse=True)[:10]
    }
    
    return summary

def trigger_deep_scan_multithreaded(passed_stocks):
    """è§¦å‘å¤šçº¿ç¨‹æ·±åº¦æ‰«æ"""
    if not passed_stocks:
        print("âš ï¸ æ²¡æœ‰é€šè¿‡ç­›é€‰çš„è‚¡ç¥¨ï¼Œè·³è¿‡æ·±åº¦æ‰«æ")
        return None
    
    print(f"\nğŸ” è§¦å‘å¤šçº¿ç¨‹æ·±åº¦æ‰«æ...")
    print(f"ğŸ“Š ç­›é€‰å‡º {len(passed_stocks)} åªè‚¡ç¥¨è¿›è¡Œæ·±åº¦åˆ†æ")
    
    stock_codes = [stock['stock_code'] for stock in passed_stocks]
    
    try:
        from run_enhanced_screening import deep_scan_stocks
        max_workers = min(cpu_count() * 2, len(stock_codes), 32)
        print(f"ğŸ§µ ä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹è¿›è¡Œæ·±åº¦æ‰«æ")
        deep_scan_results = deep_scan_stocks(stock_codes, use_optimized_params=True, max_workers=max_workers)
        print(f"âœ… å¤šçº¿ç¨‹æ·±åº¦æ‰«æå®Œæˆ")
        return deep_scan_results
        
    except Exception as e:
        print(f"âŒ å¤šçº¿ç¨‹æ·±åº¦æ‰«æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def main():
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    start_time = datetime.now()
    logger.info(f"===== å¼€å§‹æ‰§è¡Œæ‰¹é‡ç­›é€‰, ç­–ç•¥: {STRATEGY_TO_RUN} =====")
    print(f"ğŸš€ å¼€å§‹æ‰§è¡Œæ‰¹é‡ç­›é€‰, ç­–ç•¥: {STRATEGY_TO_RUN}")
    print(f"â° æ‰«ææ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    all_files = []
    for market in MARKETS:
        path = os.path.join(BASE_PATH, market, 'lday', '*.day')
        files = glob.glob(path)
        if not files:
            print(f"âš ï¸ è­¦å‘Š: åœ¨è·¯å¾„ {path} æœªæ‰¾åˆ°ä»»ä½•æ–‡ä»¶ã€‚")
        all_files.extend([(f, market) for f in files])
    
    if not all_files:
        print("âŒ é”™è¯¯: æœªèƒ½åœ¨ä»»ä½•å¸‚åœºç›®å½•ä¸‹æ‰¾åˆ°æ—¥çº¿æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥BASE_PATHé…ç½®ã€‚")
        return

    print(f"ğŸ“Š å…±æ‰¾åˆ° {len(all_files)} ä¸ªæ—¥çº¿æ–‡ä»¶ï¼Œå¼€å§‹å¤šè¿›ç¨‹å¤„ç†...")
    
    with Pool(processes=cpu_count()) as pool:
        results = pool.map(worker, all_files)
    
    passed_stocks = [r for r in results if r is not None]
    processing_time = (datetime.now() - start_time).total_seconds()
    
    print(f"ğŸ“ˆ åˆæ­¥ç­›é€‰å®Œæˆï¼Œé€šè¿‡ç­›é€‰: {len(passed_stocks)} åªè‚¡ç¥¨")
    
    output_file = os.path.join(RESULT_DIR, 'signals_summary.json')
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(passed_stocks, f, ensure_ascii=False, indent=4)
    
    summary_report = generate_summary_report(passed_stocks)
    summary_report['scan_summary']['processing_time'] = f"{processing_time:.2f} ç§’"
    summary_report['scan_summary']['files_processed'] = len(all_files)
    
    summary_file = os.path.join(RESULT_DIR, 'scan_summary_report.json')
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary_report, f, ensure_ascii=False, indent=4)
    
    text_report_file = os.path.join(RESULT_DIR, f'scan_report_{DATE}.txt')
    with open(text_report_file, 'w', encoding='utf-8') as f:
        f.write(f"=== {STRATEGY_TO_RUN} ç­–ç•¥ç­›é€‰æŠ¥å‘Š ===\n")
        f.write(f"æ‰«ææ—¶é—´: {summary_report['scan_summary']['scan_timestamp']}\n")
        f.write(f"å¤„ç†æ–‡ä»¶æ•°: {summary_report['scan_summary']['files_processed']}\n")
        f.write(f"å¤„ç†è€—æ—¶: {summary_report['scan_summary']['processing_time']}\n")
        f.write(f"å‘ç°ä¿¡å·æ•°: {summary_report['scan_summary']['total_signals']}\n")
        f.write(f"å†å²ä¿¡å·æ€»æ•°: {summary_report['scan_summary'].get('total_historical_signals', 0)}\n")
        f.write(f"å¹³å‡èƒœç‡: {summary_report['scan_summary']['avg_win_rate']}\n")
        f.write(f"å¹³å‡æ”¶ç›Šç‡: {summary_report['scan_summary']['avg_profit_rate']}\n")
        f.write(f"å¹³å‡è¾¾å³°å¤©æ•°: {summary_report['scan_summary']['avg_days_to_peak']}\n\n")
        
        if summary_report['signal_breakdown']:
            f.write("=== ä¿¡å·çŠ¶æ€åˆ†å¸ƒ ===\n")
            for state, stocks in summary_report['signal_breakdown'].items():
                f.write(f"{state}: {len(stocks)} ä¸ª\n")
            f.write("\n")
        
        if summary_report['top_performers']:
            f.write("=== å‰10åè¡¨ç°æœ€ä½³è‚¡ç¥¨ ===\n")
            for i, stock in enumerate(summary_report['top_performers'], 1):
                f.write(f"{i:2d}. {stock['stock_code']} - èƒœç‡: {stock.get('win_rate', 'N/A')}, "
                       f"æ”¶ç›Š: {stock.get('avg_max_profit', 'N/A')}, "
                       f"å¤©æ•°: {stock.get('avg_days_to_peak', 'N/A')}\n")
    
    print(f"\nğŸ“Š åˆæ­¥ç­›é€‰å®Œæˆï¼")
    print(f"ğŸ¯ å‘ç°ä¿¡å·: {len(passed_stocks)} ä¸ª")
    print(f"â±ï¸ å¤„ç†è€—æ—¶: {processing_time:.2f} ç§’")
    print(f"ğŸ“ˆ å¹³å‡èƒœç‡: {summary_report['scan_summary']['avg_win_rate']}")
    print(f"ğŸ’° å¹³å‡æ”¶ç›Š: {summary_report['scan_summary']['avg_profit_rate']}")
    print(f"ğŸ“„ ç»“æœå·²ä¿å­˜è‡³:")
    print(f"  - ä¿¡å·åˆ—è¡¨: {output_file}")
    print(f"  - æ±‡æ€»æŠ¥å‘Š: {summary_file}")
    print(f"  - æ–‡æœ¬æŠ¥å‘Š: {text_report_file}")
    
    if len(passed_stocks) > 0:
        print(f"\n" + "="*60)
        print(f"ğŸ” å¯åŠ¨æ·±åº¦æ‰«æé˜¶æ®µ (å¤šçº¿ç¨‹)")
        print(f"="*60)
        
        deep_scan_results = trigger_deep_scan_multithreaded(passed_stocks)
        
        if deep_scan_results:
            valid_deep_results = {k: v for k, v in deep_scan_results.items() if 'error' not in v}
            a_grade_stocks = [k for k, v in valid_deep_results.items() if v.get('overall_score', {}).get('grade') == 'A']
            price_evaluated_stocks = [k for k, v in valid_deep_results.items() if 'price_evaluation' in v]
            buy_recommendations = [k for k, v in valid_deep_results.items() if v.get('recommendation', {}).get('action') == 'BUY']
            
            print(f"\nğŸ‰ æ·±åº¦æ‰«æç»“æœ:")
            print(f"ğŸ“Š æ·±åº¦åˆ†ææˆåŠŸ: {len(valid_deep_results)}/{len(passed_stocks)}")
            print(f"ğŸ† Açº§è‚¡ç¥¨å‘ç°: {len(a_grade_stocks)}")
            print(f"ğŸ’° ä»·æ ¼è¯„ä¼°å®Œæˆ: {len(price_evaluated_stocks)}")
            print(f"ğŸŸ¢ ä¹°å…¥æ¨è: {len(buy_recommendations)}")
            
            if a_grade_stocks:
                print(f"\nğŸŒŸ Açº§è‚¡ç¥¨åˆ—è¡¨:")
                for stock_code in a_grade_stocks:
                    result = valid_deep_results[stock_code]
                    score = result['overall_score']['total_score']
                    price = result['basic_analysis']['current_price']
                    action = result['recommendation']['action']
                    confidence = result['recommendation']['confidence']
                    price_eval_mark = " ğŸ’°" if 'price_evaluation' in result else ""
                    print(f"  ğŸ† {stock_code}: {score:.1f}åˆ†, Â¥{price:.2f}, {action} ({confidence:.1%}){price_eval_mark}")
            
            summary_report['deep_scan_summary'] = {
                'total_analyzed': len(valid_deep_results), 'a_grade_count': len(a_grade_stocks), 'price_evaluated_count': len(price_evaluated_stocks), 'buy_recommendations': len(buy_recommendations), 'a_grade_stocks': a_grade_stocks, 'buy_recommendation_stocks': buy_recommendations
            }
            
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary_report, f, ensure_ascii=False, indent=4)
            
            with open(text_report_file, 'a', encoding='utf-8') as f:
                f.write(f"\n=== æ·±åº¦æ‰«æç»“æœ (å¤šçº¿ç¨‹) ===\n")
                f.write(f"æ·±åº¦åˆ†ææˆåŠŸ: {len(valid_deep_results)}/{len(passed_stocks)}\n")
                f.write(f"Açº§è‚¡ç¥¨å‘ç°: {len(a_grade_stocks)}\n")
                f.write(f"ä»·æ ¼è¯„ä¼°å®Œæˆ: {len(price_evaluated_stocks)}\n")
                f.write(f"ä¹°å…¥æ¨è: {len(buy_recommendations)}\n\n")
                
                if a_grade_stocks:
                    f.write("=== Açº§è‚¡ç¥¨è¯¦æƒ… ===\n")
                    for stock_code in a_grade_stocks:
                        result = valid_deep_results[stock_code]
                        score = result['overall_score']['total_score']
                        price = result['basic_analysis']['current_price']
                        action = result['recommendation']['action']
                        confidence = result['recommendation']['confidence']
                        price_eval_mark = " [å·²è¯„ä¼°]" if 'price_evaluation' in result else ""
                        f.write(f"{stock_code}: {score:.1f}åˆ†, Â¥{price:.2f}, {action} (ä¿¡å¿ƒåº¦: {confidence:.1%}){price_eval_mark}\n")
                
                if buy_recommendations:
                    f.write(f"\n=== ä¹°å…¥æ¨èè‚¡ç¥¨ ===\n")
                    for stock_code in buy_recommendations:
                        result = valid_deep_results[stock_code]
                        score = result['overall_score']['total_score']
                        price = result['basic_analysis']['current_price']
                        confidence = result['recommendation']['confidence']
                        f.write(f"{stock_code}: {score:.1f}åˆ†, Â¥{price:.2f}, ä¿¡å¿ƒåº¦: {confidence:.1%}\n")
    else:
        print(f"\nâš ï¸ æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ï¼Œè·³è¿‡æ·±åº¦æ‰«æ")
    
    total_time = (datetime.now() - start_time).total_seconds()
    print(f"\nğŸ‰ å®Œæ•´æ‰«ææµç¨‹ç»“æŸï¼æ€»è€—æ—¶: {total_time:.2f} ç§’")
    
    logger.info(f"===== å®Œæ•´æ‰«æå®Œæˆï¼åˆæ­¥ç­›é€‰: {len(passed_stocks)} ä¸ªä¿¡å·ï¼Œæ€»è€—æ—¶: {total_time:.2f} ç§’ =====")

if __name__ == '__main__':
    main()
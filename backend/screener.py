import os
import glob
import json
import pandas as pd
from multiprocessing import Pool, cpu_count
from datetime import datetime
import logging
import data_loader
import strategies
import backtester
import indicators
from win_rate_filter import WinRateFilter, AdvancedTripleCrossFilter

# --- é…ç½® ---
BASE_PATH = os.path.expanduser("~/.local/share/tdxcfv/drive_c/tc/vipdoc")
MARKETS = ['sh', 'sz', 'bj']
#STRATEGY_TO_RUN = 'MACD_ZERO_AXIS' 
#STRATEGY_TO_RUN = 'TRIPLE_CROSS' 
#STRATEGY_TO_RUN = 'PRE_CROSS'
STRATEGY_TO_RUN = 'WEEKLY_GOLDEN_CROSS_MA'
# --- è·¯å¾„å®šä¹‰ ---
backend_dir = os.path.dirname(os.path.abspath(__file__))
OUTPUT_PATH = os.path.abspath(os.path.join(backend_dir, '..', 'data', 'result'))

# --- åˆå§‹åŒ–æ—¥å¿— ---
DATE = datetime.now().strftime("%Y%m%d_%H%M")
RESULT_DIR = os.path.join(OUTPUT_PATH, STRATEGY_TO_RUN)
os.makedirs(RESULT_DIR, exist_ok=True)
LOG_FILE = os.path.join(RESULT_DIR, f'log_screener_{DATE}.txt')

file_handler = logging.FileHandler(LOG_FILE, 'a', 'utf-8')
file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
logger = logging.getLogger('screener_logger')
logger.setLevel(logging.INFO)
if logger.hasHandlers():
    logger.handlers.clear()
logger.addHandler(file_handler)

def calculate_backtest_stats(df, signal_series):
    """è®¡ç®—ç»†åŒ–çš„å›æµ‹ç»Ÿè®¡ä¿¡æ¯"""
    try:
        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ˆå›æµ‹éœ€è¦ï¼‰
        macd_values = indicators.calculate_macd(df)
        df['dif'], df['dea'] = macd_values[0], macd_values[1]
        kdj_values = indicators.calculate_kdj(df)
        df['k'], df['d'], df['j'] = kdj_values[0], kdj_values[1], kdj_values[2]
        
        # æ‰§è¡Œç»†åŒ–å›æµ‹
        backtest_results = backtester.run_backtest(df, signal_series)
        
        if isinstance(backtest_results, dict) and backtest_results.get('total_signals', 0) > 0:
            stats = {
                'total_signals': backtest_results.get('total_signals', 0),
                'win_rate': backtest_results.get('win_rate', '0.0%'),
                'avg_max_profit': backtest_results.get('avg_max_profit', '0.0%'),
                'avg_max_drawdown': backtest_results.get('avg_max_drawdown', '0.0%'),
                'avg_days_to_peak': backtest_results.get('avg_days_to_peak', '0.0 å¤©')
            }
            
            # æ·»åŠ å„çŠ¶æ€ç»Ÿè®¡ä¿¡æ¯
            if 'state_statistics' in backtest_results:
                stats['state_statistics'] = backtest_results['state_statistics']
            
            # æ·»åŠ è¯¦ç»†äº¤æ˜“ä¿¡æ¯ï¼ˆç”¨äºè¿›ä¸€æ­¥åˆ†æï¼‰
            if 'trades' in backtest_results:
                # è®¡ç®—ä¸€äº›é¢å¤–çš„ç»Ÿè®¡æŒ‡æ ‡
                trades = backtest_results['trades']
                if trades:
                    # æœ€ä½³è¡¨ç°äº¤æ˜“
                    best_trade = max(trades, key=lambda x: x['actual_max_pnl'])
                    worst_trade = min(trades, key=lambda x: x['actual_max_pnl'])
                    
                    stats.update({
                        'best_trade_profit': f"{best_trade['actual_max_pnl']:.1%}",
                        'worst_trade_profit': f"{worst_trade['actual_max_pnl']:.1%}",
                        'avg_entry_strategy': get_most_common_entry_strategy(trades)
                    })
            
            return stats
        else:
            return {
                'total_signals': 0,
                'win_rate': '0.0%',
                'avg_max_profit': '0.0%',
                'avg_max_drawdown': '0.0%',
                'avg_days_to_peak': '0.0 å¤©'
            }
    except Exception as e:
        logger.error(f"å›æµ‹è®¡ç®—å¤±è´¥: {e}")
        return {
            'total_signals': 0,
            'win_rate': '0.0%',
            'avg_max_profit': '0.0%',
            'avg_max_drawdown': '0.0%',
            'avg_days_to_peak': '0.0 å¤©'
        }

def get_most_common_entry_strategy(trades):
    """è·å–æœ€å¸¸ç”¨çš„å…¥åœºç­–ç•¥"""
    try:
        from collections import Counter
        strategies = [trade.get('entry_strategy', 'æœªçŸ¥') for trade in trades]
        most_common = Counter(strategies).most_common(1)
        return most_common[0][0] if most_common else 'æœªçŸ¥'
    except:
        return 'æœªçŸ¥'

def check_macd_zero_axis_pre_filter(df, signal_idx, signal_state, lookback_days=5):
    """
    MACDé›¶è½´å¯åŠ¨ç­–ç•¥çš„é¢„ç­›é€‰è¿‡æ»¤å™¨ï¼šæ’é™¤äº”æ—¥å†…ä»·æ ¼ä¸Šæ¶¨è¶…è¿‡5%çš„æƒ…å†µ
    
    Args:
        df: è‚¡ç¥¨æ•°æ®DataFrame
        signal_idx: ä¿¡å·å‡ºç°çš„ç´¢å¼•
        signal_state: ä¿¡å·çŠ¶æ€
        lookback_days: å›çœ‹å¤©æ•°
    
    Returns:
        tuple: (æ˜¯å¦åº”è¯¥æ’é™¤, æ’é™¤åŸå› )
    """
    try:
        # åªå¯¹MACDé›¶è½´å¯åŠ¨ç­–ç•¥è¿›è¡Œè¿‡æ»¤
        if signal_state not in ['PRE', 'MID', 'POST']:
            return False, ""
        
        # è·å–ä¿¡å·å‰5å¤©çš„æ•°æ®
        start_idx = max(0, signal_idx - lookback_days)
        end_idx = signal_idx
        
        if start_idx >= end_idx:
            return False, ""
        
        # è®¡ç®—5æ—¥å†…çš„æœ€å¤§æ¶¨å¹…
        lookback_data = df.iloc[start_idx:end_idx + 1]
        if len(lookback_data) < 2:
            return False, ""
        
        # è·å–5æ—¥å‰çš„æ”¶ç›˜ä»·å’Œä¿¡å·å½“å¤©çš„æœ€é«˜ä»·
        base_price = lookback_data.iloc[0]['close']  # 5æ—¥å‰æ”¶ç›˜ä»·
        current_high = df.iloc[signal_idx]['high']    # ä¿¡å·å½“å¤©æœ€é«˜ä»·
        
        # è®¡ç®—æ¶¨å¹…
        price_increase = (current_high - base_price) / base_price
        
        # å¦‚æœ5æ—¥å†…æ¶¨å¹…è¶…è¿‡5%ï¼Œåˆ™æ’é™¤
        if price_increase > 0.05:
            return True, f"äº”æ—¥å†…æ¶¨å¹…{price_increase:.1%}è¶…è¿‡5%ï¼Œæ’é™¤è¿½é«˜é£é™©"
        
        return False, ""
        
    except Exception as e:
        print(f"MACDé›¶è½´é¢„ç­›é€‰è¿‡æ»¤å™¨æ£€æŸ¥å¤±è´¥: {e}")
        return False, ""

def check_weekly_golden_cross_ma_filter(df, signal_idx, signal_state, stock_code):
    """
    å‘¨çº¿é‡‘å‰+æ—¥çº¿MAç­–ç•¥çš„è¿‡æ»¤å™¨
    
    Args:
        df: è‚¡ç¥¨æ•°æ®DataFrame
        signal_idx: ä¿¡å·å‡ºç°çš„ç´¢å¼•
        signal_state: ä¿¡å·çŠ¶æ€ ('BUY', 'HOLD', 'SELL')
        stock_code: è‚¡ç¥¨ä»£ç 
    
    Returns:
        tuple: (æ˜¯å¦åº”è¯¥æ’é™¤, æ’é™¤åŸå› )
    """
    try:
        # åªå¯¹BUYä¿¡å·è¿›è¡Œä¸¥æ ¼è¿‡æ»¤
        if signal_state != 'BUY':
            return False, ""
        
        # 1. æ£€æŸ¥æ•°æ®é•¿åº¦æ˜¯å¦è¶³å¤Ÿ
        if len(df) < 240:  # éœ€è¦è¶³å¤Ÿçš„æ•°æ®è®¡ç®—MA240
            return True, "æ•°æ®é•¿åº¦ä¸è¶³ï¼Œæ— æ³•è®¡ç®—é•¿æœŸMA"
        
        # 2. æ£€æŸ¥ä»·æ ¼æ˜¯å¦è¿‡åº¦ä¸Šæ¶¨ï¼ˆé˜²æ­¢è¿½é«˜ï¼‰
        current_price = df.iloc[signal_idx]['close']
        ma13 = df['close'].rolling(window=13).mean().iloc[signal_idx]
        
        if pd.isna(ma13):
            return True, "MA13è®¡ç®—å¤±è´¥"
        
        # ä»·æ ¼è·ç¦»MA13è¶…è¿‡5%åˆ™æ’é™¤
        price_distance = (current_price - ma13) / ma13
        if price_distance > 0.05:
            return True, f"ä»·æ ¼è·ç¦»MA13è¿‡è¿œ({price_distance:.1%})ï¼Œæ’é™¤è¿½é«˜é£é™©"
        
        # 3. æ£€æŸ¥æˆäº¤é‡æ˜¯å¦å¼‚å¸¸
        if 'volume' in df.columns:
            current_volume = df.iloc[signal_idx]['volume']
            avg_volume = df['volume'].rolling(window=20).mean().iloc[signal_idx]
            
            if not pd.isna(avg_volume) and avg_volume > 0:
                volume_ratio = current_volume / avg_volume
                # æˆäº¤é‡è¿‡åº¦æ”¾å¤§ï¼ˆè¶…è¿‡5å€ï¼‰å¯èƒ½æ˜¯å¼‚å¸¸
                if volume_ratio > 5.0:
                    return True, f"æˆäº¤é‡å¼‚å¸¸æ”¾å¤§({volume_ratio:.1f}å€)ï¼Œå¯èƒ½å­˜åœ¨é£é™©"
        
        # 4. æ£€æŸ¥çŸ­æœŸæ¶¨å¹…ï¼ˆ5æ—¥å†…æ¶¨å¹…è¶…è¿‡15%æ’é™¤ï¼‰
        if signal_idx >= 5:
            price_5_days_ago = df.iloc[signal_idx - 5]['close']
            short_term_gain = (current_price - price_5_days_ago) / price_5_days_ago
            if short_term_gain > 0.15:
                return True, f"çŸ­æœŸæ¶¨å¹…è¿‡å¤§({short_term_gain:.1%})ï¼Œæ’é™¤è¿½é«˜é£é™©"
        
        return False, ""
        
    except Exception as e:
        logger.error(f"å‘¨çº¿é‡‘å‰+æ—¥çº¿MAè¿‡æ»¤å™¨æ£€æŸ¥å¤±è´¥ {stock_code}: {e}")
        return True, f"è¿‡æ»¤å™¨æ‰§è¡Œå¤±è´¥: {e}"

def analyze_ma_trend(df):
    """
    åˆ†æMAè¶‹åŠ¿å¼ºåº¦å’Œç›¸å…³æŒ‡æ ‡
    
    Args:
        df: è‚¡ç¥¨æ•°æ®DataFrame
    
    Returns:
        dict: åŒ…å«è¶‹åŠ¿åˆ†æç»“æœçš„å­—å…¸
    """
    try:
        # è®¡ç®—å„ç§MA
        ma_periods = [7, 13, 30, 45]
        mas = {}
        for period in ma_periods:
            mas[f'ma_{period}'] = df['close'].rolling(window=period).mean()
        
        current_price = df['close'].iloc[-1]
        ma13_current = mas['ma_13'].iloc[-1]
        
        # 1. è®¡ç®—è¶‹åŠ¿å¼ºåº¦ï¼ˆMAæ’åˆ—ç¨‹åº¦ï¼‰
        trend_strength = 0
        if not pd.isna(ma13_current):
            # æ£€æŸ¥MAæ’åˆ—ï¼š7>13>30>45
            if (mas['ma_7'].iloc[-1] > mas['ma_13'].iloc[-1] and
                mas['ma_13'].iloc[-1] > mas['ma_30'].iloc[-1] and
                mas['ma_30'].iloc[-1] > mas['ma_45'].iloc[-1]):
                trend_strength = 1.0
            elif (mas['ma_7'].iloc[-1] > mas['ma_13'].iloc[-1] and
                  mas['ma_13'].iloc[-1] > mas['ma_30'].iloc[-1]):
                trend_strength = 0.7
            elif mas['ma_7'].iloc[-1] > mas['ma_13'].iloc[-1]:
                trend_strength = 0.4
            else:
                trend_strength = 0.0
        
        # 2. è®¡ç®—ä»·æ ¼è·ç¦»MA13çš„ç™¾åˆ†æ¯”
        ma13_distance = 0
        if not pd.isna(ma13_current) and ma13_current > 0:
            ma13_distance = (current_price - ma13_current) / ma13_current
        
        # 3. è®¡ç®—æˆäº¤é‡æ”¾å¤§æ¯”ä¾‹
        volume_surge_ratio = 1.0
        if 'volume' in df.columns and len(df) >= 20:
            current_volume = df['volume'].iloc[-1]
            avg_volume = df['volume'].rolling(window=20).mean().iloc[-1]
            if not pd.isna(avg_volume) and avg_volume > 0:
                volume_surge_ratio = current_volume / avg_volume
        
        return {
            'trend_strength': trend_strength,
            'ma13_distance': ma13_distance,
            'volume_surge_ratio': volume_surge_ratio
        }
        
    except Exception as e:
        logger.error(f"MAè¶‹åŠ¿åˆ†æå¤±è´¥: {e}")
        return {
            'trend_strength': 0,
            'ma13_distance': 0,
            'volume_surge_ratio': 1.0
        }

def check_triple_cross_enhanced_filter(df, signal_idx, stock_code):
    """
    TRIPLE_CROSSç­–ç•¥çš„å¢å¼ºè¿‡æ»¤å™¨ï¼šç»“åˆèƒœç‡ç­›é€‰å’Œäº¤å‰é˜¶æ®µåˆ†æ
    
    Args:
        df: è‚¡ç¥¨æ•°æ®DataFrame
        signal_idx: ä¿¡å·å‡ºç°çš„ç´¢å¼•
        stock_code: è‚¡ç¥¨ä»£ç 
    
    Returns:
        tuple: (æ˜¯å¦åº”è¯¥æ’é™¤, æ’é™¤åŸå› , è¯¦ç»†ä¿¡æ¯)
    """
    try:
        # 1. ä½¿ç”¨å¢å¼ºç‰ˆè¿‡æ»¤å™¨
        advanced_filter = AdvancedTripleCrossFilter()
        should_exclude, exclude_reason, quality_score, cross_stage = advanced_filter.enhanced_triple_cross_filter(df, signal_idx)
        
        if should_exclude:
            return True, exclude_reason, {
                'quality_score': quality_score,
                'cross_stage': cross_stage,
                'filter_type': 'advanced_quality'
            }
        
        # 2. èƒœç‡è¿‡æ»¤å™¨æ£€æŸ¥
        signal_series = strategies.apply_triple_cross(df)
        if signal_series is not None:
            win_rate_filter = WinRateFilter(min_win_rate=0.4, min_signals=3, min_avg_profit=0.08)
            should_exclude_wr, exclude_reason_wr, backtest_stats = win_rate_filter.should_exclude_stock(df, signal_series, stock_code)
            
            if should_exclude_wr:
                return True, f"èƒœç‡ç­›é€‰: {exclude_reason_wr}", {
                    'quality_score': quality_score,
                    'cross_stage': cross_stage,
                    'filter_type': 'win_rate',
                    'backtest_stats': backtest_stats
                }
        
        # 3. é€šè¿‡æ‰€æœ‰ç­›é€‰
        return False, "é€šè¿‡å¢å¼ºç­›é€‰", {
            'quality_score': quality_score,
            'cross_stage': cross_stage,
            'filter_type': 'passed',
            'backtest_stats': backtest_stats if 'backtest_stats' in locals() else {}
        }
        
    except Exception as e:
        return True, f"å¢å¼ºè¿‡æ»¤å™¨æ‰§è¡Œå¤±è´¥: {e}", {
            'quality_score': 0,
            'cross_stage': 'UNKNOWN',
            'filter_type': 'error'
        }

def worker(args):
    """å¤šè¿›ç¨‹å·¥ä½œå‡½æ•° - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œæé«˜æ‰§è¡Œæ•ˆç‡"""
    file_path, market = args
    stock_code_full = os.path.basename(file_path).split('.')[0]
    stock_code_no_prefix = stock_code_full.replace(market, '')

    # å¿«é€Ÿè¿‡æ»¤æ— æ•ˆè‚¡ç¥¨ä»£ç 
    valid_prefixes = ('600', '601', '603', '000', '001', '002', '003', '300', '688')
    if not stock_code_no_prefix.startswith(valid_prefixes):
        return None

    try:
        # å¿«é€ŸåŠ è½½æ•°æ®
        df = data_loader.get_daily_data(file_path)
        if df is None or len(df) < 150:
            return None

        # é¢„è®¡ç®—å¸¸ç”¨æ•°æ®
        current_timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        latest_date = df.index[-1].strftime('%Y-%m-%d')
        
        result_base = {
            'stock_code': stock_code_full,
            'strategy': STRATEGY_TO_RUN,
            'date': latest_date,
            'scan_timestamp': current_timestamp
        }
        
        # æ ¹æ®ç­–ç•¥æ‰§è¡Œç›¸åº”é€»è¾‘
        if STRATEGY_TO_RUN == 'PRE_CROSS':
            return _process_pre_cross_strategy(df, result_base)
        elif STRATEGY_TO_RUN == 'TRIPLE_CROSS':
            return _process_triple_cross_strategy(df, result_base, stock_code_full)
        elif STRATEGY_TO_RUN == 'MACD_ZERO_AXIS':
            return _process_macd_zero_axis_strategy(df, result_base, stock_code_full)
        elif STRATEGY_TO_RUN == 'WEEKLY_GOLDEN_CROSS_MA':
            return _process_weekly_golden_cross_ma_strategy(df, result_base, stock_code_full)
        
        return None
        
    except Exception as e:
        logger.error(f"å¤„ç† {stock_code_full} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return None

def _process_pre_cross_strategy(df, result_base):
    """å¤„ç†PRE_CROSSç­–ç•¥"""
    try:
        signal_series = strategies.apply_pre_cross(df)
        if signal_series is not None and signal_series.iloc[-1]:
            backtest_stats = calculate_backtest_stats_fast(df, signal_series)
            result_base.update(backtest_stats)
            return result_base
        return None
    except Exception as e:
        return None

def _process_triple_cross_strategy(df, result_base, stock_code_full):
    """å¤„ç†TRIPLE_CROSSç­–ç•¥"""
    try:
        signal_series = strategies.apply_triple_cross(df)
        if signal_series is not None and signal_series.iloc[-1]:
            # å¿«é€Ÿè¿‡æ»¤æ£€æŸ¥
            should_exclude, exclude_reason, filter_details = check_triple_cross_enhanced_filter(df, len(df) - 1, stock_code_full)
            
            if should_exclude:
                logger.info(f"{stock_code_full} è¢«è¿‡æ»¤: {exclude_reason}")
                return None
            
            backtest_stats = calculate_backtest_stats_fast(df, signal_series)
            result_base.update({
                'quality_score': filter_details.get('quality_score', 0),
                'cross_stage': filter_details.get('cross_stage', 'UNKNOWN'),
                'filter_status': 'passed',
                **backtest_stats
            })
            return result_base
        return None
    except Exception as e:
        return None

def _process_macd_zero_axis_strategy(df, result_base, stock_code_full):
    """å¤„ç†MACD_ZERO_AXISç­–ç•¥"""
    try:
        signal_series = strategies.apply_macd_zero_axis_strategy(df)
        signal_state = signal_series.iloc[-1]
        if signal_state in ['PRE', 'MID', 'POST']:
            # å¿«é€Ÿè¿‡æ»¤æ£€æŸ¥
            should_exclude, exclude_reason = check_macd_zero_axis_pre_filter(df, len(df) - 1, signal_state)
            
            if should_exclude:
                logger.info(f"{stock_code_full} è¢«è¿‡æ»¤: {exclude_reason}")
                return None
            
            backtest_stats = calculate_backtest_stats_fast(df, signal_series)
            result_base.update({
                'signal_state': signal_state,
                'filter_status': 'passed',
                **backtest_stats
            })
            return result_base
        return None
    except Exception as e:
        return None

def _process_weekly_golden_cross_ma_strategy(df, result_base, stock_code_full):
    """å¤„ç†WEEKLY_GOLDEN_CROSS_MAç­–ç•¥"""
    try:
        signal_series = strategies.apply_weekly_golden_cross_ma_strategy(df)
        signal_state = signal_series.iloc[-1]
        
        if signal_state in ['BUY', 'HOLD', 'SELL']:
            # å‘¨çº¿é‡‘å‰+æ—¥çº¿MAç­–ç•¥çš„è¿‡æ»¤æ£€æŸ¥
            should_exclude, exclude_reason = check_weekly_golden_cross_ma_filter(df, len(df) - 1, signal_state, stock_code_full)
            
            if should_exclude:
                logger.info(f"{stock_code_full} è¢«è¿‡æ»¤: {exclude_reason}")
                return None
            
            backtest_stats = calculate_backtest_stats_fast(df, signal_series)
            
            # è®¡ç®—é¢å¤–çš„MAç›¸å…³æŒ‡æ ‡
            ma_analysis = analyze_ma_trend(df)
            
            result_base.update({
                'signal_state': signal_state,
                'filter_status': 'passed',
                'ma_trend_strength': ma_analysis.get('trend_strength', 0),
                'ma13_distance': ma_analysis.get('ma13_distance', 0),
                'volume_surge_ratio': ma_analysis.get('volume_surge_ratio', 1.0),
                **backtest_stats
            })
            return result_base
        return None
    except Exception as e:
        logger.error(f"å¤„ç†å‘¨çº¿é‡‘å‰+æ—¥çº¿MAç­–ç•¥å¤±è´¥ {stock_code_full}: {e}")
        return None

def calculate_backtest_stats_fast(df, signal_series):
    """å¿«é€Ÿè®¡ç®—å›æµ‹ç»Ÿè®¡ä¿¡æ¯ - ä¼˜åŒ–ç‰ˆæœ¬"""
    try:
        # åªè®¡ç®—å¿…è¦çš„æŠ€æœ¯æŒ‡æ ‡
        if 'dif' not in df.columns or 'dea' not in df.columns:
            macd_values = indicators.calculate_macd(df)
            df['dif'], df['dea'] = macd_values[0], macd_values[1]
        
        if 'k' not in df.columns or 'd' not in df.columns:
            kdj_values = indicators.calculate_kdj(df)
            df['k'], df['d'], df['j'] = kdj_values[0], kdj_values[1], kdj_values[2]
        
        # æ‰§è¡Œå¿«é€Ÿå›æµ‹
        backtest_results = backtester.run_backtest(df, signal_series)
        
        if isinstance(backtest_results, dict) and backtest_results.get('total_signals', 0) > 0:
            return {
                'total_signals': backtest_results.get('total_signals', 0),
                'win_rate': backtest_results.get('win_rate', '0.0%'),
                'avg_max_profit': backtest_results.get('avg_max_profit', '0.0%'),
                'avg_max_drawdown': backtest_results.get('avg_max_drawdown', '0.0%'),
                'avg_days_to_peak': backtest_results.get('avg_days_to_peak', '0.0 å¤©')
            }
        else:
            return {
                'total_signals': 0,
                'win_rate': '0.0%',
                'avg_max_profit': '0.0%',
                'avg_max_drawdown': '0.0%',
                'avg_days_to_peak': '0.0 å¤©'
            }
    except Exception as e:
        logger.error(f"å¿«é€Ÿå›æµ‹è®¡ç®—å¤±è´¥: {e}")
        return {
            'total_signals': 0,
            'win_rate': '0.0%',
            'avg_max_profit': '0.0%',
            'avg_max_drawdown': '0.0%',
            'avg_days_to_peak': '0.0 å¤©'
        }

def generate_summary_report(passed_stocks):
    """ç”Ÿæˆè¯¦ç»†çš„æ±‡æ€»æŠ¥å‘Š"""
    if not passed_stocks:
        return {
            'scan_summary': {
                'total_signals': 0,
                'scan_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'strategy': STRATEGY_TO_RUN,
                'total_historical_signals': 0,
                'avg_win_rate': '0.0%',
                'avg_profit_rate': '0.0%',
                'avg_days_to_peak': '0.0 å¤©'
            },
            'signal_breakdown': {},
            'top_performers': []
        }
    
    # è®¡ç®—æ•´ä½“ç»Ÿè®¡
    total_signals = len(passed_stocks)
    
    # æŒ‰ä¿¡å·çŠ¶æ€åˆ†ç»„ï¼ˆä»…é€‚ç”¨äºMACD_ZERO_AXISç­–ç•¥ï¼‰
    signal_states = {}
    if STRATEGY_TO_RUN == 'MACD_ZERO_AXIS':
        for stock in passed_stocks:
            state = stock.get('signal_state', 'UNKNOWN')
            if state not in signal_states:
                signal_states[state] = []
            signal_states[state].append(stock)
    
    # è®¡ç®—å¹³å‡å›æµ‹æŒ‡æ ‡
    total_historical_signals = sum(stock.get('total_signals', 0) for stock in passed_stocks if stock.get('total_signals', 0) > 0)
    
    # è§£æèƒœç‡å’Œæ”¶ç›Šç‡ï¼ˆå»æ‰ç™¾åˆ†å·ï¼‰
    win_rates = []
    profit_rates = []
    days_to_peak = []
    
    for stock in passed_stocks:
        if stock.get('total_signals', 0) > 0:
            # è§£æèƒœç‡
            win_rate_str = stock.get('win_rate', '0.0%').replace('%', '')
            try:
                win_rates.append(float(win_rate_str))
            except:
                pass
            
            # è§£ææ”¶ç›Šç‡
            profit_str = stock.get('avg_max_profit', '0.0%').replace('%', '')
            try:
                profit_rates.append(float(profit_str))
            except:
                pass
            
            # è§£æè¾¾å³°å¤©æ•°
            days_str = stock.get('avg_days_to_peak', '0.0 å¤©').replace(' å¤©', '')
            try:
                days_to_peak.append(float(days_str))
            except:
                pass
    
    # è®¡ç®—å¹³å‡å€¼
    avg_win_rate = sum(win_rates) / len(win_rates) if win_rates else 0
    avg_profit_rate = sum(profit_rates) / len(profit_rates) if profit_rates else 0
    avg_days_to_peak = sum(days_to_peak) / len(days_to_peak) if days_to_peak else 0
    
    summary = {
        'scan_summary': {
            'total_signals': total_signals,
            'scan_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'strategy': STRATEGY_TO_RUN,
            'total_historical_signals': total_historical_signals,
            'avg_win_rate': f"{avg_win_rate:.1f}%",
            'avg_profit_rate': f"{avg_profit_rate:.1f}%",
            'avg_days_to_peak': f"{avg_days_to_peak:.1f} å¤©"
        },
        'signal_breakdown': signal_states if signal_states else {},
        'top_performers': sorted(
            [s for s in passed_stocks if s.get('total_signals', 0) > 0],
            key=lambda x: float(x.get('avg_max_profit', '0%').replace('%', '')),
            reverse=True
        )[:10] if passed_stocks else []  # å‰10åè¡¨ç°æœ€å¥½çš„
    }
    
    return summary

def trigger_deep_scan(passed_stocks):
    """è§¦å‘æ·±åº¦æ‰«æ"""
    if not passed_stocks:
        print("âš ï¸ æ²¡æœ‰é€šè¿‡ç­›é€‰çš„è‚¡ç¥¨ï¼Œè·³è¿‡æ·±åº¦æ‰«æ")
        return
    
    print(f"\nğŸ” è§¦å‘æ·±åº¦æ‰«æ...")
    print(f"ğŸ“Š ç­›é€‰å‡º {len(passed_stocks)} åªè‚¡ç¥¨è¿›è¡Œæ·±åº¦åˆ†æ")
    
    # æå–è‚¡ç¥¨ä»£ç 
    stock_codes = [stock['stock_code'] for stock in passed_stocks]
    
    try:
        # å¯¼å…¥æ·±åº¦æ‰«ææ¨¡å—
        from run_enhanced_screening import analyze_multiple_stocks
        
        # æ‰§è¡Œæ·±åº¦æ‰«æ
        deep_scan_results = analyze_multiple_stocks(stock_codes, use_optimized_params=True, max_workers=32)
        
        print(f"âœ… æ·±åº¦æ‰«æå®Œæˆ")
        return deep_scan_results
        
    except Exception as e:
        print(f"âŒ æ·±åº¦æ‰«æå¤±è´¥: {e}")
        return None

def trigger_deep_scan_multithreaded(passed_stocks):
    """è§¦å‘å¤šçº¿ç¨‹æ·±åº¦æ‰«æ"""
    if not passed_stocks:
        print("âš ï¸ æ²¡æœ‰é€šè¿‡ç­›é€‰çš„è‚¡ç¥¨ï¼Œè·³è¿‡æ·±åº¦æ‰«æ")
        return None
    
    print(f"\nğŸ” è§¦å‘å¤šçº¿ç¨‹æ·±åº¦æ‰«æ...")
    print(f"ğŸ“Š ç­›é€‰å‡º {len(passed_stocks)} åªè‚¡ç¥¨è¿›è¡Œæ·±åº¦åˆ†æ")
    
    # æå–è‚¡ç¥¨ä»£ç 
    stock_codes = [stock['stock_code'] for stock in passed_stocks]
    
    try:
        # å¯¼å…¥æ·±åº¦æ‰«ææ¨¡å—
        from run_enhanced_screening import deep_scan_stocks
        
        # æ ¹æ®è‚¡ç¥¨æ•°é‡åŠ¨æ€è°ƒæ•´çº¿ç¨‹æ•°
        max_workers = min(cpu_count() * 2, len(stock_codes), 32)  # æœ€å¤š16ä¸ªçº¿ç¨‹
        print(f"ğŸ§µ ä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹è¿›è¡Œæ·±åº¦æ‰«æ")
        
        # æ‰§è¡Œå¤šçº¿ç¨‹æ·±åº¦æ‰«æ
        deep_scan_results = deep_scan_stocks(stock_codes, use_optimized_params=True, max_workers=max_workers)
        
        print(f"âœ… å¤šçº¿ç¨‹æ·±åº¦æ‰«æå®Œæˆ")
        return deep_scan_results
        
    except Exception as e:
        print(f"âŒ å¤šçº¿ç¨‹æ·±åº¦æ‰«æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def main():
    """ä¸»æ‰§è¡Œå‡½æ•° - å¢å¼ºç‰ˆæœ¬ï¼Œé›†æˆæ·±åº¦æ‰«æï¼Œå¤šçº¿ç¨‹æ“ä½œ"""
    start_time = datetime.now()
    logger.info(f"===== å¼€å§‹æ‰§è¡Œæ‰¹é‡ç­›é€‰, ç­–ç•¥: {STRATEGY_TO_RUN} =====")
    print(f"ğŸš€ å¼€å§‹æ‰§è¡Œæ‰¹é‡ç­›é€‰, ç­–ç•¥: {STRATEGY_TO_RUN}")
    print(f"â° æ‰«ææ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    all_files = []
    for market in MARKETS:
        path = os.path.join(BASE_PATH, market, 'lday', '*.day')
        files = glob.glob(path)
        if not files:
            print(f"âš ï¸ è­¦å‘Š: åœ¨è·¯å¾„ {path} æœªæ‰¾åˆ°ä»»ä½•æ–‡ä»¶ã€‚")
        all_files.extend([(f, market) for f in files])
    
    if not all_files:
        print("âŒ é”™è¯¯: æœªèƒ½åœ¨ä»»ä½•å¸‚åœºç›®å½•ä¸‹æ‰¾åˆ°æ—¥çº¿æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥BASE_PATHé…ç½®ã€‚")
        return

    print(f"ğŸ“Š å…±æ‰¾åˆ° {len(all_files)} ä¸ªæ—¥çº¿æ–‡ä»¶ï¼Œå¼€å§‹å¤šè¿›ç¨‹å¤„ç†...")
    
    # ä½¿ç”¨å¤šè¿›ç¨‹è¿›è¡Œåˆæ­¥ç­›é€‰
    with Pool(processes=cpu_count()) as pool:
        results = pool.map(worker, all_files)
    
    passed_stocks = [r for r in results if r is not None]
    end_time = datetime.now()
    processing_time = (end_time - start_time).total_seconds()
    
    print(f"ğŸ“ˆ åˆæ­¥ç­›é€‰å®Œæˆï¼Œé€šè¿‡ç­›é€‰: {len(passed_stocks)} åªè‚¡ç¥¨")
    
    # ä¿å­˜è¯¦ç»†ä¿¡å·åˆ—è¡¨
    output_file = os.path.join(RESULT_DIR, 'signals_summary.json')
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(passed_stocks, f, ensure_ascii=False, indent=4)
    
    # ç”Ÿæˆå¹¶ä¿å­˜æ±‡æ€»æŠ¥å‘Š
    summary_report = generate_summary_report(passed_stocks)
    summary_report['scan_summary']['processing_time'] = f"{processing_time:.2f} ç§’"
    summary_report['scan_summary']['files_processed'] = len(all_files)
    
    summary_file = os.path.join(RESULT_DIR, 'scan_summary_report.json')
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary_report, f, ensure_ascii=False, indent=4)
    
    # ç”Ÿæˆæ–‡æœ¬æ ¼å¼çš„æ±‡æ€»æŠ¥å‘Š
    text_report_file = os.path.join(RESULT_DIR, f'scan_report_{DATE}.txt')
    with open(text_report_file, 'w', encoding='utf-8') as f:
        f.write(f"=== {STRATEGY_TO_RUN} ç­–ç•¥ç­›é€‰æŠ¥å‘Š ===\n")
        f.write(f"æ‰«ææ—¶é—´: {summary_report['scan_summary']['scan_timestamp']}\n")
        f.write(f"å¤„ç†æ–‡ä»¶æ•°: {summary_report['scan_summary']['files_processed']}\n")
        f.write(f"å¤„ç†è€—æ—¶: {summary_report['scan_summary']['processing_time']}\n")
        f.write(f"å‘ç°ä¿¡å·æ•°: {summary_report['scan_summary']['total_signals']}\n")
        f.write(f"å†å²ä¿¡å·æ€»æ•°: {summary_report['scan_summary'].get('total_historical_signals', 0)}\n")
        f.write(f"å¹³å‡èƒœç‡: {summary_report['scan_summary']['avg_win_rate']}\n")
        f.write(f"å¹³å‡æ”¶ç›Šç‡: {summary_report['scan_summary']['avg_profit_rate']}\n")
        f.write(f"å¹³å‡è¾¾å³°å¤©æ•°: {summary_report['scan_summary']['avg_days_to_peak']}\n\n")
        
        if summary_report['signal_breakdown']:
            f.write("=== ä¿¡å·çŠ¶æ€åˆ†å¸ƒ ===\n")
            for state, stocks in summary_report['signal_breakdown'].items():
                f.write(f"{state}: {len(stocks)} ä¸ª\n")
            f.write("\n")
        
        if summary_report['top_performers']:
            f.write("=== å‰10åè¡¨ç°æœ€ä½³è‚¡ç¥¨ ===\n")
            for i, stock in enumerate(summary_report['top_performers'], 1):
                f.write(f"{i:2d}. {stock['stock_code']} - èƒœç‡: {stock.get('win_rate', 'N/A')}, "
                       f"æ”¶ç›Š: {stock.get('avg_max_profit', 'N/A')}, "
                       f"å¤©æ•°: {stock.get('avg_days_to_peak', 'N/A')}\n")
    
    print(f"\nğŸ“Š åˆæ­¥ç­›é€‰å®Œæˆï¼")
    print(f"ğŸ¯ å‘ç°ä¿¡å·: {len(passed_stocks)} ä¸ª")
    print(f"â±ï¸ å¤„ç†è€—æ—¶: {processing_time:.2f} ç§’")
    print(f"ğŸ“ˆ å¹³å‡èƒœç‡: {summary_report['scan_summary']['avg_win_rate']}")
    print(f"ğŸ’° å¹³å‡æ”¶ç›Š: {summary_report['scan_summary']['avg_profit_rate']}")
    print(f"ğŸ“„ ç»“æœå·²ä¿å­˜è‡³:")
    print(f"  - ä¿¡å·åˆ—è¡¨: {output_file}")
    print(f"  - æ±‡æ€»æŠ¥å‘Š: {summary_file}")
    print(f"  - æ–‡æœ¬æŠ¥å‘Š: {text_report_file}")
    
    # è‡ªåŠ¨è§¦å‘æ·±åº¦æ‰«æï¼ˆå¤šçº¿ç¨‹ï¼‰
    if len(passed_stocks) > 0:
        print(f"\n" + "="*60)
        print(f"ğŸ” å¯åŠ¨æ·±åº¦æ‰«æé˜¶æ®µ (å¤šçº¿ç¨‹)")
        print(f"="*60)
        
        deep_scan_results = trigger_deep_scan_multithreaded(passed_stocks)
        
        if deep_scan_results:
            # ç»Ÿè®¡æ·±åº¦æ‰«æç»“æœ
            valid_deep_results = {k: v for k, v in deep_scan_results.items() if 'error' not in v}
            a_grade_stocks = [k for k, v in valid_deep_results.items() if v.get('overall_score', {}).get('grade') == 'A']
            price_evaluated_stocks = [k for k, v in valid_deep_results.items() if 'price_evaluation' in v]
            buy_recommendations = [k for k, v in valid_deep_results.items() if v.get('recommendation', {}).get('action') == 'BUY']
            
            print(f"\nğŸ‰ æ·±åº¦æ‰«æç»“æœ:")
            print(f"ğŸ“Š æ·±åº¦åˆ†ææˆåŠŸ: {len(valid_deep_results)}/{len(passed_stocks)}")
            print(f"ğŸ† Açº§è‚¡ç¥¨å‘ç°: {len(a_grade_stocks)}")
            print(f"ğŸ’° ä»·æ ¼è¯„ä¼°å®Œæˆ: {len(price_evaluated_stocks)}")
            print(f"ğŸŸ¢ ä¹°å…¥æ¨è: {len(buy_recommendations)}")
            
            if a_grade_stocks:
                print(f"\nğŸŒŸ Açº§è‚¡ç¥¨åˆ—è¡¨:")
                for stock_code in a_grade_stocks:
                    result = valid_deep_results[stock_code]
                    score = result['overall_score']['total_score']
                    price = result['basic_analysis']['current_price']
                    action = result['recommendation']['action']
                    confidence = result['recommendation']['confidence']
                    price_eval_mark = " ğŸ’°" if 'price_evaluation' in result else ""
                    print(f"  ğŸ† {stock_code}: {score:.1f}åˆ†, Â¥{price:.2f}, {action} ({confidence:.1%}){price_eval_mark}")
            
            # ä¿å­˜æ·±åº¦æ‰«ææ±‡æ€»åˆ°ç­›é€‰æŠ¥å‘Š
            summary_report['deep_scan_summary'] = {
                'total_analyzed': len(valid_deep_results),
                'a_grade_count': len(a_grade_stocks),
                'price_evaluated_count': len(price_evaluated_stocks),
                'buy_recommendations': len(buy_recommendations),
                'a_grade_stocks': a_grade_stocks,
                'buy_recommendation_stocks': buy_recommendations
            }
            
            # æ›´æ–°æ±‡æ€»æŠ¥å‘Šæ–‡ä»¶
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary_report, f, ensure_ascii=False, indent=4)
            
            # æ›´æ–°æ–‡æœ¬æŠ¥å‘Š
            with open(text_report_file, 'a', encoding='utf-8') as f:
                f.write(f"\n=== æ·±åº¦æ‰«æç»“æœ (å¤šçº¿ç¨‹) ===\n")
                f.write(f"æ·±åº¦åˆ†ææˆåŠŸ: {len(valid_deep_results)}/{len(passed_stocks)}\n")
                f.write(f"Açº§è‚¡ç¥¨å‘ç°: {len(a_grade_stocks)}\n")
                f.write(f"ä»·æ ¼è¯„ä¼°å®Œæˆ: {len(price_evaluated_stocks)}\n")
                f.write(f"ä¹°å…¥æ¨è: {len(buy_recommendations)}\n\n")
                
                if a_grade_stocks:
                    f.write("=== Açº§è‚¡ç¥¨è¯¦æƒ… ===\n")
                    for stock_code in a_grade_stocks:
                        result = valid_deep_results[stock_code]
                        score = result['overall_score']['total_score']
                        price = result['basic_analysis']['current_price']
                        action = result['recommendation']['action']
                        confidence = result['recommendation']['confidence']
                        price_eval_mark = " [å·²è¯„ä¼°]" if 'price_evaluation' in result else ""
                        f.write(f"{stock_code}: {score:.1f}åˆ†, Â¥{price:.2f}, {action} "
                               f"(ä¿¡å¿ƒåº¦: {confidence:.1%}){price_eval_mark}\n")
                
                if buy_recommendations:
                    f.write(f"\n=== ä¹°å…¥æ¨èè‚¡ç¥¨ ===\n")
                    for stock_code in buy_recommendations:
                        result = valid_deep_results[stock_code]
                        score = result['overall_score']['total_score']
                        price = result['basic_analysis']['current_price']
                        confidence = result['recommendation']['confidence']
                        f.write(f"{stock_code}: {score:.1f}åˆ†, Â¥{price:.2f}, ä¿¡å¿ƒåº¦: {confidence:.1%}\n")
    else:
        print(f"\nâš ï¸ æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ï¼Œè·³è¿‡æ·±åº¦æ‰«æ")
    
    total_time = (datetime.now() - start_time).total_seconds()
    print(f"\nğŸ‰ å®Œæ•´æ‰«ææµç¨‹ç»“æŸï¼æ€»è€—æ—¶: {total_time:.2f} ç§’")
    
    logger.info(f"===== å®Œæ•´æ‰«æå®Œæˆï¼åˆæ­¥ç­›é€‰: {len(passed_stocks)} ä¸ªä¿¡å·ï¼Œæ€»è€—æ—¶: {total_time:.2f} ç§’ =====")

if __name__ == '__main__':
    main()
